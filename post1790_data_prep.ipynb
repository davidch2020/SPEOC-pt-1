{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "from os.path import exists\n",
    "import itertools\n",
    "from whoswho import who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringConvert(x):\n",
    "    return x.replace(\"  \", \" \") if type(x) == str else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineLists(lst):\n",
    "    returnlst = []\n",
    "    for sublist in lst:\n",
    "        if type(sublist) == list:\n",
    "            returnlst.extend([item for item in sublist])\n",
    "        else:\n",
    "            returnlst.append(sublist)\n",
    "    return returnlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that makes dictionary that combines 3 full name columns into 1\n",
    "def genFullNameList(namelst): \n",
    "    #remove duplicates and nulls\n",
    "    namelst = list(set([name for name in namelst if not pd.isnull(name)]))\n",
    "    namelst = sorted(namelst, key=len)\n",
    "    #remove names that are really similar\n",
    "    namelstnew = namelst\n",
    "    if len(namelst) > 1:\n",
    "        namelstnew = []\n",
    "        name1 = namelst[0]\n",
    "        namelstnew.append(name1)\n",
    "        for name in namelst[1:]:\n",
    "            score1  = process.extract(name1, [name])[0][1]\n",
    "            score2 = who.match(name1, name)\n",
    "            #only add names if they are dissimilar - fuzzy score 70 or less\n",
    "            if score1 <= 70:\n",
    "                namelstnew.append(name)\n",
    "    return namelstnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genFuzzyDict(df):\n",
    "    namelst = list(set([name for namelist in df['full name prelim'] for name in namelist]))\n",
    "    #create dictionary that matches similar names together\n",
    "    fn_fuzzy_pre = dict()\n",
    "    for name in namelst:\n",
    "        marker = False\n",
    "        if not pd.isnull(name):\n",
    "            #find matches for name\n",
    "            match = process.extract(name, [x for x in namelst if x != name and not \n",
    "                                           pd.isnull(x)], limit = 1, score_cutoff = 90)\n",
    "            if len(match)> 0:\n",
    "                match = match[0]\n",
    "                if match[1]>95:\n",
    "                    #add suitable matches to dictionary\n",
    "                    for nm in [match[0], name]:\n",
    "                        if nm in fn_fuzzy_pre.keys() and not marker:\n",
    "                            fn_fuzzy_pre[nm].extend([n for n in [match[0], name] if \n",
    "                                                     n != nm and n not in fn_fuzzy_pre[nm]])\n",
    "                            marker = True\n",
    "                    if not marker:\n",
    "                        if len(name) < len(match[0]):\n",
    "                            fn_fuzzy_pre[name] = [match[0]]\n",
    "                        else:\n",
    "                            fn_fuzzy_pre[match[0]] = [name]\n",
    "    #invert dictionary\n",
    "    fn_fuzzy = dict()\n",
    "    for key in fn_fuzzy_pre.keys():\n",
    "        vals = fn_fuzzy_pre[key]\n",
    "        for val in vals:\n",
    "            fn_fuzzy[val] = key\n",
    "    \n",
    "    return fn_fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate a string that contains two names into a list of two names\n",
    "def parseNames(x):\n",
    "    #replace words that don't have meaning\n",
    "    x = x.replace(\"and Co\", \"\").replace(\"and co\", \"\").replace(\"and Others\" ,\"\")\n",
    "    x = x.replace(\"and others\", \"\").replace(\"and Son\", \"\").replace(\"and Sons\", \"\")\n",
    "    x = x.replace(\"and Brothers\", \"\").strip()\n",
    "    #string preprocessing\n",
    "    namelst = x.split(\" and \")\n",
    "    namelst = [x.strip() for x in namelst if x.strip() != \"\"]\n",
    "    if len(namelst) > 1:\n",
    "        wd1len = len(namelst[0].split(\" \"))\n",
    "        wd2len = len(namelst[1].split(\" \"))\n",
    "        #add last name\n",
    "        if wd1len == 1 and wd2len != 1:\n",
    "            namelst[0] = namelst[0] + \" \" + namelst[1].split(\" \")[-1]\n",
    "    return namelst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformdf(df, state):\n",
    "    #add full name columns\n",
    "    df['full name 1'] = (df['First Name'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 1'] = df['full name 1'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['full name 2'] = (df['First Name.1'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name.1'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 2'] = df['full name 2'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['full name 3'] = (df['First Name.2'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name.2'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 3'] = df['full name 3'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['state'] = state\n",
    "    #add dicionary to merge different full name columns into one\n",
    "    df['full name prelim'] = [genFullNameList([fname1, fname2, fname3]) \n",
    "                              for fname1, fname2, fname3 in zip(df['full name 1'],\n",
    "                                                                df['full name 2'],\n",
    "                                                                df['full name 3'])]\n",
    "    df['full name'] = df['full name prelim']\n",
    "    #do some additional preprocessing\n",
    "    df = df[df['full name'].apply(lambda x: x != [])]\n",
    "    #separate names that are combined with \"and\", or otherwise treatde as one when they should be two\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [parseNames(x) if len(x.strip().split(\" \")) > 2 and \" and \" in x \n",
    "                                                                 else x for x in lst])\n",
    "    df['full name'] = df['full name'].apply(lambda namelist: combineLists(namelist))\n",
    "    \n",
    "    #fuzzy matching for different names in the full name column\n",
    "    fn_fuzzy = genFuzzyDict(df)\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [x if x not in fn_fuzzy.keys() \n",
    "                                                         else fn_fuzzy[x] for x in lst])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformonecoldf(df, state):\n",
    "    #do transformdf but for when you only have one full name oclumn\n",
    "    df['full name prelim'] =  (df['First Name'] + \" \" + df['Last Name']).apply(lambda x: [x] if not pd.isnull(x) else [])\n",
    "    df['state'] = state\n",
    "    \n",
    "    df['full name'] = df['full name prelim']\n",
    "    #some preprocessing\n",
    "    df = df[df['full name'].apply(lambda x: x != [])]\n",
    "    #separate names that are combined with \"and\", or otherwise treated as one when they should be two\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [parseNames(x) if len(x.strip().split(\" \")) > 2 and \" and \" in x \n",
    "                                                                 else x for x in lst])\n",
    "    df['full name'] = df['full name'].apply(lambda namelist: combineLists(namelist))\n",
    "    \n",
    "    #fuzzy matching for different names in the full name column\n",
    "    fn_fuzzy = genFuzzyDict(df)\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [x if x not in fn_fuzzy.keys() \n",
    "                                                         else fn_fuzzy[x] for x in lst]) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecticut Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "CT_CD = pd.read_excel(\"Data/Post1790/CT/CT_post1790_CD_ledger.xlsx\", \n",
    "                      header = 13, usecols = 'H, I, N, O, X, Y, AD, AE, AN, AO, AT, AU')\n",
    "CT_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                  'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "CT_CD_agg_pre = transformdf(CT_CD, 'CT')\n",
    "CT_CD_agg = CT_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maryland Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "MD_CD = pd.read_excel(\"Data/Post1790/MD/MD_post1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, L, M, U, V, Z, AA, AI, AJ, AN, AO')\n",
    "MD_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "MD_CD_agg_pre = transformdf(MD_CD, 'MD')\n",
    "MD_CD_agg = MD_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([CT_CD_agg, MD_CD_agg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# North Carolina Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NC_CD = pd.read_excel(\"Data/Post1790/NC/T695_R4_NC_CD.xlsx\", \n",
    "                      header = 11, usecols = 'J, K, W, X, Z, AA, AC, AD ')\n",
    "NC_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NC_CD_agg_pre = transformonecoldf(NC_CD, 'NC')\n",
    "NC_CD_agg = NC_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NC_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Hampshire Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NH_CD = pd.read_excel(\"Data/Post1790/NH/T652_R6_New_Hampshire_CD.xlsx\", \n",
    "                      header = 10, usecols = 'I, J, N, O, P, Q, R, S')\n",
    "NH_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents',  \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NH_CD_agg_pre = transformonecoldf(NH_CD, 'NH')\n",
    "NH_CD_agg = NH_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NH_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NY_CD = pd.read_excel(\"Data/Post1790/NY/NY_1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, M, N, X, Y, AC, AD, AM, AN, AR, AS')\n",
    "NY_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "NY_CD_agg_pre = transformdf(NY_CD, 'NY')\n",
    "NY_CD_agg = NY_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NY_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# South Carolina Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "SC_CD = pd.read_excel(\"Data/Post1790/SC/Post_1790_South_Carolina_CD.xlsx\", \n",
    "                      header = 11, usecols = 'D, E, M, N, S, T, AB, AC, AH, AI, AQ, AR')\n",
    "SC_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "SC_CD_agg_pre = transformdf(SC_CD, 'SC')\n",
    "SC_CD_agg = SC_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([SC_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pennsylvania Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "PA_CD = pd.read_excel(\"Data/Post1790/PA/PA_post1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, L, M, U, V, Z, AA, AI, AJ, AO, AP')\n",
    "PA_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "PA_CD_agg_pre = transformdf(PA_CD, 'PA')\n",
    "PA_CD_agg = PA_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([PA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rhode Island Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "RI_CD = pd.read_excel(\"Data/Post1790/RI/T653_Rhode_Island_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, L, M, U, V, Z, AA, AI, AJ, AN, AO')\n",
    "RI_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "RI_CD_agg_pre = transformdf(RI_CD, 'RI')\n",
    "RI_CD_agg = RI_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([RI_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virginia Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "VA_CD = pd.read_excel(\"Data/Post1790/VA/VA_CD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, K, L, U, V, X, Y, AH, AI, AK, AL')\n",
    "VA_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "VA_CD_agg_pre = transformdf(VA_CD, 'VA')\n",
    "VA_CD_agg = VA_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([VA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Georgia Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "GA_CD = pd.read_excel(\"Data/Post1790/GA/T694_GA_Loan_Office_CD.xlsx\", \n",
    "                      header = 10, usecols = 'Q, R, Z, AA, AB, AC, AD, AE')\n",
    "GA_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents',  \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "GA_CD_agg_pre = transformonecoldf(GA_CD, 'GA')\n",
    "GA_CD_agg = GA_CD_agg_pre[['full name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([GA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Jersey Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "#new jersey is handled manually because it only has 3 percent stock\n",
    "NJ_CD = pd.read_excel(\"Data/Post1790/NJ/NJ_3_percent_stock_T698_R1_R2.xlsx\", \n",
    "                      header = 11, usecols = 'D, E, L, M')\n",
    "NJ_CD.columns = ['First Name', 'Last Name', '3p_Dollar', '3p_Cents']\n",
    "NJ_CD['full name prelim'] =  (NJ_CD['First Name'] + \" \" + NJ_CD['Last Name']).apply(lambda x: [x] if not pd.isnull(x) else [])\n",
    "NJ_CD['state'] = 'NJ'\n",
    "NJ_CD['full name'] = NJ_CD['full name prelim']\n",
    "NJ_CD = NJ_CD[NJ_CD['full name'].apply(lambda x: x != [])]\n",
    "NJ_CD['full name'] = NJ_CD['full name'].apply(lambda lst: [parseNames(x) if len(x.strip().split(\" \")) > 2 and \" and \" in x \n",
    "                                                           else x for x in lst])\n",
    "NJ_CD['full name'] = NJ_CD['full name'].apply(lambda namelist: combineLists(namelist))\n",
    "    \n",
    "fn_fuzzy = genFuzzyDict(NJ_CD)\n",
    "NJ_CD['full name'] = NJ_CD['full name'].apply(lambda lst: [x if x not in fn_fuzzy.keys() \n",
    "                                                           else fn_fuzzy[x] for x in lst]) \n",
    "NJ_CD_agg_pre = NJ_CD\n",
    "NJ_CD_agg = NJ_CD_agg_pre[['full name', 'state', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset in final form\n",
    "cumulative_CD = pd.concat([NJ_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD['full name'] = cumulative_CD['full name'].apply(lambda lst: [x for x in lst if len(x.split(\" \")) > 1])\n",
    "cumulative_CD = cumulative_CD[cumulative_CD['full name'].apply(lambda x: x != [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn full name column from list into strings\n",
    "fname = cumulative_CD['full name'].apply(pd.Series)\n",
    "nnames = len(fname.columns)\n",
    "colnames = ['full name ' + str(i) for i in np.arange(1, nnames+1, 1)]\n",
    "fname.columns = colnames\n",
    "cumulative_CD = pd.concat([cumulative_CD, fname], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many unique individuals were issued 6 percent stocks or deferred 6 percent stocks in 1790 and after?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table of number of unique individuals issued 6% stocks (normal or deferred) by state\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    758\n",
       "GA     53\n",
       "MD    371\n",
       "NC     54\n",
       "NH    169\n",
       "NJ    569\n",
       "NY    879\n",
       "PA    877\n",
       "RI    530\n",
       "SC    272\n",
       "VA    522\n",
       "Name: full name, dtype: int64"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_6 = cumulative_CD[['6p_Dollar', '6p_Cents', \n",
    "                          '6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index\n",
    "print('table of number of unique individuals issued 6% stocks (normal or deferred) by state')\n",
    "cumulative_CD.groupby('state')['full name'].agg(sum).apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many of these individuals\n",
    "- were original purchasers of loan office certicates of the same state as the 6 percent stock?\n",
    "- were original purchasers of loan office certicates issued from another state?\n",
    "- were original recipients of liquidated debtcertiâ€‚cates issued by the same-state loan office? other state loan offices?\n",
    "- were original recipients of the Pierce Certicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_merge(lst1, lst2, threshold=85, limit = 100):\n",
    "    delegates = pd.Series([x for x in lst1.unique() if not pd.isnull(x)])\n",
    "    possible =  [x for x in lst2.unique().tolist() if type(x) == str]\n",
    " \n",
    "    #get matches\n",
    "    #process.extract uses a combination of all four fuzzywuzzy scores\n",
    "    matches = delegates.apply(lambda x: \n",
    "                              process.extract(x, possible, limit=limit, score_cutoff = threshold))\n",
    "    \n",
    "    match_df = pd.DataFrame(columns = ['Delegates', 'Loan Matches'])\n",
    "    #make each match a row in the dataframe\n",
    "    for delegate, matchset in zip(delegates, matches):\n",
    "        matchset_thres = [name for name in matchset if name[1] >= threshold]\n",
    "        if len(matchset_thres) == 0:\n",
    "            add_df = pd.DataFrame(data = {'Delegates': [delegate], 'Loan Matches': [\"\"], 'Scores': [0]})\n",
    "            match_df = pd.concat([match_df, add_df])\n",
    "        else:\n",
    "            delegate_lst = [delegate] * len(matchset_thres)\n",
    "            add_df = pd.DataFrame(data = {'Delegates': delegate_lst, \n",
    "                                          'Loan Matches': [x[0] for x in matchset_thres],\n",
    "                                          'Scores': [x[1] for x in matchset_thres]})\n",
    "            match_df = pd.concat([match_df, add_df])\n",
    "\n",
    "    return match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for performing the second step of the match\n",
    "def matchFunction(lst1, lst2, score = 90):\n",
    "    #check if our matches are actually min 2 words each\n",
    "    #make sure our match is because the individual are similar, not because the phrase or one word in the phrase is similar\n",
    "    #lst1 = list(pd.Series(lst1).unique())\n",
    "    #lst2 = list(pd.Series(lst2).unique())\n",
    "    threshold = min(len(lst1), len(lst2))\n",
    "    matches = 0\n",
    "    nomatch = []\n",
    "    i = 0\n",
    "    for wd1 in lst1:\n",
    "        #modifying which words we compare - dont want to compare first in lst1 with last in lst2\n",
    "        for wd2 in lst2:\n",
    "            if wd1 not in nomatch and process.extract(wd1, [wd2])[0][1] > score:\n",
    "                matches+=1\n",
    "                nomatch.append(wd1)\n",
    "        i+=1\n",
    "    return matches >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceMatches(delegates, debt, delegate_names, debt_names, threshold = 85):\n",
    "    initial = True\n",
    "    join_df = pd.DataFrame()\n",
    "    #run firs step of matching function\n",
    "    for del_name in delegate_names:\n",
    "        for debt_name in debt_names:\n",
    "            if initial:\n",
    "                join_df = fuzzy_merge(delegates[del_name], debt[debt_name], threshold)\n",
    "                initial = False\n",
    "            else:\n",
    "                add_df = fuzzy_merge(delegates[del_name], debt[debt_name], threshold)\n",
    "                join_df = pd.concat([join_df, add_df])\n",
    "    join_df = join_df.drop_duplicates().reset_index(drop = True)\n",
    "    join_df = join_df[join_df['Scores'].apply(lambda x: x != 0)]\n",
    "    join_df = join_df[join_df['Loan Matches'].apply(lambda x: not pd.isnull(x))]    \n",
    "    #run second step of matching function\n",
    "    join_df_p2 = join_df[join_df['Loan Matches'].apply(lambda x: len(list(set(x.replace(\"??\", \"\").strip().split(\" \"))))>=2)]\n",
    "    join_df_p2_final = join_df_p2[[matchFunction(x.split(\" \"), y.split(\" \")) for x, y in zip(join_df_p2['Delegates'], join_df_p2['Loan Matches'])]]\n",
    "    return join_df_p2_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and preprocess loan office data\n",
    "loan_office = pd.read_csv('Data/Pre1790/cleaned/loan_office_certificates_9_states_cleaned.csv', index_col = 0)\n",
    "states = ['NH', 'MA', 'CT', 'NY', 'NJ', 'PA', 'DE', 'MD', 'VA']\n",
    "num_names = [1, 2, 2, 3, 2, None, 2, None, None]\n",
    "state_names = dict(zip(np.arange(1, 10, 1), states))\n",
    "loan_office['State Name'] = loan_office['State'].apply(lambda x: state_names[x])\n",
    "loan_office['Full Name 1'] = (loan_office['First Name 1 '].apply(lambda x: stringConvert(x)) + \" \" + loan_office['Last Name 1 '].apply(lambda x: stringConvert(x)))\n",
    "loan_office['Full Name 2'] = (loan_office['First Name 2'].apply(lambda x: stringConvert(x)) + \" \" + loan_office['Last Name 2'].apply(lambda x: stringConvert(x)))\n",
    "loan_office['Full Name 3'] = (loan_office['First Name 3'].apply(lambda x: stringConvert(x)) + \" \" + loan_office['Last Name 3'].apply(lambda x: stringConvert(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many individuals were original purchasers of loan office certicates of the same state as the 6 percent stock?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_select = colnames\n",
    "state_select.extend(['state'])\n",
    "state_cols = ['cd name ' + str(i) for i in np.arange(1, len(state_select))]\n",
    "state_cols.extend(['cd state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match cd debt data with loan office data from the same state\n",
    "def loanOfficeSameState(state):\n",
    "    #filter for 6% stock\n",
    "    state_ind = cumulative_CD[cumulative_CD['state'] == state][['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index\n",
    "    #skip empty dataframes\n",
    "    if len(state_ind) != 0:\n",
    "        #prepare state and loan office data\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        loan_office_state = loan_office[loan_office['State Name'] == state][['Full Name 1', 'Full Name 2', 'Full Name 3', 'State Name']].drop_duplicates()\n",
    "        loan_office_state.columns = ['loan office name 1', 'loan office name 2', 'loan office name 3', 'loan office state']\n",
    "        #match data\n",
    "        matches = produceMatches(state_cd, loan_office_state, \n",
    "                                 delegate_names = [x for x in state_cols if 'state' not in x],\n",
    "                                 debt_names = ['loan office name 1', 'loan office name 2', 'loan office name 3'], threshold = 85)\n",
    "        matches['state'] = state\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loanoffice_samestate = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine matches from all the states\n",
    "for state in states:\n",
    "    df_loanoffice_samestate = pd.concat([df_loanoffice_samestate, loanOfficeSameState(state)])\n",
    "df_loanoffice_samestate.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loanoffice_samestate = df_loanoffice_samestate[df_loanoffice_samestate['CD name'].apply(lambda x: len(x.split(\" \")) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loanoffice_samestate.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual edits\n",
    "rem_ind = [233, 399, 425, 432, 451, 493, 494, 495, 591, 604, 651, 744, 753, 906]\n",
    "df_loanoffice_samestate = df_loanoffice_samestate.loc[[ind for ind in df_loanoffice_samestate.index if ind not in rem_ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals who were original purchasers of loan office certicates of the same state as the 6 percent stock\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    314\n",
       "MD    106\n",
       "NH     62\n",
       "NY     32\n",
       "PA    323\n",
       "VA     61\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarize results\n",
    "print(\"Number of individuals who were original purchasers of loan office certicates of the same state as the 6 percent stock\")\n",
    "df_loanoffice_samestate.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many individuals were original purchasers of loan office certicates issued from another state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#higher match threshold for non-same state loan office certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match cd debt data with loan office data from a different state\n",
    "def loanOfficeDifState(state):\n",
    "    #filter for 6% stock\n",
    "    state_ind = cumulative_CD[cumulative_CD['state'] == state][['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index\n",
    "    if len(state_ind) != 0:\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        loan_office_nostate = loan_office[loan_office['State Name'] != state][['Full Name 1', 'Full Name 2', 'Full Name 3', 'State Name']].drop_duplicates()\n",
    "        loan_office_nostate.columns = ['loan office name 1', 'loan office name 2', 'loan office name 3', 'loan office state']\n",
    "        #match data\n",
    "        matches = produceMatches(state_cd, loan_office_nostate, \n",
    "                                 delegate_names = [x for x in state_cols if 'state' not in x],\n",
    "                                 debt_names = ['loan office name 1', 'loan office name 2', 'loan office name 3'], threshold = 95)\n",
    "        matches['state'] = state\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loanoffice_difstate = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine matches from all the states\n",
    "for state in states:\n",
    "    df_loanoffice_difstate = pd.concat([df_loanoffice_difstate, loanOfficeDifState(state)])\n",
    "df_loanoffice_difstate.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loanoffice_difstate = df_loanoffice_difstate[df_loanoffice_difstate['CD name'].apply(lambda x: len(x.split(\" \")) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loanoffice_difstate.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual edits\n",
    "rem_ind = [86, 87, 88, 89, 90, 141, 142, 143, 158, 205, 206, 207, 369, 370, 377, 378, 379, 380, 381, 387, 388, 389, 413, 471, 472, 473]\n",
    "df_loanoffice_difstate = df_loanoffice_difstate.loc[[ind for ind in df_loanoffice_difstate.index if ind not in rem_ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    112\n",
       "MD     62\n",
       "NH     41\n",
       "NY     25\n",
       "PA    122\n",
       "VA     99\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loanoffice_difstate.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many individuals were original recipients of liquidated debt certificates issued by the same-state loan office? other state loan offices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match CD state data with liquidated debt from the same state\n",
    "def liquidatedSameStateDebt(state, file, num_names):\n",
    "    #filter for 6% stock   \n",
    "    state_ind = cumulative_CD[cumulative_CD['state'] == state][['6p_Dollar', '6p_Cents']].dropna(thresh = 1).index\n",
    "    if len(state_ind) != 0:\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        #import liquidated state debt files\n",
    "        datafile = 'Data/Pre1790/cleaned/'+file\n",
    "        if exists(datafile):\n",
    "            state_cert = pd.read_csv(datafile, index_col = 0)\n",
    "            namelst = []\n",
    "            #figure out how many full name columns there are in the state liquidated debt file\n",
    "            state_cert['Full Name'] = state_cert['First name'] + \" \" + state_cert['Last name'] \n",
    "            namelst.append('Full Name')\n",
    "            if num_names > 1:\n",
    "                for i in np.arange(2, num_names+1, 1):\n",
    "                    fullname_str = 'Full Name ' + str(i)\n",
    "                    state_cert[fullname_str] = state_cert['First name ' + str(i)] + \" \" + state_cert['Last name ' + str(i)] \n",
    "                    namelst.append(fullname_str)\n",
    "            state_cert_names = state_cert[namelst].drop_duplicates()\n",
    "            #produce matches\n",
    "            matches = produceMatches(state_cd, state_cert_names, \n",
    "                                     delegate_names = state_cols, debt_names = namelst, \n",
    "                                     threshold = 85)\n",
    "            matches['state'] = state\n",
    "            return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samestateliquid = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name = dict(zip(states, num_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine matches from all the states\n",
    "for state, num_name in state_name.items():\n",
    "    if state != \"PA\":\n",
    "        file = 'liquidated_debt_certificates_'+state+'_cleaned.csv'\n",
    "        df_samestateliquid = pd.concat([df_samestateliquid, liquidatedSameStateDebt(state, file, num_name)])\n",
    "    else:\n",
    "        file1 = 'liquidated_debt_certificates_PA_story_cleaned.csv'\n",
    "        df1 = liquidatedSameStateDebt('PA', file1, 1)\n",
    "        file2 = 'liquidated_debt_certificates_PA_stelle_cleaned.csv'\n",
    "        df2 = liquidatedSameStateDebt('PA', file2, 2)\n",
    "        df = pd.concat([df1, df2]).drop_duplicates()\n",
    "        df_samestateliquid = pd.concat([df_samestateliquid, df])\n",
    "df_samestateliquid.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samestateliquid = df_samestateliquid[df_samestateliquid['CD name'].apply(lambda x: len(x.split(\" \")) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samestateliquid.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual edits\n",
    "rem_ind = [162, 171, 191, 296, 319, 327, 330,]\n",
    "df_samestateliquid = df_samestateliquid.loc[[ind for ind in df_samestateliquid.index if ind not in rem_ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    104\n",
       "NH     28\n",
       "NY     38\n",
       "PA    220\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarize results\n",
    "df_samestateliquid.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceLiquidatedMatches(datafile, num_names, state_cd):\n",
    "    if exists(datafile):\n",
    "        state_cert = pd.read_csv(datafile, index_col = 0)\n",
    "        namelst = []\n",
    "        #figure out how many full name columns there are in the state liquidated debt file\n",
    "        state_cert['Full Name'] = state_cert['First name'] + \" \" + state_cert['Last name'] \n",
    "        namelst.append('Full Name')\n",
    "        if num_names > 1:\n",
    "            for i in np.arange(2, num_names+1, 1):\n",
    "                fullname_str = 'Full Name ' + str(i)\n",
    "                state_cert[fullname_str] = state_cert['First name ' + str(i)] + \" \" + state_cert['Last name ' + str(i)] \n",
    "                namelst.append(fullname_str)\n",
    "        state_cert_names = state_cert[namelst].drop_duplicates()\n",
    "        state_names = [x for x in state_cd.columns if x != 'cd state']\n",
    "        #produce matches\n",
    "        matches = produceMatches(state_cd, state_cert_names, \n",
    "                                 delegate_names = state_names, debt_names = namelst, \n",
    "                                 threshold = 95)\n",
    "        matches['state'] = state\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match CD state data with liquidated debt from a dif state\n",
    "def liquidatedDifStateDebt(state):\n",
    "    #filter for 6% stock   \n",
    "    state_ind = cumulative_CD[cumulative_CD['state'] == state][['6p_Dollar', '6p_Cents']].dropna(thresh = 1).index\n",
    "    if len(state_ind) != 0:\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        #import liquidated state debt files\n",
    "        match_df = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores'])\n",
    "        for statename, num_names in state_name.items():\n",
    "            if not pd.isnull(num_names):\n",
    "                datafile = 'Data/Pre1790/cleaned/liquidated_debt_certificates_'+statename+'_cleaned.csv'\n",
    "                matches = produceLiquidatedMatches(datafile, num_names, state_cd)\n",
    "                match_df = pd.concat([match_df, matches])\n",
    "            elif state == 'PA':    \n",
    "                datafile1 = 'Data/Pre1790/cleaned/liquidated_debt_certificates_PA_story_cleaned.csv'\n",
    "                matches1 = produceLiquidatedMatches(datafile, 1, state_cd)\n",
    "                datafile2 = 'Data/Pre1790/cleaned/liquidated_debt_certificates_PA_stelle_cleaned.csv'\n",
    "                matches2 = produceLiquidatedMatches(datafile, 2, state_cd)\n",
    "                match_df = pd.concat([match_df, matches2])\n",
    "        match_df['state'] = state\n",
    "        return match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_difstateliquid = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine matches from all the states\n",
    "for state in states:\n",
    "    df_difstateliquid = pd.concat([df_difstateliquid, liquidatedDifStateDebt(state)])\n",
    "df_difstateliquid.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_difstateliquid.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual edits\n",
    "rem_ind = [263, 378, 386, 496, 797]\n",
    "df_difstateliquid = df_difstateliquid.loc[[ind for ind in df_difstateliquid.index if ind not in rem_ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    182\n",
       "MD     42\n",
       "NH     59\n",
       "NY     49\n",
       "PA    133\n",
       "VA     58\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_difstateliquid.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many individuals were original recipients of the Pierce Certicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pierce = pd.read_csv('Data/Pre1790/cleaned/'+\"Pierce_Certs_cleaned_2021.csv\", index_col = 0)\n",
    "pierce['Full Name'] = pierce['First'].apply(lambda x: stringConvert(x)) + \" \" + pierce['Last'].apply(lambda x: stringConvert(x))\n",
    "pierce['Full Name 2'] = pierce['First 2'].apply(lambda x: stringConvert(x)) + \" \" + pierce['Last 2'].apply(lambda x: stringConvert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match cd debt data with loan office data from the Pierce certificate data\n",
    "def pierceCertificates(state):\n",
    "    #filter for 6% stock\n",
    "    state_ind = cumulative_CD[cumulative_CD['state'] == state][['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index\n",
    "    if len(state_ind) != 0:\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        #match data\n",
    "        pierce_names = pierce[pierce['State'].apply(lambda x: pd.isnull(x) or x == state)][['Full Name', 'Full Name 2']].drop_duplicates()\n",
    "        matches = produceMatches(state_cd, pierce_names, \n",
    "                                 delegate_names = ['cd name 1'], \n",
    "                                 debt_names = ['Full Name', 'Full Name 2'], \n",
    "                                 threshold = 95)\n",
    "        matches['state'] = state\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pierce = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    df_pierce = pd.concat([df_pierce, pierceCertificates(state)])\n",
    "df_pierce.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pierce = df_pierce[df_pierce['CD name'].apply(lambda x: len(x.split(\" \")) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    175\n",
       "MD     82\n",
       "NH     35\n",
       "NY     30\n",
       "PA    166\n",
       "VA    135\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pierce.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pierce.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual edits\n",
    "rem_ind = [193, 194, 195, 196, 197, 266, 267, 268, 269, 272, 273, 274, 275, \n",
    "           315, 316, 317, 318, 352, 353, 390, 391, 392, 393, 394, 395, 396, \n",
    "           549, 550, 551, 552, 565, 615, 616, 617, 618, 619, 620]\n",
    "df_pierce = df_pierce.loc[[ind for ind in df_pierce.index if ind not in rem_ind]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing all our results into one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column to add the matching names into a total table containing cd loan names\n",
    "#and corresopnding match names for each pre1790 loan times\n",
    "def mergeNames(colname, df):\n",
    "    colnames = [colname + ' 1', colname + ' 2', colname + ' 3', colname + ' 4', colname + ' 5']\n",
    "    loss_dict = dict(df.groupby('CD name')['Loan Office name'].apply(lambda x: list(x)))\n",
    "    cumulative_CD[colname + ' 1'] = cumulative_CD['full name 1'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname + ' 2'] = cumulative_CD['full name 2'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname + ' 3'] = cumulative_CD['full name 3'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname + ' 4'] = cumulative_CD['full name 4'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname + ' 5'] = cumulative_CD['full name 5'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname] = cumulative_CD[colnames].values.tolist()\n",
    "    cumulative_CD[colname] = cumulative_CD[colname].apply(lambda lst: list(set(combineLists([x for x in lst if type(x) != float]))))\n",
    "    cumulative_CD[colname] = cumulative_CD[colname].apply(lambda x: x if x != [] else np.nan)\n",
    "    cumulative_CD.drop(colnames, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run process on all four pre1790 loan types\n",
    "mergeNames('Same State Loan Office', df_loanoffice_samestate)\n",
    "mergeNames('Different State Loan Office', df_loanoffice_difstate)\n",
    "mergeNames('Same State Liquidated Debt', df_samestateliquid)\n",
    "mergeNames('Different State Liquidated Debt', df_difstateliquid)\n",
    "mergeNames('Pierce Certificates', df_pierce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of loan types one person had\n",
    "cumulative_CD['tot_count'] = 5 - cumulative_CD[['Same State Loan Office',\n",
    "                                                'Different State Loan Office',\n",
    "                                                'Same State Liquidated Debt',\n",
    "                                                'Different State Liquidated Debt',\n",
    "                                                'Pierce Certificates']].isna().sum(axis = 1)\n",
    "cumulative_CD.drop(['3p_Cents','3p_Dollar', 'full name 1', \n",
    "                    'full name 2','full name 3', 'full name 4',\n",
    "                    'full name 5'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some preprocesing - creating dictionaries to add back in data, after I turned the list of names into a string to remove duplicates\n",
    "#the original data we imported above was lost so we readd it by creating dictionaries\n",
    "cumulative_CD['str name'] = cumulative_CD['full name'].apply(lambda x: str(x)) + \"____\" + cumulative_CD['state']\n",
    "fullnamedict = dict(zip(cumulative_CD['str name'], cumulative_CD['full name']))\n",
    "statenamedict = dict(zip(cumulative_CD['str name'], cumulative_CD['state']))\n",
    "sslodict = dict(zip(cumulative_CD['str name'], cumulative_CD['Same State Loan Office']))\n",
    "dslodict = dict(zip(cumulative_CD['str name'], cumulative_CD['Different State Loan Office']))\n",
    "sslddict = dict(zip(cumulative_CD['str name'], cumulative_CD['Same State Liquidated Debt']))\n",
    "dslddict = dict(zip(cumulative_CD['str name'], cumulative_CD['Different State Liquidated Debt']))\n",
    "pcdict = dict(zip(cumulative_CD['str name'], cumulative_CD['Pierce Certificates']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use dictionaries to link data to matched values for each loan type\n",
    "cumulative_CD_assets = cumulative_CD.groupby('str name')['6p_Cents','6p_Dollar',\n",
    "                                                         '6p_def_Cents','6p_def_Dollar'].sum()\n",
    "cumulative_CD_assets.reset_index(inplace = True)\n",
    "cumulative_CD_assets['full name'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                           fullnamedict[x])\n",
    "cumulative_CD_assets['state'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                       statenamedict[x])\n",
    "cumulative_CD_assets['Same State Loan Office'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                        sslodict[x])\n",
    "cumulative_CD_assets['Different State Loan Office'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                             dslodict[x])\n",
    "cumulative_CD_assets['Same State Liquidated Debt'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                            sslddict[x])\n",
    "cumulative_CD_assets['Different State Liquidated Debt'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                                 dslddict[x])\n",
    "cumulative_CD_assets['Pierce Certificates'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                     pcdict[x])\n",
    "cumulative_CD_assets['Total'] = (cumulative_CD_assets['6p_def_Cents'] + \n",
    "                                 cumulative_CD_assets['6p_Cents'])/100 + (cumulative_CD_assets['6p_Dollar'] + \n",
    "                                                                          cumulative_CD_assets['6p_def_Dollar'])\n",
    "cumulative_CD_assets.drop(['6p_def_Cents', '6p_Cents', \n",
    "                           '6p_Dollar', '6p_def_Dollar', 'str name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>state</th>\n",
       "      <th>Same State Loan Office</th>\n",
       "      <th>Different State Loan Office</th>\n",
       "      <th>Same State Liquidated Debt</th>\n",
       "      <th>Different State Liquidated Debt</th>\n",
       "      <th>Pierce Certificates</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Bernard O'Neill]</td>\n",
       "      <td>MD</td>\n",
       "      <td>[Bernard O'Neill]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Francis O'Neill]</td>\n",
       "      <td>MD</td>\n",
       "      <td>[Francis O'Neill]</td>\n",
       "      <td>[Francis O Neill]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[H ', S Johnson ']</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Henry O'Neale]</td>\n",
       "      <td>MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Henry O'Neal]</td>\n",
       "      <td>99.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[James O'Hara]</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4977</td>\n",
       "      <td>[Zephaniah Andrews]</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1728.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4978</td>\n",
       "      <td>[Zephaniah Brown]</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4979</td>\n",
       "      <td>[Zephaniah Davis]</td>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4980</td>\n",
       "      <td>[Zerujah Bearley]</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4981</td>\n",
       "      <td>[Zuriel Waterman]</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4982 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                full name state Same State Loan Office  \\\n",
       "0       [Bernard O'Neill]    MD      [Bernard O'Neill]   \n",
       "1       [Francis O'Neill]    MD      [Francis O'Neill]   \n",
       "2      [H ', S Johnson ']    NY                    NaN   \n",
       "3         [Henry O'Neale]    MD                    NaN   \n",
       "4          [James O'Hara]    PA                    NaN   \n",
       "...                   ...   ...                    ...   \n",
       "4977  [Zephaniah Andrews]    RI                    NaN   \n",
       "4978    [Zephaniah Brown]    RI                    NaN   \n",
       "4979    [Zephaniah Davis]    CT                    NaN   \n",
       "4980    [Zerujah Bearley]    NJ                    NaN   \n",
       "4981    [Zuriel Waterman]    RI                    NaN   \n",
       "\n",
       "     Different State Loan Office Same State Liquidated Debt  \\\n",
       "0                            NaN                        NaN   \n",
       "1              [Francis O Neill]                        NaN   \n",
       "2                            NaN                        NaN   \n",
       "3                            NaN                        NaN   \n",
       "4                            NaN                        NaN   \n",
       "...                          ...                        ...   \n",
       "4977                         NaN                        NaN   \n",
       "4978                         NaN                        NaN   \n",
       "4979                         NaN                        NaN   \n",
       "4980                         NaN                        NaN   \n",
       "4981                         NaN                        NaN   \n",
       "\n",
       "     Different State Liquidated Debt Pierce Certificates    Total  \n",
       "0                                NaN                 NaN   230.31  \n",
       "1                                NaN                 NaN    37.96  \n",
       "2                                NaN                 NaN     0.00  \n",
       "3                                NaN      [Henry O'Neal]    99.77  \n",
       "4                                NaN                 NaN    33.44  \n",
       "...                              ...                 ...      ...  \n",
       "4977                             NaN                 NaN  1728.74  \n",
       "4978                             NaN                 NaN  2415.08  \n",
       "4979                             NaN                 NaN    77.20  \n",
       "4980                             NaN                 NaN     0.00  \n",
       "4981                             NaN                 NaN    10.95  \n",
       "\n",
       "[4982 rows x 8 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_CD_assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same State Loan Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add asset counts for each individual on each row to the state loan office table for the same state merging method\n",
    "def ssloTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Same State Loan Office']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state']\n",
    "    state_office = loan_office[loan_office['State Name'] == state]\n",
    "    ind1 = state_office[state_office['Full Name 1'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind2 = state_office[state_office['Full Name 2'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind3 = state_office[state_office['Full Name 3'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind1.extend(ind2)\n",
    "    ind1.extend(ind3)\n",
    "    total_val = state_office.loc[ind1]['Specie Value '].sum()\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD_assets['SSLO Total'] = np.nan\n",
    "ssloIndex = cumulative_CD_assets[cumulative_CD_assets['Same State Loan Office'].apply(lambda x: type(x) == list)].index\n",
    "cumulative_CD_assets.loc[ssloIndex, 'SSLO Total'] = [ssloTotal(x) for x in ssloIndex]\n",
    "cumulative_CD_assets['SSLO Total'] = cumulative_CD_assets['SSLO Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different State Loan Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add asset counts for each individual on each row to the state loan office table for the dif state merging method\n",
    "def dsloTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Different State Loan Office']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state']    \n",
    "    state_office = loan_office[loan_office['State Name'] != state]\n",
    "    ind1 = state_office[state_office['Full Name 1'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind2 = state_office[state_office['Full Name 2'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind3 = state_office[state_office['Full Name 3'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind1.extend(ind2)\n",
    "    ind1.extend(ind3)\n",
    "    total_val = state_office.loc[ind1]['Specie Value '].sum()\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD_assets['DSLO Total'] = np.nan\n",
    "dsloIndex = cumulative_CD_assets[cumulative_CD_assets['Different State Loan Office'].apply(lambda x: \n",
    "                                                                                           type(x) == list)].index\n",
    "cumulative_CD_assets.loc[dsloIndex, 'DSLO Total'] = [dsloTotal(x) for x in dsloIndex]\n",
    "cumulative_CD_assets['DSLO Total'] = cumulative_CD_assets['DSLO Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same State Liquidated Debt Certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to add values of liquidated debt certificates\n",
    "def ssldTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Same State Liquidated Debt']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state']\n",
    "    \n",
    "    if state != 'PA' and state in state_name.keys():\n",
    "        num_names = state_name[state]\n",
    "        state_certs_file = 'Data/Pre1790/cleaned/liquidated_debt_certificates_'+state+'_cleaned.csv'\n",
    "        if exists(state_certs_file):\n",
    "            total_val = calculateTotalValue(state_certs_file, num_names, name_options)\n",
    "            return total_val\n",
    "    elif state == 'PA':\n",
    "        state_certs_file1 = 'Data/Pre1790/cleaned/liquidated_debt_certificates_PA_story_cleaned.csv'\n",
    "        total_val1 = calculateTotalValue(state_certs_file1, 1, name_options)\n",
    "        state_certs_file2 = 'Data/Pre1790/cleaned/liquidated_debt_certificates_PA_stelle_cleaned.csv'\n",
    "        total_val2 = calculateTotalValue(state_certs_file2, 2, name_options)\n",
    "        return total_val1 + total_val2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate total value held by one person in debt certificates from a particular state\n",
    "def calculateTotalValue(file, num_names, name_options):\n",
    "    #this part is pretty similar to the merging part for liquidated debt certificates\n",
    "    state_cert = pd.read_csv(file, index_col = 0)\n",
    "    state_cert['Full Name'] = state_cert['First name'] + \" \" + state_cert['Last name'] \n",
    "    namelst = []\n",
    "    namelst.append('Full Name')\n",
    "    if num_names > 1:\n",
    "        for i in np.arange(2, num_names+1, 1):\n",
    "            fullname_str = 'Full Name ' + str(i)\n",
    "            state_cert[fullname_str] = state_cert['First name ' + str(i)] + \" \" + state_cert['Last name ' + str(i)] \n",
    "            namelst.append(fullname_str)\n",
    "    ind = []\n",
    "    for name in namelst:\n",
    "        ind.extend(state_cert[state_cert[name].apply(lambda x: x in name_options)].index.tolist())\n",
    "    #create subtable for the data we want, make it into a numeric value and sum it\n",
    "    subtbl = state_cert.loc[ind]\n",
    "    subtbl['Dollars'] = subtbl['Dollars'].apply(lambda x: float(x))\n",
    "    subtbl['90th'] = subtbl['90th'].apply(lambda x: float(x) if x != '22/8' else 22/8)\n",
    "    total_val = subtbl['Dollars'].sum() + subtbl['90th'].sum()/90\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD_assets['SSLD Total'] = np.nan\n",
    "ssldIndex = cumulative_CD_assets[cumulative_CD_assets['Same State Liquidated Debt'].apply(lambda x: \n",
    "                                                                                          type(x) == list)].index\n",
    "cumulative_CD_assets.loc[ssldIndex, 'SSLD Total'] = [ssldTotal(x) for x in ssldIndex]\n",
    "cumulative_CD_assets['SSLD Total'] = cumulative_CD_assets['SSLD Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different State Liquidated Debt Certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to add values of liquidated debt certificates\n",
    "def dsldTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Different State Liquidated Debt']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state']\n",
    "    sumval = 0\n",
    "    for statename in states:\n",
    "        if statename != 'PA' and not pd.isnull(state_name[statename]):\n",
    "            num_names = state_name[statename]\n",
    "            state_certs_file = 'Data/Pre1790/cleaned/liquidated_debt_certificates_'+statename+'_cleaned.csv'\n",
    "            if exists(state_certs_file):\n",
    "                total_val = calculateTotalValue(state_certs_file, \n",
    "                                                num_names, name_options)\n",
    "            sumval = sumval + total_val\n",
    "        elif statename == 'PA':\n",
    "            state_certs_file1 = 'Data/Pre1790/cleaned/liquidated_debt_certificates_PA_story_cleaned.csv'\n",
    "            total_val1 = calculateTotalValue(state_certs_file1, \n",
    "                                             1, name_options)\n",
    "            state_certs_file2 = 'Data/Pre1790/cleaned/liquidated_debt_certificates_PA_stelle_cleaned.csv'\n",
    "            total_val2 = calculateTotalValue(state_certs_file2, \n",
    "                                             2, name_options)\n",
    "            sumval = sumval + total_val1 + total_val2\n",
    "    return sumval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate total value held by one person in debt certificates from a particular state\n",
    "def calculateTotalValue(file, num_names, name_options):\n",
    "    #this part is pretty similar to the merging part for liquidated debt certificates\n",
    "    state_cert = pd.read_csv(file, index_col = 0)\n",
    "    state_cert['Full Name'] = state_cert['First name'] + \" \" + state_cert['Last name'] \n",
    "    namelst = []\n",
    "    namelst.append('Full Name')\n",
    "    if num_names > 1:\n",
    "        for i in np.arange(2, num_names+1, 1):\n",
    "            fullname_str = 'Full Name ' + str(i)\n",
    "            state_cert[fullname_str] = state_cert['First name ' + str(i)] + \" \" + state_cert['Last name ' + str(i)] \n",
    "            namelst.append(fullname_str)\n",
    "    ind = []\n",
    "    for name in namelst:\n",
    "        ind.extend(state_cert[state_cert[name].apply(lambda x: x in name_options)].index.tolist())\n",
    "    #create subtable for the data we want, make it into a numeric value and sum it\n",
    "    subtbl = state_cert.loc[ind]\n",
    "    subtbl['Dollars'] = subtbl['Dollars'].apply(lambda x: float(x))\n",
    "    subtbl['90th'] = subtbl['90th'].apply(lambda x: float(x) if x != '22/8' else 22/8)\n",
    "    total_val = subtbl['Dollars'].sum() + subtbl['90th'].sum()/90\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD_assets['DSLD Total'] = np.nan\n",
    "dsldIndex = cumulative_CD_assets[cumulative_CD_assets['Different State Liquidated Debt'].apply(lambda x:\n",
    "                                                                                               type(x) == list)].index\n",
    "cumulative_CD_assets.loc[dsldIndex, 'DSLD Total'] = [dsldTotal(x) for x in dsldIndex]\n",
    "cumulative_CD_assets['DSLD Total'] = cumulative_CD_assets['DSLD Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same State Pierce Certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate sum for pierce certificates\n",
    "def pcTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Pierce Certificates']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state']\n",
    "    \n",
    "    pierce_state = pierce[pierce['State'].apply(lambda x: \n",
    "                                                pd.isnull(x) or x == state)]\n",
    "    ind1 = pierce_state[pierce_state['Full Name'].apply(lambda x: \n",
    "                                                        x in name_options)].index.tolist()\n",
    "    ind2 = pierce_state[pierce_state['Full Name 2'].apply(lambda x: \n",
    "                                                          x in name_options)].index.tolist()\n",
    "    ind1.extend(ind2)\n",
    "    total_val = pierce_state.loc[ind1]['Value'].sum()\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD_assets['PC Total'] = np.nan\n",
    "pcIndex = cumulative_CD_assets[cumulative_CD_assets['Pierce Certificates'].apply(lambda x: \n",
    "                                                                                 type(x) == list)].index\n",
    "cumulative_CD_assets.loc[pcIndex, 'PC Total'] = [pcTotal(x) for x in pcIndex]\n",
    "cumulative_CD_assets['PC Total'] = cumulative_CD_assets['PC Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>state</th>\n",
       "      <th>Same State Loan Office</th>\n",
       "      <th>Different State Loan Office</th>\n",
       "      <th>Same State Liquidated Debt</th>\n",
       "      <th>Different State Liquidated Debt</th>\n",
       "      <th>Pierce Certificates</th>\n",
       "      <th>Total</th>\n",
       "      <th>SSLO Total</th>\n",
       "      <th>DSLO Total</th>\n",
       "      <th>SSLD Total</th>\n",
       "      <th>DSLD Total</th>\n",
       "      <th>PC Total</th>\n",
       "      <th>Debt Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Bernard O'Neill]</td>\n",
       "      <td>MD</td>\n",
       "      <td>[Bernard O'Neill]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.31</td>\n",
       "      <td>118.85973</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.85973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Francis O'Neill]</td>\n",
       "      <td>MD</td>\n",
       "      <td>[Francis O'Neill]</td>\n",
       "      <td>[Francis O Neill]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.96</td>\n",
       "      <td>17.50000</td>\n",
       "      <td>151.5125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.01250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[H ', S Johnson ']</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Henry O'Neale]</td>\n",
       "      <td>MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Henry O'Neal]</td>\n",
       "      <td>99.77</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[James O'Hara]</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.44</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4977</td>\n",
       "      <td>[Zephaniah Andrews]</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1728.74</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4978</td>\n",
       "      <td>[Zephaniah Brown]</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415.08</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4979</td>\n",
       "      <td>[Zephaniah Davis]</td>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.20</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4980</td>\n",
       "      <td>[Zerujah Bearley]</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4981</td>\n",
       "      <td>[Zuriel Waterman]</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.95</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4982 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                full name state Same State Loan Office  \\\n",
       "0       [Bernard O'Neill]    MD      [Bernard O'Neill]   \n",
       "1       [Francis O'Neill]    MD      [Francis O'Neill]   \n",
       "2      [H ', S Johnson ']    NY                    NaN   \n",
       "3         [Henry O'Neale]    MD                    NaN   \n",
       "4          [James O'Hara]    PA                    NaN   \n",
       "...                   ...   ...                    ...   \n",
       "4977  [Zephaniah Andrews]    RI                    NaN   \n",
       "4978    [Zephaniah Brown]    RI                    NaN   \n",
       "4979    [Zephaniah Davis]    CT                    NaN   \n",
       "4980    [Zerujah Bearley]    NJ                    NaN   \n",
       "4981    [Zuriel Waterman]    RI                    NaN   \n",
       "\n",
       "     Different State Loan Office Same State Liquidated Debt  \\\n",
       "0                            NaN                        NaN   \n",
       "1              [Francis O Neill]                        NaN   \n",
       "2                            NaN                        NaN   \n",
       "3                            NaN                        NaN   \n",
       "4                            NaN                        NaN   \n",
       "...                          ...                        ...   \n",
       "4977                         NaN                        NaN   \n",
       "4978                         NaN                        NaN   \n",
       "4979                         NaN                        NaN   \n",
       "4980                         NaN                        NaN   \n",
       "4981                         NaN                        NaN   \n",
       "\n",
       "     Different State Liquidated Debt Pierce Certificates    Total  SSLO Total  \\\n",
       "0                                NaN                 NaN   230.31   118.85973   \n",
       "1                                NaN                 NaN    37.96    17.50000   \n",
       "2                                NaN                 NaN     0.00     0.00000   \n",
       "3                                NaN      [Henry O'Neal]    99.77     0.00000   \n",
       "4                                NaN                 NaN    33.44     0.00000   \n",
       "...                              ...                 ...      ...         ...   \n",
       "4977                             NaN                 NaN  1728.74     0.00000   \n",
       "4978                             NaN                 NaN  2415.08     0.00000   \n",
       "4979                             NaN                 NaN    77.20     0.00000   \n",
       "4980                             NaN                 NaN     0.00     0.00000   \n",
       "4981                             NaN                 NaN    10.95     0.00000   \n",
       "\n",
       "      DSLO Total  SSLD Total  DSLD Total  PC Total  Debt Total  \n",
       "0         0.0000         0.0         0.0       0.0   118.85973  \n",
       "1       151.5125         0.0         0.0       0.0   169.01250  \n",
       "2         0.0000         0.0         0.0       0.0     0.00000  \n",
       "3         0.0000         0.0         0.0      23.0    23.00000  \n",
       "4         0.0000         0.0         0.0       0.0     0.00000  \n",
       "...          ...         ...         ...       ...         ...  \n",
       "4977      0.0000         0.0         0.0       0.0     0.00000  \n",
       "4978      0.0000         0.0         0.0       0.0     0.00000  \n",
       "4979      0.0000         0.0         0.0       0.0     0.00000  \n",
       "4980      0.0000         0.0         0.0       0.0     0.00000  \n",
       "4981      0.0000         0.0         0.0       0.0     0.00000  \n",
       "\n",
       "[4982 rows x 14 columns]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_CD_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD_assets['Debt Total'] = cumulative_CD_assets[['SSLO Total','DSLO Total',\n",
    "                                                           'SSLD Total', 'DSLD Total',\n",
    "                                                           'PC Total']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790_certs = ['Same State Loan Office','Different State Loan Office', \n",
    "                 'Same State Liquidated Debt','Different State Liquidated Debt','Pierce Certificates']\n",
    "cumulative_CD_assets['tot_pre1790_certs'] = 5 - cumulative_CD_assets[pre1790_certs].isna().sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_CD_assets.to_csv(\"prepost_matched_debt_files.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>state</th>\n",
       "      <th>Same State Loan Office</th>\n",
       "      <th>Different State Loan Office</th>\n",
       "      <th>Same State Liquidated Debt</th>\n",
       "      <th>Different State Liquidated Debt</th>\n",
       "      <th>Pierce Certificates</th>\n",
       "      <th>Total</th>\n",
       "      <th>SSLO Total</th>\n",
       "      <th>DSLO Total</th>\n",
       "      <th>SSLD Total</th>\n",
       "      <th>DSLD Total</th>\n",
       "      <th>PC Total</th>\n",
       "      <th>Debt Total</th>\n",
       "      <th>tot_pre1790_certs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Bernard O'Neill]</td>\n",
       "      <td>MD</td>\n",
       "      <td>[Bernard O'Neill]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.31</td>\n",
       "      <td>118.85973</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.85973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Francis O'Neill]</td>\n",
       "      <td>MD</td>\n",
       "      <td>[Francis O'Neill]</td>\n",
       "      <td>[Francis O Neill]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.96</td>\n",
       "      <td>17.50000</td>\n",
       "      <td>151.5125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.01250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[H ', S Johnson ']</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Henry O'Neale]</td>\n",
       "      <td>MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Henry O'Neal]</td>\n",
       "      <td>99.77</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[James O'Hara]</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.44</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4977</td>\n",
       "      <td>[Zephaniah Andrews]</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1728.74</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4978</td>\n",
       "      <td>[Zephaniah Brown]</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415.08</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4979</td>\n",
       "      <td>[Zephaniah Davis]</td>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.20</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4980</td>\n",
       "      <td>[Zerujah Bearley]</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4981</td>\n",
       "      <td>[Zuriel Waterman]</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.95</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4982 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                full name state Same State Loan Office  \\\n",
       "0       [Bernard O'Neill]    MD      [Bernard O'Neill]   \n",
       "1       [Francis O'Neill]    MD      [Francis O'Neill]   \n",
       "2      [H ', S Johnson ']    NY                    NaN   \n",
       "3         [Henry O'Neale]    MD                    NaN   \n",
       "4          [James O'Hara]    PA                    NaN   \n",
       "...                   ...   ...                    ...   \n",
       "4977  [Zephaniah Andrews]    RI                    NaN   \n",
       "4978    [Zephaniah Brown]    RI                    NaN   \n",
       "4979    [Zephaniah Davis]    CT                    NaN   \n",
       "4980    [Zerujah Bearley]    NJ                    NaN   \n",
       "4981    [Zuriel Waterman]    RI                    NaN   \n",
       "\n",
       "     Different State Loan Office Same State Liquidated Debt  \\\n",
       "0                            NaN                        NaN   \n",
       "1              [Francis O Neill]                        NaN   \n",
       "2                            NaN                        NaN   \n",
       "3                            NaN                        NaN   \n",
       "4                            NaN                        NaN   \n",
       "...                          ...                        ...   \n",
       "4977                         NaN                        NaN   \n",
       "4978                         NaN                        NaN   \n",
       "4979                         NaN                        NaN   \n",
       "4980                         NaN                        NaN   \n",
       "4981                         NaN                        NaN   \n",
       "\n",
       "     Different State Liquidated Debt Pierce Certificates    Total  SSLO Total  \\\n",
       "0                                NaN                 NaN   230.31   118.85973   \n",
       "1                                NaN                 NaN    37.96    17.50000   \n",
       "2                                NaN                 NaN     0.00     0.00000   \n",
       "3                                NaN      [Henry O'Neal]    99.77     0.00000   \n",
       "4                                NaN                 NaN    33.44     0.00000   \n",
       "...                              ...                 ...      ...         ...   \n",
       "4977                             NaN                 NaN  1728.74     0.00000   \n",
       "4978                             NaN                 NaN  2415.08     0.00000   \n",
       "4979                             NaN                 NaN    77.20     0.00000   \n",
       "4980                             NaN                 NaN     0.00     0.00000   \n",
       "4981                             NaN                 NaN    10.95     0.00000   \n",
       "\n",
       "      DSLO Total  SSLD Total  DSLD Total  PC Total  Debt Total  \\\n",
       "0         0.0000         0.0         0.0       0.0   118.85973   \n",
       "1       151.5125         0.0         0.0       0.0   169.01250   \n",
       "2         0.0000         0.0         0.0       0.0     0.00000   \n",
       "3         0.0000         0.0         0.0      23.0    23.00000   \n",
       "4         0.0000         0.0         0.0       0.0     0.00000   \n",
       "...          ...         ...         ...       ...         ...   \n",
       "4977      0.0000         0.0         0.0       0.0     0.00000   \n",
       "4978      0.0000         0.0         0.0       0.0     0.00000   \n",
       "4979      0.0000         0.0         0.0       0.0     0.00000   \n",
       "4980      0.0000         0.0         0.0       0.0     0.00000   \n",
       "4981      0.0000         0.0         0.0       0.0     0.00000   \n",
       "\n",
       "      tot_pre1790_certs  \n",
       "0                     1  \n",
       "1                     2  \n",
       "2                     0  \n",
       "3                     1  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "4977                  0  \n",
       "4978                  0  \n",
       "4979                  0  \n",
       "4980                  0  \n",
       "4981                  0  \n",
       "\n",
       "[4982 rows x 15 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_CD_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD name</th>\n",
       "      <th>Loan Office name</th>\n",
       "      <th>Scores</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ammi R Cutter</td>\n",
       "      <td>Ammi R Cutter</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Matthew Thornton</td>\n",
       "      <td>Matthew Thornton</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Samuel Brooks</td>\n",
       "      <td>Samuel Brooks</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>John Ward Gilman</td>\n",
       "      <td>John Ward Gilman</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>John Ward Gilman</td>\n",
       "      <td>John Gilman</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>Abraham Hite</td>\n",
       "      <td>Abraham Hite</td>\n",
       "      <td>100.0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>971</td>\n",
       "      <td>James Mercer</td>\n",
       "      <td>James Mercer</td>\n",
       "      <td>100.0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>972</td>\n",
       "      <td>John Chisman</td>\n",
       "      <td>John Chisman</td>\n",
       "      <td>100.0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>973</td>\n",
       "      <td>William Price</td>\n",
       "      <td>William Price</td>\n",
       "      <td>100.0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>974</td>\n",
       "      <td>John Colgin</td>\n",
       "      <td>John Colgin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              CD name  Loan Office name  Scores state\n",
       "0       Ammi R Cutter     Ammi R Cutter   100.0    NH\n",
       "1    Matthew Thornton  Matthew Thornton   100.0    NH\n",
       "2       Samuel Brooks     Samuel Brooks   100.0    NH\n",
       "3    John Ward Gilman  John Ward Gilman   100.0    NH\n",
       "4    John Ward Gilman       John Gilman    95.0    NH\n",
       "..                ...               ...     ...   ...\n",
       "970      Abraham Hite      Abraham Hite   100.0    VA\n",
       "971      James Mercer      James Mercer   100.0    VA\n",
       "972      John Chisman      John Chisman   100.0    VA\n",
       "973     William Price     William Price   100.0    VA\n",
       "974       John Colgin       John Colgin   100.0    VA\n",
       "\n",
       "[961 rows x 4 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loanoffice_samestate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run process on all four pre1790 loan types\n",
    "mergeNames('Same State Loan Office', df_loanoffice_samestate)\n",
    "mergeNames('Different State Loan Office', df_loanoffice_difstate)\n",
    "mergeNames('Same State Liquidated Debt', df_samestateliquid)\n",
    "mergeNames('Different State Liquidated Debt', df_difstateliquid)\n",
    "mergeNames('Pierce Certificates', df_pierce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
