{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions and Structures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "# state abbreviation conversion dictionary\n",
    "statedict = {'PA': 'Pennsylvania', 'CT': 'Connecticut', 'MA': 'Massachusetts', 'NH': 'New Hampshire', 'DE': 'Delaware',\n",
    "             'NC': 'North Carolina', 'GA': 'Georgia', 'NY': 'New York', 'NJ': 'New Jersey', 'RI': 'Rhode Island',\n",
    "             'VA': 'Virginia', 'MD': 'Maryland', 'SC': 'South Carolina', 'VT': 'Vermont'}\n",
    "# user variable\n",
    "user = \"Chris\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "final_name_list = pd.read_csv('scrape_tools/name_list.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scrape Data From Ancestry"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "def tNameList(lst):\n",
    "    \"\"\"\n",
    "    takes a list of names and returns a string of names separated by \" | \", sorted and with duplicates removed, and with \"\" removed\n",
    "    :param lst: input lst\n",
    "    :return: string with names joined\n",
    "    \"\"\"\n",
    "    return \" | \".join(sorted(list(set([ele for ele in lst if ele != \"\"]))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "def determineMatchList(name_type,state):\n",
    "    \"\"\"\n",
    "    lists out the different options (how strict we will be with location + name) for searching that we will iterate through based on whether our location option is a town, county, state or nation location\n",
    "    :param name_type: whether we have a town, county, state or nation location\n",
    "    :return: strictness_params\n",
    "    \"\"\"\n",
    "    if name_type == \"town\":\n",
    "        return [\"name_x=1_1&residence_x=_1-0\", \"name_x=s_s&residence_x=_1-0\", \"name_x=ps_ps&residence_x=_1-0\",\n",
    "                \"name_x=ps_ps&residence_x=_1-1\", \"name_x=ps_ps&residence_x=_1-1-a\"]\n",
    "    elif name_type == \"county\":\n",
    "        return [\"name_x=1_1&residence_x=_1-0\", \"name_x=s_s&residence_x=_1-0\", \"name_x=ps_ps&residence_x=_1-0\",\n",
    "                \"name_x=ps_ps&residence_x=_1-0-a\", \"name_x=ps_ps&residence_x=_1-1\"]\n",
    "    else:\n",
    "        # name_type = state\n",
    "        if state == 'NY':\n",
    "            return [\"name_x=1_1&residence_x=_1-0\", \"name_x=s_s&residence_x=_1-0\", \"name_x=ps_ps&residence_x=_1-0\",\n",
    "                    \"name_x=ps_ps&residence_x=_1-0-a\"]\n",
    "        else:\n",
    "            return [\"name_x=1_1&residence_x=_1-0\", \"name_x=s_s&residence_x=_1-0\", \"name_x=ps_ps&residence_x=_1-0\",\n",
    "                \"name_x=ps_ps&residence_x=_1-0\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "def processLocationString(name_type, town, county, state, keep_county=True):\n",
    "    \"\"\"\n",
    "    Convert our information on a geography into a well-formatted string\n",
    "    :param name_type_fn: whether we have a town, county or a state\n",
    "    :param town: town name, if exists\n",
    "    :param county: county name, if exists\n",
    "    :param state: state name\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not keep_county and name_type != 'state':\n",
    "        county = county.replace(\" County\", \"\").strip()\n",
    "\n",
    "    if name_type == \"town\":\n",
    "        return town + \", \" + county + \", \" + statedict[state]\n",
    "    elif name_type == \"county\":\n",
    "        return county + \", \" + statedict[state]\n",
    "    else:\n",
    "        # name_type is state\n",
    "        return statedict[state]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "# function that controls settings for strictness of search and returns final data for each individual\n",
    "def findMatches(fn, ln, driver, search_town, search_county, search_state, name_type):\n",
    "    \"\"\"\n",
    "    Function that controls settings for strictness of search and returns final data for each individual\n",
    "\n",
    "    :param fn: first name\n",
    "    :param ln: last name\n",
    "    :param driver: selenium web scraper driver\n",
    "    :param search_town: name of town we are searching for\n",
    "    :param search_county: name of county we are searching for\n",
    "    :param search_state: name of state we are searching for\n",
    "    :param name_type: type of location given (town, county, state)\n",
    "    :return: final data for each individual from ancestry database\n",
    "    \"\"\"\n",
    "    # how many searches to conduct\n",
    "    max_searchind = 4 if name_type != \"state\" else 3\n",
    "    # navigate to original url\n",
    "    search_ind = 0\n",
    "\n",
    "    # navigate to initial url for person\n",
    "    driver, url = navigateTo(fn, ln, driver, search_ind, search_town, search_county, search_state, name_type,\n",
    "                             initial=True)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # see if there are any matches using initial strict settings\n",
    "    val, search_ind = listPeople(driver, search_ind, name_type)\n",
    "\n",
    "    # if we have found a match or we have exhausted all possible matchings, exit while loop\n",
    "    # finding a match will automatically make seach_ind = max_searchind\n",
    "    while search_ind < max_searchind:\n",
    "        search_ind += 1\n",
    "        # navigate to url with new settings\n",
    "        driver, url = navigateTo(fn, ln, driver, search_ind, search_town, search_county, search_state, name_type)\n",
    "        time.sleep(1.5)\n",
    "        val, search_ind = listPeople(driver, search_ind, name_type)\n",
    "\n",
    "    # add last url used to data\n",
    "    val['url'] = url\n",
    "    return val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "# probably could amend this so that we don't have an \"initial\" setting, we just search for the location code for the particular location\n",
    "def navigateTo(fn, ln, driver, search_ind, search_town, search_county, search_state, name_type_fn, initial=False):\n",
    "    \"\"\"\n",
    "    Function that helps us navigate to the correct url for a particular name search, given the location as well as the iteration of the search (iteration will determine which index we use)\n",
    "\n",
    "    :param fn: first name\n",
    "    :param ln: last name\n",
    "    :param driver: selenium web scraper driver\n",
    "    :param search_ind: index of the search we are doing, deterines strictness of name and location suffix parameters\n",
    "    :param search_town: town name\n",
    "    :param search_county: county name\n",
    "    :param search_state: state name\n",
    "    :param name_type_fn: whether we are searching for a town, county or state\n",
    "    :param initial: whether this is the first time we are doing this search\n",
    "    :return: selenium web scraper driver and the url we navigated to\n",
    "    \"\"\"\n",
    "    # replace spaces with + for url formatting\n",
    "    fn = fn.replace(\" \", \"+\")\n",
    "    ln = ln.replace(\" \", \"+\")\n",
    "\n",
    "    # get name and location suffix parameters for search\n",
    "    searchstr = searchLocationString(name_type, search_town, search_county, search_state)\n",
    "    search_params = determineMatchList(name_type_fn, search_state)[search_ind]\n",
    "    namesuffix = search_params.split(\"&\")[0].replace(\"name_x=\", \"\")\n",
    "    locsuffix = search_params.split(\"&\")[1].replace(\"residence_x=\", \"\")\n",
    "\n",
    "    # get location number for the particular location we are searching for\n",
    "    if initial:\n",
    "        # there are two formats for the location string, one with the word county in the county name and one without\n",
    "        locationstr_keep = processLocationString(name_type, search_town, search_county, search_state, True)\n",
    "        locationstr_disc = processLocationString(name_type, search_town, search_county, search_state, False)\n",
    "\n",
    "        # see if there is a location string that we have a valid code for\n",
    "        # by default, if there is no location string that we have a valid code for, we will use the location string with the county name\n",
    "        # this is because we use the location string with the county name to search for the correct code\n",
    "        if locationstr_disc in locationsuffix.keys():\n",
    "            locationstr = locationstr_disc\n",
    "        else:\n",
    "            locationstr = locationstr_keep\n",
    "\n",
    "        # if we have the location code, and this is the initial search, enter the necessary information\n",
    "        if locationstr in locationsuffix.keys():\n",
    "            locationnum = locationsuffix[locationstr]\n",
    "            url = f\"https://www.ancestrylibrary.com/search/collections/5058/?name={fn}_{ln}&name_x={namesuffix}&residence=_{searchstr}_{locationnum}&residence_x={locsuffix}\"\n",
    "            driver.get(url)\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            # need to find the location code - we do this by doing a general search using the location and then obtaning the code from the search url\n",
    "            driver.get('https://www.ancestrylibrary.com/search/collections/5058/')\n",
    "            time.sleep(2)\n",
    "            #val = driver.find_element(by = By.XPATH, value =\"//*[@id=\\\"sfs_ContentBased\\\"]/div[1]/div/fieldset[1]/div[2]/label\").get_attribute(\"for\").split(\"Place_\")[1]\n",
    "\n",
    "            # try obtaining the code by using either the location string with the county name or the location string without the county name\n",
    "            try:\n",
    "                driver.find_element(by=By.XPATH, value=f\"//*[@id=\\\"sfs__SelfResidencePlace\\\"]\").send_keys(\n",
    "                    locationstr_keep)\n",
    "                time.sleep(2)\n",
    "                driver.find_element(by=By.XPATH, value=f\"//*[@id=\\\"sfs__SelfResidencePlaceAutocomplete0\\\"]\").click()\n",
    "                time.sleep(1)\n",
    "                driver.find_element(by=By.XPATH, value=f\"//*[@id=\\\"sfs__SelfResidencePlace\\\"]\").send_keys(Keys.ENTER)\n",
    "                time.sleep(2)\n",
    "                currurl = driver.current_url\n",
    "                code = currurl.split(\"usa_\")[1]\n",
    "                locationsuffix[locationstr] = code\n",
    "            except:\n",
    "                driver.get('https://www.ancestrylibrary.com/search/collections/5058/')\n",
    "                time.sleep(3)\n",
    "                driver.find_element(by=By.XPATH, value=f\"//*[@id=\\\"sfs__SelfResidencePlace\\\"]\").send_keys(\n",
    "                    locationstr_disc)\n",
    "                time.sleep(2)\n",
    "                driver.find_element(by=By.XPATH, value=f\"//*[@id=\\\"sfs__SelfResidencePlaceAutocomplete0\\\"]\").click()\n",
    "                time.sleep(1)\n",
    "                driver.find_element(by=By.XPATH, value=f\"//*[@id=\\\"sfs__SelfResidencePlace\\\"]\").send_keys(Keys.ENTER)\n",
    "                time.sleep(2)\n",
    "                print(currurl)\n",
    "                currurl = driver.current_url\n",
    "                code = currurl.split(\"usa_\")[1]\n",
    "                locationsuffix[locationstr] = code\n",
    "\n",
    "            # final url with all the necessary inputs\n",
    "            url = f\"https://www.ancestrylibrary.com/search/collections/5058/?name={fn}_{ln}&name_x={namesuffix}&residence=_{searchstr}_{code}&residence_x={locsuffix}\"\n",
    "            driver.get(url)\n",
    "            time.sleep(3)\n",
    "    else:\n",
    "        # if we are not doing the initial search, we can just use the url that we have already obtained and then input the desired parameters\n",
    "        currurl = driver.current_url\n",
    "        url = currurl.split(\"&name_x\")[0] + f\"&name_x={namesuffix}\" + \"&residence=_\" + currurl.split(\"&residence=_\")[1].split(\"&residence_x=\")[0] + f\"&residence_x={locsuffix}\"\n",
    "    driver.get(url)\n",
    "\n",
    "    return driver, url"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "def listPeople(driver, search_ind, name_type):\n",
    "    \"\"\"\n",
    "    Function that obtains data on individuals from an Ancestry.com search page\n",
    "\n",
    "    :param driver: driver for selenium web scraper\n",
    "    :param fn:\n",
    "    :param ln:\n",
    "    :param samelocation:\n",
    "    :param expandGeography:\n",
    "    :param expandNameMatch:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    max_searchind = 4 if name_type != \"state\" else 3\n",
    "\n",
    "    info = dict()\n",
    "    # if no matches found, loosen the restrictions on gegraphy and name\n",
    "    try:\n",
    "        count_text = driver.find_element(By.XPATH, \"//*[@id=\\\"results-footer\\\"]/h3\").text\n",
    "        search_ind = max_searchind\n",
    "    except:\n",
    "        # we only have 4/5 search options\n",
    "        if search_ind == max_searchind:\n",
    "            info['Match Status'] = 'No Match'\n",
    "            return info, search_ind\n",
    "        else:\n",
    "            return \"continue searching\", search_ind\n",
    "\n",
    "    count = int(count_text.split(\" of \")[1])\n",
    "    # if multiple matches found, see if any of them are all in the same place\n",
    "    # we can categorize this as a \"location match\"\n",
    "    if count > 1:\n",
    "        if count < 5:  # likelihood of same location for over 5 individuals = rare\n",
    "            info['Match Status'] = f'{count} Potential Matches Found'\n",
    "            for i in range(count):\n",
    "                currurl = driver.current_url\n",
    "                p_info = getInfo(driver, i)\n",
    "                info[f'Match {i + 1}'] = p_info\n",
    "                driver.get(currurl)\n",
    "        else:\n",
    "            info['Match Status'] = f'No Match: Too Many Potential Matches Found {count}'\n",
    "        return info, search_ind\n",
    "    # if only one name is found then we categorize this as a person match\n",
    "    else:\n",
    "        p_info = getInfo(driver, 0)\n",
    "        info['Match Status'] = 'Complete Match'\n",
    "        info[f'Match 1'] = p_info\n",
    "        return info, search_ind"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "def getInfo(driver, i):\n",
    "    \"\"\"\n",
    "    Function that obtains data on an individual from an Ancestry.com search page\n",
    "\n",
    "    :param driver: selenium driver\n",
    "    :param i: which index on the search page to gather data for\n",
    "    :return: dictionary of data for individual\n",
    "    \"\"\"\n",
    "    time.sleep(1.5)\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.XPATH, f\"//*[@id=\\\"sRes-{i}\\\"]/td[1]/span[1]/a\")))\n",
    "    driver.find_element(By.XPATH, f\"//*[@id=\\\"sRes-{i}\\\"]/td[1]/span[1]/a\").click()\n",
    "    print(\"clicked!\")\n",
    "    time.sleep(1.5)\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.XPATH, f\"//*[@id=\\\"recordServiceData\\\"]/tbody/tr[1]/th\")))\n",
    "\n",
    "    success = True\n",
    "    ind = 1\n",
    "    info = {}\n",
    "    while success:\n",
    "        try:\n",
    "            key = driver.find_element(By.XPATH, f\"//*[@id=\\\"recordServiceData\\\"]/tbody/tr[{ind}]/th\").text.strip()\n",
    "            val = driver.find_element(By.XPATH, f\"//*[@id=\\\"recordServiceData\\\"]/tbody/tr[{ind}]/td\").text.strip()\n",
    "            info[key] = val\n",
    "            ind += 1\n",
    "        except:\n",
    "            success = False\n",
    "    return info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "def searchLocationString(name_type, town, county, state):\n",
    "    \"\"\"\n",
    "    Function that creates the location string for the Ancestry.com search page\n",
    "    :param name_type: type of name we are searching for (town, county, state)\n",
    "    :param town: town name\n",
    "    :param county: county name\n",
    "    :param state: state name\n",
    "    :return: location string\n",
    "    \"\"\"\n",
    "\n",
    "    # county name should not have County in it, must be formatted in a certain way\n",
    "    if not pd.isnull(county):\n",
    "        county = county.replace('County', '').strip().replace(' ', '+').replace('\\'', '+').lower()\n",
    "    # connect different parts of name, add necessary suffixes\n",
    "    if name_type == \"town\":\n",
    "        return town.lower() + \"-\" + county + \"-\" + statedict[state].lower() + \"-usa\"\n",
    "    elif name_type == \"county\":\n",
    "        return county + \"-\" + statedict[state].lower() + \"-usa\"\n",
    "    elif name_type == \"state\" or name_type == \"state_flag\":\n",
    "        return statedict[state] + \"-usa\"\n",
    "    else:\n",
    "        return \"usa\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "def addToResult(res, fn, ln, search_town, search_county, search_state, name_type):\n",
    "    \"\"\"\n",
    "    Function that adds parameters to the result dictionary\n",
    "\n",
    "    :param res: result dictionary\n",
    "    :param fn: first name\n",
    "    :param ln: last name\n",
    "    :param search_town: town name\n",
    "    :param search_county: county name\n",
    "    :param search_state: state name\n",
    "    :param name_type: type of name we are searching for (town, county, state)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    res['First Name'] = fn\n",
    "    res['Last Name'] = ln\n",
    "    res['Search Town'] = search_town\n",
    "    res['Search County'] = search_county\n",
    "    res['Search State'] = search_state\n",
    "    res['Name Type'] = name_type\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [],
   "source": [
    "def parseResult(res, df_list, match_list):\n",
    "    \"\"\"\n",
    "    Function that parses the result dictionary and adds the results to df_list, match_list\n",
    "\n",
    "    :param res: result dictionary\n",
    "    :param df_list: dataframe that contains all of the people we searched for\n",
    "    :param match_list: database of results from ancestry.com that people are linked to\n",
    "    :return: df_list, match_list with res added in\n",
    "    \"\"\"\n",
    "\n",
    "    # if there is at least one potential match, we want to see how many there are\n",
    "    if 'No Match' not in res['Match Status']:\n",
    "        # find number of matches\n",
    "        i = 1\n",
    "        pres = True\n",
    "        while pres:\n",
    "            try:\n",
    "                res[f'Match {i}']\n",
    "                i += 1\n",
    "            except:\n",
    "                pres = False\n",
    "        # iterate through all matches, add the corresponding match information in res to match_list\n",
    "        match_inds = []\n",
    "        for j in range(1, i):\n",
    "            match_list = pd.concat([match_list, pd.DataFrame(res[f'Match {j}'].copy(), index=[0])]).reset_index(\n",
    "                drop=True)\n",
    "            match_inds.append(str(match_list.shape[0] - 1))\n",
    "            del res[f'Match {j}']\n",
    "        res['Match Index'] = \" | \".join(match_inds) if len(match_inds) > 1 else match_inds[0]\n",
    "    # add person in res to df_list\n",
    "    df_list = pd.concat([df_list, pd.DataFrame(res, index=[0])]).reset_index(drop=True)\n",
    "\n",
    "    return df_list, match_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "def verifyNoMatch(driver, res):\n",
    "    \"\"\"\n",
    "    Function that verifies that there is no match for a person on ancestry.com\n",
    "\n",
    "    :param driver: selenium web scraper driver\n",
    "    :param res: url of our research result\n",
    "    :return: whether there is actually a result\n",
    "    \"\"\"\n",
    "    driver.get(res['url'])\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, \"//*[@id=\\\"results-footer\\\"]/h3\").text\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\ndf_list_og = pd.DataFrame(columns = ['First Name', 'Last Name', 'Search Town', 'Search County', 'Search State', 'Name Type', 'url', 'Match Index', 'Match Status'])\\nmatch_list_og = pd.DataFrame(columns = ['Name', 'Home in 1790 (City, County, State)', 'Free White Persons - Males - 16 and over', 'Free White Persons - Females', 'Number of Household Members'])\\nlocationsuffix = dict()\""
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structures that store our data\n",
    "\"\"\"\n",
    "df_list_og = pd.DataFrame(columns = ['First Name', 'Last Name', 'Search Town', 'Search County', 'Search State', 'Name Type', 'url', 'Match Index', 'Match Status'])\n",
    "match_list_og = pd.DataFrame(columns = ['Name', 'Home in 1790 (City, County, State)', 'Free White Persons - Males - 16 and over', 'Free White Persons - Females', 'Number of Household Members'])\n",
    "locationsuffix = dict()\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "locationsuffix['Littleton, Middlesex County, Massachusetts'] = 4534"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5s/dvrxt95949x1pm_sjxm85lj00000gn/T/ipykernel_20346/316541429.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# iterate through all individuals and try to find ancestry.com data for them\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# set selenium driver\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mdriver\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwebdriver\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSafari\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexecutable_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34mr'/usr/bin/safaridriver'\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m#set driver\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;31m# login details for uchicago server authentication\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0muser\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"Chris\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/selenium/webdriver/safari/webdriver.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, port, executable_path, reuse_service, desired_capabilities, quiet, keep_alive, service_args, options, service)\u001B[0m\n\u001B[1;32m     91\u001B[0m                                           keep_alive=keep_alive)\n\u001B[1;32m     92\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 93\u001B[0;31m         super().__init__(\n\u001B[0m\u001B[1;32m     94\u001B[0m             \u001B[0mcommand_executor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mexecutor\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m             \u001B[0moptions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001B[0m\n\u001B[1;32m    275\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_authenticator_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    276\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_client\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 277\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_session\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcapabilities\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbrowser_profile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    278\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    279\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001B[0m in \u001B[0;36mstart_session\u001B[0;34m(self, capabilities, browser_profile)\u001B[0m\n\u001B[1;32m    368\u001B[0m         \u001B[0mw3c_caps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_make_w3c_caps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcapabilities\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    369\u001B[0m         \u001B[0mparameters\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"capabilities\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mw3c_caps\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 370\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCommand\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNEW_SESSION\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparameters\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    371\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'sessionId'\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    372\u001B[0m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'value'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, driver_command, params)\u001B[0m\n\u001B[1;32m    431\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    432\u001B[0m         \u001B[0mparams\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_wrap_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 433\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcommand_executor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdriver_command\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    434\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    435\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheck_response\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, command, params)\u001B[0m\n\u001B[1;32m    342\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdump_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    343\u001B[0m         \u001B[0murl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"{self._url}{path}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 344\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand_info\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    345\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    346\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py\u001B[0m in \u001B[0;36m_request\u001B[0;34m(self, method, url, body)\u001B[0m\n\u001B[1;32m    364\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    365\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeep_alive\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 366\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    367\u001B[0m             \u001B[0mstatuscode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    368\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/urllib3/request.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001B[0m\n\u001B[1;32m     76\u001B[0m             )\n\u001B[1;32m     77\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m             return self.request_encode_body(\n\u001B[0m\u001B[1;32m     79\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfields\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfields\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mheaders\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0murlopen_kw\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m             )\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/urllib3/request.py\u001B[0m in \u001B[0;36mrequest_encode_body\u001B[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001B[0m\n\u001B[1;32m    168\u001B[0m         \u001B[0mextra_kw\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murlopen_kw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 170\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mextra_kw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/urllib3/poolmanager.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(self, method, url, redirect, **kw)\u001B[0m\n\u001B[1;32m    373\u001B[0m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    374\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 375\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mu\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest_uri\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    376\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    377\u001B[0m         \u001B[0mredirect_location\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mredirect\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_redirect_location\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    697\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    698\u001B[0m             \u001B[0;31m# Make the request on the httplib connection object.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 699\u001B[0;31m             httplib_response = self._make_request(\n\u001B[0m\u001B[1;32m    700\u001B[0m                 \u001B[0mconn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    443\u001B[0m                     \u001B[0;31m# Python 3 (including for exceptions like SystemExit).\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    444\u001B[0m                     \u001B[0;31m# Otherwise it looks like a bug in the code.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 445\u001B[0;31m                     \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    446\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSocketError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    447\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_raise_timeout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mread_timeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/urllib3/packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    438\u001B[0m                 \u001B[0;31m# Python 3\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    439\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 440\u001B[0;31m                     \u001B[0mhttplib_response\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetresponse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    441\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m                     \u001B[0;31m# Remove the TypeError from the exception chain in\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36mgetresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1347\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1348\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1349\u001B[0;31m                 \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbegin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1350\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1351\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36mbegin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    314\u001B[0m         \u001B[0;31m# read until we get a non-100 response\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    315\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 316\u001B[0;31m             \u001B[0mversion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstatus\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreason\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    317\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mstatus\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mCONTINUE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    318\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36m_read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    276\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 277\u001B[0;31m         \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_MAXLINE\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"iso-8859-1\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    278\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0m_MAXLINE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    279\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mLineTooLong\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"status line\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    703\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 704\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    705\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    706\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_timeout_occurred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# iterate through all individuals and try to find ancestry.com data for them\n",
    "# set selenium driver\n",
    "driver = webdriver.Safari(executable_path=r'/usr/bin/safaridriver')  #set driver\n",
    "# login details for uchicago server authentication\n",
    "if user == \"Chris\":\n",
    "    file = pd.read_csv('~/Desktop/login_details.txt')\n",
    "# get login information\n",
    "username = file.columns[0]\n",
    "password = file[username].tolist()[0]\n",
    "# navigate to url\n",
    "driver.set_window_size(1000, 700)\n",
    "driver.get(\"http://www.lib.uchicago.edu/h/ancestry\")\n",
    "# login to uchicago server\n",
    "WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.ID, \"okta-signin-username\"))).send_keys(username)\n",
    "time.sleep(1)\n",
    "driver.find_element(by=By.ID, value=\"okta-signin-password\").send_keys(password)\n",
    "time.sleep(5)\n",
    "# click on login button\n",
    "driver.find_element(by=By.ID, value=\"okta-signin-submit\").click()  #sign in\n",
    "# click on duo authentication button\n",
    "time.sleep(10)\n",
    "WebDriverWait(driver, 100).until(\n",
    "    EC.frame_to_be_available_and_switch_to_it((By.XPATH, \"//*[@id=\\\"form62\\\"]/div/div[2]/iframe\")))\n",
    "WebDriverWait(driver, 100).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//*[@id=\\\"auth_methods\\\"]/fieldset/div[1]/button\"))).click()\n",
    "\n",
    "# wait for page to load\n",
    "time.sleep(17)\n",
    "\n",
    "# specify name match and location match options\n",
    "for index in final_name_list.index:\n",
    "    \"\"\"if index < 4401: #3606:\n",
    "        continue\"\"\"\n",
    "    # save our data after each run\n",
    "    df_list_og.to_csv('scrape_tools/scrape_ids_prelim.csv')\n",
    "    match_list_og.to_csv('scrape_tools/scrape_results_prelim.csv')\n",
    "\n",
    "    # obtain attributes of data we want to use to search\n",
    "    fn = final_name_list.loc[index, 'Fn_Fix']\n",
    "    ln = final_name_list.loc[index, 'Ln_Fix']\n",
    "    search_town = final_name_list.loc[index, 'new_town']\n",
    "    search_county = final_name_list.loc[index, 'county']\n",
    "    search_state = final_name_list.loc[index, 'new_state']\n",
    "    name_type = final_name_list.loc[index, 'name_type']\n",
    "\n",
    "    if name_type != \"country\":\n",
    "        # transform information into searchable params\n",
    "        searchparams = determineMatchList(name_type, search_state)\n",
    "        location = processLocationString(name_type, search_town, search_county, search_state)\n",
    "        # distinguish between names that correspond to multiple real names vs. just one name\n",
    "        if type(fn) != str:\n",
    "            fn = \"\"\n",
    "        name = fn + \" \" + ln\n",
    "        print(f\"Searching for {name} that lived in {location}\")\n",
    "\n",
    "        # if matching one time fails, retry (up to 8 times)\n",
    "        # when matching fails its likely a bug\n",
    "        match = False\n",
    "        tries = 0\n",
    "        while not match and tries < 8:\n",
    "            try:\n",
    "                res = findMatches(fn, ln, driver, search_town, search_county, search_state, name_type)\n",
    "                while res['Match Status'] == 'No Match' and verifyNoMatch(driver, res):\n",
    "                    print(\"Need to obtain information again\")\n",
    "                    res = findMatches(fn, ln, driver, search_town, search_county, search_state, name_type)\n",
    "                match = True\n",
    "            except:\n",
    "                print(\"trying again\")\n",
    "                tries += 1\n",
    "                pass\n",
    "\n",
    "        print(tries, res)\n",
    "        # transform our result and add it to our dataframes\n",
    "        res = addToResult(res, fn, ln, search_town, search_county, search_state, name_type)\n",
    "        df_list_og, match_list_og = parseResult(res, df_list_og, match_list_og)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"df_rescrape = df_list_og[df_list_og['Match Status'] == 'No Match'][['First Name', 'Last Name', 'Search Town', 'Search County', 'Search State', 'Name Type']]\n",
    "df_rescrape.columns = ['Fn_Fix', 'Ln_Fix', 'new_town', 'county', 'new_state', 'name_type']\n",
    "df_rescrape.drop([ele for ele in df_rescrape.index if ele >= 4101])\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "# create copies of our dataframe before we edit them\n",
    "match_list = match_list_og.copy()\n",
    "df_list = df_list_og.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "# correct matches for certain people who we know for sure the match is wrong for\n",
    "df_list.loc[df_list[df_list['First Name'] + df_list['Last Name'] == 'AnnCook'].index,\n",
    "               ['Match Index', 'Match Status']] = [np.nan, 'No Match']\n",
    "df_list.loc[df_list[df_list['First Name'] + df_list['Last Name'] == 'AnnFromberger'].index,\n",
    "               ['Match Index', 'Match Status']] = [np.nan, 'No Match']\n",
    "df_list.loc[df_list[df_list['First Name'] + df_list['Last Name'] == 'JaneOlmsted'].index,\n",
    "               ['Match Index', 'Match Status']] = [np.nan, 'No Match']\n",
    "\n",
    "# there are some places where we have duplicates, drop these\n",
    "# particular idiosyncracy related to our matching this time\n",
    "ben_bosw_drop = df_list[df_list['First Name'] + \" \" + df_list['Last Name'] + df_list['Match Status'] == \"Benjamin Bosworth3 Potential Matches Found\"].index\n",
    "df_list.drop(ben_bosw_drop, inplace=True)\n",
    "\n",
    "rwaterman = df_list[df_list['First Name'] + \" \" + df_list['Last Name'] + df_list['Match Status'] == \"Richard WatermanNo Match\"].index\n",
    "df_list.drop(rwaterman, inplace=True)\n",
    "\n",
    "warnold = df_list[df_list['First Name'] + \" \" + df_list['Last Name'] + df_list['Match Status'] == \"William ArnoldNo Match\"].index\n",
    "df_list.drop(warnold, inplace=True)\n",
    "\n",
    "wpotter = df_list[df_list['First Name'] + \" \" + df_list['Last Name'] + df_list['Match Status'] == \"William PotterNo Match\"].index\n",
    "df_list.drop(wpotter, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "# remove indices from match dataframe if that match is not in our dataframe\n",
    "inds = df_list['Match Index'].apply(lambda x: str(x).split(\" | \") if not pd.isnull(x) else [0]).explode().apply(lambda x: int(x)).drop_duplicates().tolist()\n",
    "match_list = match_list.loc[inds]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "# make manual changes to some entries where the scraper bugged out\n",
    "match_list.loc[match_list[match_list['Home in 1790 (City, County, State)'].isnull()].index, ['Home in 1790 (City, County, State)', 'Free White Persons - Females', 'Number of Household Members']] = ['Philadelphia City, Philadelphia, Pennsylvania', 2, 2]\n",
    "match_list.loc[match_list[match_list['Name'].apply(lambda x: 'Rebecca Ha' in x)].index, 'Home in 1790 (City, County, State)'] = 'Sherburn, Nantucket, Massachusetts, USA'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "# Reformat names properly - some have brackets, too many new line or tab characters\n",
    "brack_ind = match_list[match_list['Name'].apply(lambda x: \"[\" in x and \"\\n\" not in x)].index\n",
    "match_list.loc[brack_ind, 'Name'] = match_list.loc[brack_ind, 'Name'].apply(\n",
    "    lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "space_ind = match_list[match_list['Name'].apply(lambda x: '\\n' in x)].index\n",
    "match_list.loc[space_ind, 'Name'] = match_list.loc[space_ind, 'Name'].apply(\n",
    "    lambda x: x.replace('\\n', ' ').replace('\\t', '').replace('[', '| ').replace(']', '').replace('  ', ''))\n",
    "\n",
    "# Add information about the town, county, state and type of our match\n",
    "match_list['Match Type'] = match_list['Home in 1790 (City, County, State)'].apply(\n",
    "    lambda x: 'town' if len(x.split(\", \")) == 3 else 'county' if len(x.split(\", \")) == 2 else 'state' if len(\n",
    "        x.split(\", \")) == 1 else 'state')\n",
    "match_list['Match Town'] = match_list.apply(\n",
    "    lambda x: x['Home in 1790 (City, County, State)'].split(\", \")[0] if x['Match Type'] == 'town' else np.nan, axis=1)\n",
    "match_list['Match County'] = match_list.apply(\n",
    "    lambda x: x['Home in 1790 (City, County, State)'].split(\", \")[1] + \" County\" if x['Match Type'] == 'town' else\n",
    "    x['Home in 1790 (City, County, State)'].split(\", \")[0] + \" County\" if x['Match Type'] == 'county' else np.nan,\n",
    "    axis=1)\n",
    "match_list['Match State'] = match_list.apply(lambda x: x['Home in 1790 (City, County, State)'].split(\", \")[-1], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "# manually edit two entry types since they cannot be parsed by our earlier commands\n",
    "match_list.loc[match_list[match_list['Home in 1790 (City, County, State)'] == 'Hopewell, Newton, Tyborn, and Westpensboro, Cumberland, Pennsylvania'].index, ['Match Town', 'Match County', 'Match State', 'Match Type']] = ['Hopewell, Newton, Tyborn and Westpensboro', 'Cumberland County', 'Pennsylvania', 'town']\n",
    "match_list.loc[match_list[match_list['Home in 1790 (City, County, State)'] == 'Fannet, Hamilton, Letterkenney, Montgomery, and Peters, Franklin, Pennsylvania'].index, ['Match Town', 'Match County', 'Match State', 'Match Type']] = ['Fannet, Hamilton, Letterkenney, Montgomery and Peters', 'Franklin County', 'Pennsylvania', 'town']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5s/dvrxt95949x1pm_sjxm85lj00000gn/T/ipykernel_20346/1096089481.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  match_list_no_dup.rename({'index_old': 'index_temp'}, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# next, we want to remove entries in match_list that are duplicated, and create a dictionary that maps the old indices in df_list to the new indices, after we drop duplicates in match_list\n",
    "\n",
    "# save old index\n",
    "match_list['index_old'] = match_list.index\n",
    "# drop duplicates, create temporary index column\n",
    "match_list_no_dup = match_list.drop_duplicates(subset=[ele for ele in match_list.columns if ele != 'index_old'])\n",
    "match_list_no_dup.rename({'index_old': 'index_temp'}, axis=1, inplace=True)\n",
    "\n",
    "# create mapping between old index, and temporary new index\n",
    "# the temporary new index removes indices of repeated values without renumbering anything\n",
    "match_dict_df = pd.merge(match_list.reset_index(),\n",
    "                         match_list_no_dup,\n",
    "                         how='left').set_index('index')\n",
    "match_dict_df['index_old'] = match_dict_df.index\n",
    "\n",
    "# now, we want to renumber the temporary index so that it is sequential and doesn't skip any numbers\n",
    "# we call this the new index\n",
    "gen_newind = match_dict_df[['index_temp']].drop_duplicates().reset_index(drop=True).copy()\n",
    "gen_newind['index_new'] = gen_newind.index\n",
    "# merge in new index to merged dataframe, map old index to new index\n",
    "match_dict_df = pd.merge(match_dict_df, gen_newind)\n",
    "match_dict = dict(zip(match_dict_df['index_old'], match_dict_df['index_new']))\n",
    "\n",
    "# change from old indices to new indices in df_list dataframe\n",
    "df_list['Match Index'] = df_list['Match Index'].apply(\n",
    "    lambda x: tNameList([str(match_dict[int(ele)]) for ele in x.split(' | ')]) if not pd.isnull(x) else x)\n",
    "# change match_list dataframe so that it removes duplicates and is indexed by the new index method\n",
    "match_list = pd.merge(match_list_no_dup, gen_newind)\n",
    "match_list['index_new'] = match_list['index_new'].apply(lambda x: str(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "# correct times where two people matched to the same individual but they have the same info/are likely the same\n",
    "# caused by our reindex scheme, does not occur frequently\n",
    "double_rep_ind = df_list[df_list.apply(lambda x: (not pd.isnull(x['Match Index']) and ' | ' not in x['Match Index'])\n",
    "                                                 and x['Match Status'] not in ['Complete Match', 'Poor Match'],\n",
    "                                       axis=1)].index\n",
    "df_list.loc[double_rep_ind, 'Match Status'] = 'Complete Match'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "# export our results\n",
    "pd.merge(final_name_list, df_list.drop_duplicates(),\n",
    "         how='left',\n",
    "         left_on=['Fn_Fix', 'Ln_Fix', 'new_town', 'county', 'new_state', 'name_type'],\n",
    "         right_on=['First Name', 'Last Name', 'Search Town', 'Search County', 'Search State', 'Name Type']).to_csv('scrape_tools/name_list_scraped.csv')\n",
    "\n",
    "df_list.to_csv('scrape_tools/scrape_ids.csv')\n",
    "match_list.to_csv('scrape_tools/scrape_results.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"# in cases where we have 2/3/4 potential matches, create a dataframe where each individual who has \"n\" potential matches is linked to each of those matches\n",
    "mult_matches = df_list[\n",
    "    df_list['Match Status'].apply(lambda x: ('2' in x or '3' in x or '4' in x) and 'Too Many' not in x)].index\n",
    "# generate dataframe where each individual with multiple matches is repeated for each of their matches\n",
    "mult_df = pd.DataFrame(np.repeat(df_list.loc[mult_matches].values,\n",
    "                                 df_list.loc[mult_matches, 'Match Index'].apply(lambda x: len(x.split(\" | \"))).values,\n",
    "                                 axis=0),\n",
    "                       columns=df_list.columns)\n",
    "# turn np.nan into \"\" so we can use group by\n",
    "mult_df['Search Town'] = mult_df['Search Town'].apply(lambda x: \"\" if pd.isnull(x) else x)\n",
    "mult_df['Search County'] = mult_df['Search County'].apply(lambda x: \"\" if pd.isnull(x) else x)\n",
    "# see how many different potential matches an entry in df_list has\n",
    "mult_df['count'] = mult_df.index\n",
    "mult_df['count'] = mult_df.groupby([ele for ele in mult_df.columns if ele != 'count']).cumcount()\n",
    "# create a column that has one single match that each individual is linked to, out of all potential matches\n",
    "mult_df['Match Index Single'] = mult_df.apply(lambda x: x['Match Index'].split(\" | \")[int(x['count'])], axis=1)\n",
    "# merge with match dataframe\n",
    "merged_df = pd.merge(mult_df, match_list,\n",
    "                       how='left', left_on='Match Index Single', right_on='index_new')\n",
    "# replace NA with \"\"\n",
    "all_mult_df[['Search Town', 'Search County', 'Match Town', 'Match County']] = all_mult_df[\n",
    "    ['Search Town', 'Search County', 'Match Town', 'Match County']].fillna(\"\")\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"# now, we want to see how many of these matches are actually good matches, based on whether our given locations match with the ancestry.com locations and when necessary copmaring names\n",
    "# good match list\n",
    "strong_mult_match = pd.concat([\n",
    "    # town and county match\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] == x['Match Town'], axis=1)],\n",
    "    # only reason why town doesn't match is because we don't have town info from ancestry.com\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] != x['Match Town'] and x['Match Town'] == \"\", axis=1)],\n",
    "    # county match, town doesn't match exactly but mainly due to naming differences, not incorrect matching\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] != x['Match Town'] and x['Match Town'] != \"\" and x['Search Town'] in x['Match Town'], axis=1)],\n",
    "    # different town, same county, but our search name matches the ancestry.com name perectly\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] != x['Match Town'] and x['Match Town'] != \"\" and x['Search Town'] not in x['Match Town'] and (x['First Name'] + \" \" + x['Last Name'] in x['Name']), axis=1)],\n",
    "    # results here likely appear because of my mistake with town-county assignments\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] == x['Match Town'] and x['Match Town'] != \"\", axis=1)],\n",
    "    # both results have the same state, and we only had state information to begin with for our search. here, we have max county information for our matches\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] == x['Match Town'] and x['Match Town'] == \"\" and x['Search County'] == \"\" and statedict[x['Search State']] == x['Match State'], axis=1)],\n",
    "    # both results have the same state, and we only had state information to begin with for our search. here, we have town information for our matches, and our search name matches the ancestry.com name perfectly\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'state' and statedict[x['Search State']] == x['Match State'] and (x['First Name'] + \" \" + x['Last Name'] in x['Name']), axis=1)]\n",
    "]).index\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"# medium match strength\n",
    "pd.concat([\n",
    "    # only have state information for search and match + the state matches, but search and ancestry.com names differ slightly\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'state' and statedict[x['Search State']] == x['Match State'] and (x['First Name'] + \" \" + x['Last Name'] not in x['Name']), axis=1)],\n",
    "    # different town, same county, but name doesn't match well\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] != x['Match Town'] and x['Match Town'] != \"\" and x['Search Town'] not in x['Match Town'] and (x['First Name'] + \" \" + x['Last Name'] not in x['Name']), axis=1)],\n",
    "    # search and match have different counties, when the most amount of information we have is county level data\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'county', axis=1)],\n",
    "    # search and match have different counties, when the most amount of information we have is town level data - search and ancestry.com names match up but will doublecheck just to be sure\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'town' and (x['First Name'] + \" \" + x['Last Name'] in x['Name']), axis=1)],\n",
    "    # search and match have different counties, when the most amount of information we have is town level data - also search and ancestry.com names do not match up\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'town' and (x['First Name'] + \" \" + x['Last Name'] not in x['Name']), axis=1)]\n",
    "])\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    # different state, begs investigation\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] == x['Match Town'] and x['Match Town'] == \"\" and x['Search County'] == \"\" and statedict[x['Search State']] != x['Match State'], axis=1)],\n",
    "    # different county (for sure, might even have different state) - begs investigation\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] == x['Match Town'] and x['Match Town'] == \"\" and x['Search County'] != \"\", axis=1)],\n",
    "    # only have state information for search and match but the state does not match\n",
    "    all_mult_df[all_mult_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'state' and statedict[x['Search State']] != x['Match State'], axis=1)],\n",
    "])[['First Name', 'Last Name', 'Search Town', 'Search County', 'Search State',  'Name', 'Home in 1790 (City, County, State)', 'index_new']]\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"merged_df = pd.merge(df_list[df_list['Match Status'].apply(lambda x: x == 'Complete Match')],\n",
    "                     match_list,\n",
    "                     left_on='Match Index',\n",
    "                     right_on='index_new')\n",
    "merged_df[['Search Town', 'Search County', 'Match Town', 'Match County']] = merged_df[\n",
    "    ['Search Town', 'Search County', 'Match Town', 'Match County']].fillna(\"\")\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"# now, we want to see how many of these matches are actually good matches, based on whether our given locations match with the ancestry.com locations and when necessary copmaring names\n",
    "# good match list\n",
    "\n",
    "pd.concat([\n",
    "    # town and county match\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] == x['Match Town'], axis=1)],\n",
    "    # only reason why town doesn't match is because we don't have town info from ancestry.com\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] != x['Match Town'] and x['Match Town'] == \"\", axis=1)],\n",
    "    # county match, town doesn't match exactly but mainly due to naming differences, not incorrect matching\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] != x['Match Town'] and x['Match Town'] != \"\" and x['Search Town'] in x['Match Town'], axis=1)],\n",
    "    # different town, same county, but our search name matches the ancestry.com name perectly\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] != x['Match Town'] and x['Match Town'] != \"\" and x['Search Town'] not in x['Match Town'] and (x['First Name'] + \" \" + x['Last Name'] in x['Name']), axis=1)],\n",
    "    # results here likely appear because of my mistake with town-county assignments\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] == x['Match Town'] and x['Match Town'] != \"\", axis=1)],\n",
    "    # both results have the same state, and we only had state information to begin with for our search. here, we have max county information for our matches\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] == x['Match Town'] and x['Match Town'] == \"\" and x['Search County'] == \"\" and statedict[x['Search State']] == x['Match State'], axis=1)],\n",
    "    # both results have the same state, and we only had state information to begin with for our search. here, we have town information for our matches, and our search name matches the ancestry.com name perfectly\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'state' and statedict[x['Search State']] == x['Match State'] and (x['First Name'] + \" \" + x['Last Name'] in x['Name']), axis=1)]\n",
    "])\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"# poor match list - need to inspect\n",
    "pd.concat([\n",
    "    # different town, same county, but name doesn't match well\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] == x['Match County'] and x['Search Town'] != x['Match Town'] and x['Match Town'] != \"\" and x['Search Town'] not in x['Match Town'] and (x['First Name'] + \" \" + x['Last Name'] not in x['Name']), axis=1)],\n",
    "    # different state, begs investigation\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] == x['Match Town'] and x['Match Town'] == \"\" and x['Search County'] == \"\" and statedict[x['Search State']] != x['Match State'], axis=1)],\n",
    "    # different county (for sure, might even have different state) - begs investigation\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] == x['Match Town'] and x['Match Town'] == \"\" and x['Search County'] != \"\", axis=1)],\n",
    "    # only have state information for search and match + the state matches, but search and ancestry.com names differ slightly\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'state' and statedict[x['Search State']] == x['Match State'] and (x['First Name'] + \" \" + x['Last Name'] not in x['Name']), axis=1)],\n",
    "    # only have state information for search and match but the state does not match\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'state' and statedict[x['Search State']] != x['Match State'], axis=1)],\n",
    "    # search and match have different counties, when the most amount of information we have is county level data\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'county', axis=1)],\n",
    "    # search and match have different counties, when the most amount of information we have is town level data - search and ancestry.com names match up but will doublecheck just to be sure\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'town' and (x['First Name'] + \" \" + x['Last Name'] in x['Name']), axis=1)],\n",
    "    # search and match have different counties, when the most amount of information we have is town level data - also search and ancestry.com names do not match up\n",
    "    merged_df[merged_df.apply(lambda x: x['Search County'] != x['Match County'] and x['Search Town'] != x['Match Town'] and x['Name Type'] == 'town' and (x['First Name'] + \" \" + x['Last Name'] not in x['Name']), axis=1)]\n",
    "])[['First Name', 'Last Name', 'Search Town', 'Search County', 'Search State',  'Name', 'Home in 1790 (City, County, State)', 'index_new']].to_csv('clean_tools/perf_match_check.csv')\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"pd.merge(final_name_list, df_list,\n",
    "         how='left',\n",
    "         left_on=['Fn_Fix', 'Ln_Fix', 'new_town', 'county', 'new_state', 'name_type'],\n",
    "         right_on=['First Name', 'Last Name', 'Search Town', 'Search County', 'Search State', 'Name Type'])\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}