{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4715,
   "id": "60c1ab43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: rapidfuzz in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (3.13.0)\n",
      "Requirement already satisfied: python-Levenshtein in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (0.27.1)\n",
      "Requirement already satisfied: Levenshtein==0.27.1 in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (from python-Levenshtein) (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /opt/anaconda3/envs/pandas/lib/python3.12/site-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n"
     ]
    }
   ],
   "source": [
    "import pip\n",
    "!pip install pandas\n",
    "!pip install rapidfuzz\n",
    "from rapidfuzz import process\n",
    "from rapidfuzz import fuzz\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4716,
   "id": "0082a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4717,
   "id": "e6ef7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790VA = pd.read_csv('VA_ASD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4718,
   "id": "2a80e230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "914    False\n",
      "915    False\n",
      "916    False\n",
      "917    False\n",
      "918    False\n",
      "Length: 919, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "VA_mask_strange_date =  (\n",
    "    (pd.to_numeric(post1790VA['Def_6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790VA['6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790VA['3p_Day'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {VA_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4719,
   "id": "5230f960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "914    False\n",
      "915    False\n",
      "916    False\n",
      "917    False\n",
      "918    False\n",
      "Length: 919, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "VA_mask_strange_month =  (\n",
    "    (pd.to_numeric(post1790VA['Def_6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790VA['6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790VA['3p_Month'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {VA_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4720,
   "id": "f672eef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years under 1790: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "914    False\n",
      "915    False\n",
      "916    False\n",
      "917    False\n",
      "918    False\n",
      "Length: 919, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values under 1790\n",
    "VA_mask_strange_year =  (\n",
    "    (pd.to_numeric(post1790VA['Def_6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790VA['6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790VA['3p_Year'], errors='coerce') <1790)\n",
    ")\n",
    "print(f'\\nAmount of years under 1790: {VA_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14828266",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4721,
   "id": "8b6de556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column   Original      Match      Score\n",
      "0   6p_First_Name    Matthew     Mathew  92.307692\n",
      "1   6p_First_Name     Mathew    Matthew  92.307692\n",
      "2    6p_Last_Name     Stuart    Steuart  92.307692\n",
      "3    6p_Last_Name    Steuart     Stuart  92.307692\n",
      "4    6p_Last_Name    Philips   Phillips  93.333333\n",
      "..            ...        ...        ...        ...\n",
      "93   3p_Last_Name   Donaldon  Donaldson  94.117647\n",
      "94   3p_Last_Name   Phillips    Philips  93.333333\n",
      "95   3p_Last_Name  Dandridge   Dandrige  94.117647\n",
      "96   3p_Last_Name    Goodwin     Godwin  92.307692\n",
      "97   3p_Last_Name   Walllace    Wallace  93.333333\n",
      "\n",
      "[98 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "VA_columns_to_check = ['6p_First_Name', '6p_Last_Name', 'Def_6p_First_Name', 'Def_6p_Last_Name', '3p_First_Name', '3p_Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in VA_columns_to_check:\n",
    "    VA_unique_vals = post1790VA[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in VA_unique_vals:\n",
    "        result = process.extract(val, VA_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "VA_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(VA_fuzzy_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4722,
   "id": "78256c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790SC = pd.read_csv('Post_1790_South_Carolina_CD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4723,
   "id": "57ebd14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "434    False\n",
      "435    False\n",
      "436    False\n",
      "437    False\n",
      "438    False\n",
      "Length: 439, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "SC_mask_strange_date =  (\n",
    "    (pd.to_numeric(post1790SC['Def_6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790SC['6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790SC['3p_Day'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {SC_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4724,
   "id": "b0624640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "434    False\n",
      "435    False\n",
      "436    False\n",
      "437    False\n",
      "438    False\n",
      "Length: 439, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "SC_mask_strange_month =  (\n",
    "    (pd.to_numeric(post1790SC['Def_6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790SC['6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790SC['3p_Month'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {SC_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4725,
   "id": "f57618be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years under 1790: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "434    False\n",
      "435    False\n",
      "436    False\n",
      "437    False\n",
      "438    False\n",
      "Length: 439, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values under 1790\n",
    "SC_mask_strange_year =  (\n",
    "    (pd.to_numeric(post1790SC['Def_6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790SC['6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790SC['3p_Year'], errors='coerce') <1790)\n",
    ")\n",
    "print(f'\\nAmount of years under 1790: {SC_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaad41b",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4726,
   "id": "8d867ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Column  Original     Match       Score\n",
      "0       6p_First_Name   William  Williams   93.333333\n",
      "1       6p_First_Name  Williams   William   93.333333\n",
      "2       6p_First_Name      John     John   100.000000\n",
      "3       6p_First_Name   Daniel     Daniel  100.000000\n",
      "4       6p_First_Name    Daniel   Daniel   100.000000\n",
      "5       6p_First_Name    Mathew   Mathew   100.000000\n",
      "6       6p_First_Name   Mathew     Mathew  100.000000\n",
      "7       6p_First_Name     John       John  100.000000\n",
      "8        6p_Last_Name     Mason    Manson   90.909091\n",
      "9        6p_Last_Name   Johnson  Johnston   93.333333\n",
      "10       6p_Last_Name    McCall   McCalla   92.307692\n",
      "11       6p_Last_Name    Manson     Mason   90.909091\n",
      "12       6p_Last_Name  Johnston   Johnson   93.333333\n",
      "13       6p_Last_Name   McCalla    McCall   92.307692\n",
      "14  Def_6p_First_Name   William  Williams   93.333333\n",
      "15  Def_6p_First_Name  Williams   William   93.333333\n",
      "16  Def_6p_First_Name      John     John   100.000000\n",
      "17  Def_6p_First_Name   Daniel     Daniel  100.000000\n",
      "18  Def_6p_First_Name    Daniel   Daniel   100.000000\n",
      "19  Def_6p_First_Name    Mathew   Mathew   100.000000\n",
      "20  Def_6p_First_Name   Mathew     Mathew  100.000000\n",
      "21  Def_6p_First_Name     John       John  100.000000\n",
      "22   Def_6p_Last_Name     Mason    Manson   90.909091\n",
      "23   Def_6p_Last_Name   Johnson  Johnston   93.333333\n",
      "24   Def_6p_Last_Name    McCall   McCalla   92.307692\n",
      "25   Def_6p_Last_Name    Manson     Mason   90.909091\n",
      "26   Def_6p_Last_Name  Johnston   Johnson   93.333333\n",
      "27   Def_6p_Last_Name   McCalla    McCall   92.307692\n",
      "28      3p_First_Name   William  Williams   93.333333\n",
      "29      3p_First_Name  Williams   William   93.333333\n",
      "30      3p_First_Name      John     John   100.000000\n",
      "31      3p_First_Name   Daniel     Daniel  100.000000\n",
      "32      3p_First_Name    Daniel   Daniel   100.000000\n",
      "33      3p_First_Name    Mathew   Mathew   100.000000\n",
      "34      3p_First_Name   Mathew     Mathew  100.000000\n",
      "35      3p_First_Name     John       John  100.000000\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "post1790SC.columns = post1790SC.columns.str.strip()\n",
    "SC_columns_to_check = ['6p_First_Name', '6p_Last_Name', 'Def_6p_First_Name', 'Def_6p_Last_Name', '3p_First_Name', '3p_Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in SC_columns_to_check:\n",
    "    SC_unique_vals = post1790SC[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in SC_unique_vals:\n",
    "        result = process.extract(val, SC_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "SC_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(SC_fuzzy_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4727,
   "id": "d0e58e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790RI = pd.read_csv('T653_Rhode_Island_ASD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4728,
   "id": "56a55290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "291    False\n",
      "292    False\n",
      "293    False\n",
      "294    False\n",
      "295    False\n",
      "Length: 296, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "RI_mask_strange_date =  (\n",
    "    (pd.to_numeric(post1790RI['Def_6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790RI['6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790RI['3p_Day'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {RI_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4729,
   "id": "83923638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "291    False\n",
      "292    False\n",
      "293    False\n",
      "294    False\n",
      "295    False\n",
      "Length: 296, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "RI_mask_strange_month =  (\n",
    "    (pd.to_numeric(post1790RI['Def_6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790RI['6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790RI['3p_Month'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {RI_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4730,
   "id": "12ad2e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years under 1790: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "291    False\n",
      "292    False\n",
      "293    False\n",
      "294    False\n",
      "295    False\n",
      "Length: 296, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values under 1790\n",
    "RI_mask_strange_year =  (\n",
    "    (pd.to_numeric(post1790RI['Def_6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790RI['6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790RI['3p_Year'], errors='coerce') <1790)\n",
    ")\n",
    "print(f'\\nAmount of years under 1790: {RI_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b097d45",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4731,
   "id": "3926a12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Column                        Original  \\\n",
      "0   Def_6p_First_Name                            John   \n",
      "1   Def_6p_First_Name                      Cristopher   \n",
      "2   Def_6p_First_Name                     Christopher   \n",
      "3   Def_6p_First_Name                      Nicholas     \n",
      "4   Def_6p_First_Name                        Daniel C   \n",
      "5   Def_6p_First_Name                       Joseph      \n",
      "6   Def_6p_First_Name                       Daniel C    \n",
      "7   Def_6p_First_Name                          Joseph   \n",
      "8   Def_6p_First_Name                         John      \n",
      "9   Def_6p_First_Name                Brown and Bonson   \n",
      "10  Def_6p_First_Name                            Ann    \n",
      "11  Def_6p_First_Name                             Ann   \n",
      "12  Def_6p_First_Name                Brown and Benson   \n",
      "13  Def_6p_First_Name                        Nicholas   \n",
      "14   Def_6p_Last_Name                       Verplanck   \n",
      "15   Def_6p_Last_Name                       Verplanck   \n",
      "16      3p_First_Name  Pordon Tillinghast W Greenwich   \n",
      "17      3p_First_Name   Pardon Tillinghast W Greewich   \n",
      "18       3p_Last_Name                          Browne   \n",
      "19       3p_Last_Name                           Brown   \n",
      "\n",
      "                             Match       Score  \n",
      "0                          John     100.000000  \n",
      "1                      Christopher   95.238095  \n",
      "2                       Cristopher   95.238095  \n",
      "3                         Nicholas  100.000000  \n",
      "4                        Daniel C   100.000000  \n",
      "5                           Joseph  100.000000  \n",
      "6                         Daniel C  100.000000  \n",
      "7                        Joseph     100.000000  \n",
      "8                             John  100.000000  \n",
      "9                 Brown and Benson   93.750000  \n",
      "10                             Ann  100.000000  \n",
      "11                            Ann   100.000000  \n",
      "12                Brown and Bonson   93.750000  \n",
      "13                      Nicholas    100.000000  \n",
      "14                       Verplanck  100.000000  \n",
      "15                       Verplanck  100.000000  \n",
      "16   Pardon Tillinghast W Greewich   94.915254  \n",
      "17  Pordon Tillinghast W Greenwich   94.915254  \n",
      "18                           Brown   90.909091  \n",
      "19                          Browne   90.909091  \n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "RI_columns_to_check = ['6p_First_Name', '6p_Last_Name', 'Def_6p_First_Name', 'Def_6p_Last_Name', '3p_First_Name', '3p_Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in RI_columns_to_check:\n",
    "    RI_unique_vals = post1790RI[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in RI_unique_vals:\n",
    "        result = process.extract(val, RI_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "RI_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(RI_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4732,
   "id": "36b67828",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790PA = pd.read_csv('PA_post1790_CD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4733,
   "id": "27b40ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1297    False\n",
      "1298    False\n",
      "1299    False\n",
      "1300    False\n",
      "1301    False\n",
      "Length: 1302, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "PA_mask_strange_date =  (\n",
    "    (pd.to_numeric(post1790PA['Def_6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790PA['6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790PA['3p_Day'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {PA_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4734,
   "id": "f7661912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1297    False\n",
      "1298    False\n",
      "1299    False\n",
      "1300    False\n",
      "1301    False\n",
      "Length: 1302, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "PA_mask_strange_month =  (\n",
    "    (pd.to_numeric(post1790PA['Def_6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790PA['6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790PA['3p_Month'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {PA_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4735,
   "id": "9a98a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years under 1790: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1297    False\n",
      "1298    False\n",
      "1299    False\n",
      "1300    False\n",
      "1301    False\n",
      "Length: 1302, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values under 1790\n",
    "PA_mask_strange_year =  (\n",
    "    (pd.to_numeric(post1790PA['Def_6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790PA['6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790PA['3p_Year'], errors='coerce') <1790)\n",
    ")\n",
    "print(f'\\nAmount of years under 1790: {PA_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293811c0",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4736,
   "id": "7c02ef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Column  Original      Match       Score\n",
      "0    6p_First_Name   William   William   100.000000\n",
      "1    6p_First_Name    Jasper    Jasper   100.000000\n",
      "2    6p_First_Name    Robert    Robert   100.000000\n",
      "3    6p_First_Name     James     James   100.000000\n",
      "4    6p_First_Name  Margaret  Margarett   94.117647\n",
      "..             ...       ...        ...         ...\n",
      "265   3p_Last_Name    Ashton      Aston   90.909091\n",
      "266   3p_Last_Name    Wagner    Wagener   92.307692\n",
      "267   3p_Last_Name    Wagner      Wager   90.909091\n",
      "268   3p_Last_Name   Bennett     Bennet   92.307692\n",
      "269   3p_Last_Name   Johnson   Johnston   93.333333\n",
      "\n",
      "[270 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "PA_columns_to_check = ['6p_First_Name', '6p_Last_Name', 'Def_6p_First_Name', 'Def_6p_Last_Name', '3p_First_Name', '3p_Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in PA_columns_to_check:\n",
    "    PA_unique_vals = post1790PA[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in PA_unique_vals:\n",
    "        result = process.extract(val, PA_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "PA_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(PA_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4737,
   "id": "853202ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790NY = pd.read_csv('NY_1790_ASD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4738,
   "id": "eb7f0d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1466    False\n",
      "1467    False\n",
      "1468    False\n",
      "1469    False\n",
      "1470    False\n",
      "Length: 1471, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "NY_mask_strange_date =  (\n",
    "    (pd.to_numeric(post1790NY['Def_6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790NY['6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790NY['3p_Day'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {NY_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4739,
   "id": "45fa3018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1466    False\n",
      "1467    False\n",
      "1468    False\n",
      "1469    False\n",
      "1470    False\n",
      "Length: 1471, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "NY_mask_strange_month =  (\n",
    "    (pd.to_numeric(post1790NY['Def_6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790NY['6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790NY['3p_Month'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {NY_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4740,
   "id": "5ca45e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years under 1790: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1466    False\n",
      "1467    False\n",
      "1468    False\n",
      "1469    False\n",
      "1470    False\n",
      "Length: 1471, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values under 1790\n",
    "NY_mask_strange_year =  (\n",
    "    (pd.to_numeric(post1790NY['Def_6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790NY['6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790NY['3p_Year'], errors='coerce') <1790)\n",
    ")\n",
    "print(f'\\nAmount of years under 1790: {NY_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f77ea0c",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4741,
   "id": "b89db6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Column        Original           Match       Score\n",
      "0    6p_First_Name           James          James   100.000000\n",
      "1    6p_First_Name          Thomas         Thomas   100.000000\n",
      "2    6p_First_Name            John           John   100.000000\n",
      "3    6p_First_Name         William        William   100.000000\n",
      "4    6p_First_Name         William        Willliam   93.333333\n",
      "..             ...             ...             ...         ...\n",
      "265   3p_Last_Name  van Bunschoten  Van Bunschoten   92.857143\n",
      "266   3p_Last_Name         Richard        Richards   93.333333\n",
      "267   3p_Last_Name         Rathbun        Rathburn   93.333333\n",
      "268   3p_Last_Name          Pitkin         Pitkins   92.307692\n",
      "269   3p_Last_Name         Pitkins          Pitkin   92.307692\n",
      "\n",
      "[270 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "NY_columns_to_check = ['6p_First_Name', '6p_Last_Name', 'Def_6p_First_Name', 'Def_6p_Last_Name', '3p_First_Name', '3p_Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in NY_columns_to_check:\n",
    "    NY_unique_vals = post1790NY[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in NY_unique_vals:\n",
    "        result = process.extract(val, NY_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "NY_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(NY_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4742,
   "id": "fa5a12ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790NJ = pd.read_csv('NJ_3_percent_stock_T698_R1_R2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4743,
   "id": "a51945e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "982    False\n",
      "983    False\n",
      "984    False\n",
      "985    False\n",
      "986    False\n",
      "Name: Day, Length: 987, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "NJ_mask_strange_date =  (pd.to_numeric(post1790NJ['Day'], errors='coerce') >31)\n",
    "print(f'\\nAmount of dates over 31: {NJ_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4744,
   "id": "766721ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "982    False\n",
      "983    False\n",
      "984    False\n",
      "985    False\n",
      "986    False\n",
      "Name: Month, Length: 987, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "NJ_mask_strange_month =  (pd.to_numeric(post1790NJ['Month'], errors='coerce') >12)\n",
    "print(f'\\nAmount of dates over 31: {NJ_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f69dbde",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4745,
   "id": "6b796209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column       Original          Match       Score\n",
      "0   First_Name       Benjamin      Benjamin   100.000000\n",
      "1   First_Name           John          John   100.000000\n",
      "2   First_Name      Archibald    Archibald W   90.000000\n",
      "3   First_Name         Peter           Peter  100.000000\n",
      "4   First_Name    Archibald W      Archibald   90.000000\n",
      "5   First_Name      Benjamin        Benjamin  100.000000\n",
      "6   First_Name          Asher         Asher   100.000000\n",
      "7   First_Name          Peter         Peter   100.000000\n",
      "8   First_Name        Garret          Garret  100.000000\n",
      "9   First_Name         Garret        Garret   100.000000\n",
      "10  First_Name          Hugh            Hugh  100.000000\n",
      "11  First_Name        Israel          Israel  100.000000\n",
      "12  First_Name         Asher           Asher  100.000000\n",
      "13  First_Name         Israel        Israel   100.000000\n",
      "14  First_Name           Hugh          Hugh   100.000000\n",
      "15  First_Name          John            John  100.000000\n",
      "16  First_Name       Ebenezer        Ebenzer   93.333333\n",
      "17  First_Name        Ebenzer       Ebenezer   93.333333\n",
      "18   Last_Name        Philips       Phillips   93.333333\n",
      "19   Last_Name        Thomson       Thompson   93.333333\n",
      "20   Last_Name         Wikoff        Wickoff   92.307692\n",
      "21   Last_Name        Wyckoff         Wykoff   92.307692\n",
      "22   Last_Name       Brearley        Bearley   93.333333\n",
      "23   Last_Name    Van Derveer     Van Derver   95.238095\n",
      "24   Last_Name         Wykoff        Wyckoff   92.307692\n",
      "25   Last_Name         Schenk        Schenck   92.307692\n",
      "26   Last_Name         Holmes          Holme   90.909091\n",
      "27   Last_Name      Cheltwood       Chetwood   94.117647\n",
      "28   Last_Name         McEwen        McEowen   92.307692\n",
      "29   Last_Name       Phillips        Philips   93.333333\n",
      "30   Last_Name       Whickoff        Wickoff   93.333333\n",
      "31   Last_Name  Ferlinghuysen  Frelinghuysen   92.307692\n",
      "32   Last_Name        McEowen         McEwen   92.307692\n",
      "33   Last_Name        McEowen         Mcowen   92.307692\n",
      "34   Last_Name       Southard      Southhard   94.117647\n",
      "35   Last_Name          Moore         Moores   90.909091\n",
      "36   Last_Name        Schenck         Schenk   92.307692\n",
      "37   Last_Name       Thompson        Thomson   93.333333\n",
      "38   Last_Name      Langstaff     Langstaffe   94.736842\n",
      "39   Last_Name    Vredenbergh    Vredenburgh   90.909091\n",
      "40   Last_Name         Vanuys        VanNuys   92.307692\n",
      "41   Last_Name        Bearley       Brearley   93.333333\n",
      "42   Last_Name       Chetwood      Cheltwood   94.117647\n",
      "43   Last_Name     Van Derver    Van Derveer   95.238095\n",
      "44   Last_Name         Mcowen        McEowen   92.307692\n",
      "45   Last_Name  Frelinghuysen  Ferlinghuysen   92.307692\n",
      "46   Last_Name      Southhard       Southard   94.117647\n",
      "47   Last_Name         Moores          Moore   90.909091\n",
      "48   Last_Name        Wickoff       Whickoff   93.333333\n",
      "49   Last_Name        Wickoff         Wikoff   92.307692\n",
      "50   Last_Name     Langstaffe      Langstaff   94.736842\n",
      "51   Last_Name    Vredenburgh    Vredenbergh   90.909091\n",
      "52   Last_Name        VanNuys         Vanuys   92.307692\n",
      "53   Last_Name      Tenbroeck       Tenbrock   94.117647\n",
      "54   Last_Name          Holme         Holmes   90.909091\n",
      "55   Last_Name       Tenbrock      Tenbroeck   94.117647\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "NJ_columns_to_check = ['First_Name', 'Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in NJ_columns_to_check:\n",
    "    NJ_unique_vals = post1790NJ[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in NJ_unique_vals:\n",
    "        result = process.extract(val, NJ_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "NJ_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(NJ_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4746,
   "id": "9f58e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790NH = pd.read_csv('T652_New_Hampshire_ASD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4747,
   "id": "9625cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "post1790NH.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8085290",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Column     Original        Match       Score\n",
      "0       6p_First_Name  Nathaniel A   Nathaniel    90.000000\n",
      "1       6p_First_Name  Nathaniel A    Nathaniel   90.000000\n",
      "2       6p_First_Name       Joseph      Joseph   100.000000\n",
      "3       6p_First_Name       Robert      Robert   100.000000\n",
      "4       6p_First_Name   Nathaniel     Nathaniel  100.000000\n",
      "5       6p_First_Name   Nathaniel   Nathaniel A   90.000000\n",
      "6       6p_First_Name       Nathan      Nathan   100.000000\n",
      "7       6p_First_Name      Nathan        Nathan  100.000000\n",
      "8       6p_First_Name    Nathaniel   Nathaniel   100.000000\n",
      "9       6p_First_Name    Nathaniel  Nathaniel A   90.000000\n",
      "10      6p_First_Name      Joseph        Joseph  100.000000\n",
      "11      6p_First_Name      Robert        Robert  100.000000\n",
      "12       6p_Last_Name      Folsome       Folsom   92.307692\n",
      "13       6p_Last_Name     Whiteing    Whiteing   100.000000\n",
      "14       6p_Last_Name          Ham         Ham   100.000000\n",
      "15       6p_Last_Name         Ham           Ham  100.000000\n",
      "16       6p_Last_Name       Folsom      Folsome   92.307692\n",
      "17       6p_Last_Name    Whiteing      Whiteing  100.000000\n",
      "18  Def_6p_First_Name  Nathaniel A   Nathaniel    90.000000\n",
      "19  Def_6p_First_Name  Nathaniel A    Nathaniel   90.000000\n",
      "20  Def_6p_First_Name       Joseph      Joseph   100.000000\n",
      "21  Def_6p_First_Name       Robert      Robert   100.000000\n",
      "22  Def_6p_First_Name   Nathaniel     Nathaniel  100.000000\n",
      "23  Def_6p_First_Name   Nathaniel   Nathaniel A   90.000000\n",
      "24  Def_6p_First_Name       Nathan      Nathan   100.000000\n",
      "25  Def_6p_First_Name      Nathan        Nathan  100.000000\n",
      "26  Def_6p_First_Name    Nathaniel   Nathaniel   100.000000\n",
      "27  Def_6p_First_Name    Nathaniel  Nathaniel A   90.000000\n",
      "28  Def_6p_First_Name      Joseph        Joseph  100.000000\n",
      "29  Def_6p_First_Name      Robert        Robert  100.000000\n",
      "30  Def_6p_First_Name  Nathaniel A   Nathaniel    90.000000\n",
      "31  Def_6p_First_Name  Nathaniel A    Nathaniel   90.000000\n",
      "32  Def_6p_First_Name       Joseph      Joseph   100.000000\n",
      "33  Def_6p_First_Name       Robert      Robert   100.000000\n",
      "34  Def_6p_First_Name   Nathaniel     Nathaniel  100.000000\n",
      "35  Def_6p_First_Name   Nathaniel   Nathaniel A   90.000000\n",
      "36  Def_6p_First_Name       Nathan      Nathan   100.000000\n",
      "37  Def_6p_First_Name      Nathan        Nathan  100.000000\n",
      "38  Def_6p_First_Name    Nathaniel   Nathaniel   100.000000\n",
      "39  Def_6p_First_Name    Nathaniel  Nathaniel A   90.000000\n",
      "40  Def_6p_First_Name      Joseph        Joseph  100.000000\n",
      "41  Def_6p_First_Name      Robert        Robert  100.000000\n",
      "42      3p_First_Name  Nathaniel A   Nathaniel    90.000000\n",
      "43      3p_First_Name  Nathaniel A    Nathaniel   90.000000\n",
      "44      3p_First_Name       Joseph      Joseph   100.000000\n",
      "45      3p_First_Name       Robert      Robert   100.000000\n",
      "46      3p_First_Name   Nathaniel     Nathaniel  100.000000\n",
      "47      3p_First_Name   Nathaniel   Nathaniel A   90.000000\n",
      "48      3p_First_Name       Nathan      Nathan   100.000000\n",
      "49      3p_First_Name      Nathan        Nathan  100.000000\n",
      "50      3p_First_Name    Nathaniel   Nathaniel   100.000000\n",
      "51      3p_First_Name    Nathaniel  Nathaniel A   90.000000\n",
      "52      3p_First_Name      Joseph        Joseph  100.000000\n",
      "53      3p_First_Name      Robert        Robert  100.000000\n",
      "54       3p_Last_Name      Folsome       Folsom   92.307692\n",
      "55       3p_Last_Name     Whiteing    Whiteing   100.000000\n",
      "56       3p_Last_Name          Ham         Ham   100.000000\n",
      "57       3p_Last_Name         Ham           Ham  100.000000\n",
      "58       3p_Last_Name       Folsom      Folsome   92.307692\n",
      "59       3p_Last_Name    Whiteing      Whiteing  100.000000\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "NH_columns_to_check = ['6p_First_Name', '6p_Last_Name', 'Def_6p_First_Name', 'Def_6p_First_Name', '3p_First_Name', '3p_Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in NH_columns_to_check:\n",
    "    NH_unique_vals = post1790NH[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in NH_unique_vals:\n",
    "        result = process.extract(val, NH_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "NH_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(NH_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4749,
   "id": "e70601de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "221     True\n",
      "222     True\n",
      "223     True\n",
      "224     True\n",
      "226    False\n",
      "Length: 225, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "NH_mask_strange_date =  (\n",
    "    (pd.to_numeric(post1790NH['Def_6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790NH['6p_Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(post1790NH['3p_Day'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {NH_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4750,
   "id": "7c2be1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "221    False\n",
      "222    False\n",
      "223    False\n",
      "224    False\n",
      "226    False\n",
      "Length: 225, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "NH_mask_strange_month =  (\n",
    "    (pd.to_numeric(post1790NH['Def_6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790NH['6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790NH['3p_Month'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {NH_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4751,
   "id": "2d1b1e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years before 1790: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "221    False\n",
      "222    False\n",
      "223    False\n",
      "224    False\n",
      "226    False\n",
      "Length: 225, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values under 1790\n",
    "NH_mask_strange_year =  (\n",
    "    (pd.to_numeric(post1790NH['Def_6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790NH['6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790NH['3p_Year'], errors='coerce') <1790)\n",
    ")\n",
    "print(f'\\nAmount of years before 1790: {NH_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4752,
   "id": "ea76dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790NC = pd.read_csv('T695_R3_NC_ASD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4753,
   "id": "2b10c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "post1790NC.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec98ff",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4754,
   "id": "367c1a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Column  Original     Match       Score\n",
      "0  First_Name   Samuel     Samuel  100.000000\n",
      "1  First_Name    Samuel   Samuel   100.000000\n",
      "2   Last_Name  Johnston   Johnson   93.333333\n",
      "3   Last_Name   Johnson  Johnston   93.333333\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "NC_columns_to_check = ['First_Name', 'Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in NC_columns_to_check:\n",
    "    NC_unique_vals = post1790NC[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in NC_unique_vals:\n",
    "        result = process.extract(val, NC_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "NC_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(NC_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4755,
   "id": "16add9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "242    False\n",
      "243    False\n",
      "244    False\n",
      "246    False\n",
      "247    False\n",
      "Name: Day, Length: 247, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "NC_mask_strange_date = (pd.to_numeric(post1790NC['Day'], errors='coerce') >31)\n",
    "print(f'\\nAmount of dates over 31: {NC_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4756,
   "id": "ab450462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of month values over 12: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "242    False\n",
      "243    False\n",
      "244    False\n",
      "246    False\n",
      "247    False\n",
      "Name: Month, Length: 247, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "NC_mask_strange_month = (pd.to_numeric(post1790NC['Month'], errors='coerce') >12)\n",
    "print(f'\\nAmount of month values over 12: {NC_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4757,
   "id": "e56ab77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of year values under 1790: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "242    False\n",
      "243    False\n",
      "244    False\n",
      "246    False\n",
      "247    False\n",
      "Name: Year, Length: 247, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values under 1790\n",
    "NC_mask_strange_year = (pd.to_numeric(post1790NC['Year'], errors='coerce') <1790)\n",
    "print(f'\\nAmount of year values under 1790: {NC_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4758,
   "id": "fb61a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790MD = pd.read_csv('MD_post1790_ASD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4759,
   "id": "b9a2fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "post1790MD.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c40c5",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4760,
   "id": "dd02bddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Column  Original     Match  Score\n",
      "0  6p_Def_First_Name   Adrian     Adrian  100.0\n",
      "1  6p_Def_First_Name      John     John   100.0\n",
      "2  6p_Def_First_Name   Charles  Charles   100.0\n",
      "3  6p_Def_First_Name     John       John  100.0\n",
      "4  6p_Def_First_Name    Adrian   Adrian   100.0\n",
      "5  6p_Def_First_Name  Charles    Charles  100.0\n",
      "6      3p_First_Name   Charles  Charles   100.0\n",
      "7      3p_First_Name  Charles    Charles  100.0\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "MD_columns_to_check = ['6p_Name', '6p_Last Name', '6p_Def_First_Name', '6p_Def_Last_Name', '3p_First_Name', '3p_Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in MD_columns_to_check:\n",
    "    MD_unique_vals = post1790MD[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in MD_unique_vals:\n",
    "        result = process.extract(val, MD_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "MD_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(MD_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4761,
   "id": "dc196176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "188    False\n",
      "189    False\n",
      "190    False\n",
      "191    False\n",
      "192    False\n",
      "Length: 193, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "MD_mask_strange_date = (\n",
    "    (pd.to_numeric(post1790MD['6p_Day'], errors='coerce') >31) | \n",
    "    (pd.to_numeric(post1790MD['6p_Def_Day'], errors='coerce') >31) | \n",
    "    (pd.to_numeric(post1790MD['3p_Day'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {MD_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4762,
   "id": "e14387aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of month values over 12: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "188    False\n",
      "189    False\n",
      "190    False\n",
      "191    False\n",
      "192    False\n",
      "Length: 193, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#detect months after december\n",
    "MD_mask_strange_month = (\n",
    "    (pd.to_numeric(post1790MD['6p_Def_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790MD['6p_Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(post1790MD['3p_Month'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of month values over 12: {MD_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02535215",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4763,
   "id": "ff79a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of year values under 1790: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "188    False\n",
      "189    False\n",
      "190    False\n",
      "191    False\n",
      "192    False\n",
      "Length: 193, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#detect years before 1790\n",
    "MD_mask_strange_year = (\n",
    "    (pd.to_numeric(post1790MD['6p_Def_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790MD['6p_Year'], errors='coerce') <1790) |\n",
    "    (pd.to_numeric(post1790MD['3p_Year'], errors='coerce') <1790)\n",
    ")\n",
    "print(f'\\nAmount of year values under 1790: {MD_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4764,
   "id": "915e43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790GA = pd.read_csv('T694_GA_Loan_Office_CD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4765,
   "id": "8365c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "post1790GA.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c63b53f",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4766,
   "id": "9b5b0f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Column Original    Match      Score\n",
      "0  Last_Name  Josephs   Joseph  92.307692\n",
      "1  Last_Name   Joseph  Josephs  92.307692\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "GA_columns_to_check = ['First_Name', 'Last_Name', 'First_Name.1']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in GA_columns_to_check:\n",
    "    GA_unique_vals = post1790GA[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in GA_unique_vals:\n",
    "        result = process.extract(val, GA_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "GA_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(GA_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4767,
   "id": "85e3ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "      ...  \n",
      "71    False\n",
      "72    False\n",
      "73    False\n",
      "74    False\n",
      "76    False\n",
      "Name: Day, Length: 76, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#detect date values over 31\n",
    "GA_mask_strange_date = pd.to_numeric(post1790GA['Day'], errors='coerce') >31\n",
    "print(f'\\nAmount of dates over 31: {GA_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4768,
   "id": "edac31b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months listed as after December: 0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "      ...  \n",
      "71    False\n",
      "72    False\n",
      "73    False\n",
      "74    False\n",
      "76    False\n",
      "Name: Month, Length: 76, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#detect month values over 12\n",
    "GA_mask_strange_month = pd.to_numeric(post1790GA['Month'], errors='coerce') >12\n",
    "print(f'\\nAmount of months listed as after December: {GA_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4769,
   "id": "3b2eeaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years listed as before 1790: 0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "      ...  \n",
      "71    False\n",
      "72    False\n",
      "73    False\n",
      "74    False\n",
      "76    False\n",
      "Name: Year, Length: 76, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#detect year values under 1790 (or equal to)\n",
    "GA_mask_strange_year = pd.to_numeric(post1790GA['Year'], errors='coerce') < 1790\n",
    "print(f'\\nAmount of years listed as before 1790: {GA_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4770,
   "id": "06a28002",
   "metadata": {},
   "outputs": [],
   "source": [
    "post1790CT = pd.read_csv('CT_post1790_CD_ledger.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4771,
   "id": "461cc6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "post1790CT.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4772,
   "id": "6bc48f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Summary:\n",
      "                                                    CT_missing_count  \\\n",
      "Unnamed: 15                                                     1017   \n",
      "Unnamed: 31                                                     1017   \n",
      "3p_Title                                                         951   \n",
      "Def_6p_Title                                                     926   \n",
      "6p_Title                                                         923   \n",
      "3p_Occupation                                                    570   \n",
      "Def_6p_Occupation                                                531   \n",
      "6p_Occupation                                                    522   \n",
      "3p_Cents                                                         274   \n",
      "3p_Town                                                          191   \n",
      "3p_State                                                         175   \n",
      "3p_Last_Name                                                     168   \n",
      "3p_Page                                                          148   \n",
      "3p_Month                                                         140   \n",
      "3p_No                                                            139   \n",
      "3p_Year                                                          139   \n",
      "3p_Dollar                                                        138   \n",
      "3p_Day                                                           137   \n",
      "3p_First_Name                                                    136   \n",
      "Records of the bureau of the public debt  Conne...               130   \n",
      "Def_6p_Cents                                                     129   \n",
      "Record Name.2                                                    128   \n",
      "6p_Cents                                                         112   \n",
      "Def_6_Last_Name                                                  103   \n",
      "Def_6p_Town                                                       98   \n",
      "Def_6p_Dollar                                                     86   \n",
      "Def_6p_Page                                                       85   \n",
      "Def_6p_First_Name                                                 85   \n",
      "6p_Town                                                           85   \n",
      "Def_6p_No                                                         85   \n",
      "Def_6p_Day                                                        85   \n",
      "Def_6p_Month                                                      85   \n",
      "Def_6p_Year                                                       85   \n",
      "6p_Last_Name                                                      83   \n",
      "Def_6p_State                                                      82   \n",
      "Records of the bureau of the public debt  Conne...                78   \n",
      "Record Name.1                                                     76   \n",
      "6p_No                                                             71   \n",
      "6p_Page                                                           71   \n",
      "6p_Dollar                                                         71   \n",
      "6p_State                                                          70   \n",
      "6p_First_Name                                                     70   \n",
      "6p_Day                                                            70   \n",
      "6p_Month                                                          70   \n",
      "6p_Year                                                           70   \n",
      "Records of the bureau of the public debt  Conne...                63   \n",
      "Record Name                                                       61   \n",
      "\n",
      "                                                    CT_missing_percent  \n",
      "Unnamed: 15                                                 100.000000  \n",
      "Unnamed: 31                                                 100.000000  \n",
      "3p_Title                                                     93.510324  \n",
      "Def_6p_Title                                                 91.052114  \n",
      "6p_Title                                                     90.757129  \n",
      "3p_Occupation                                                56.047198  \n",
      "Def_6p_Occupation                                            52.212389  \n",
      "6p_Occupation                                                51.327434  \n",
      "3p_Cents                                                     26.941986  \n",
      "3p_Town                                                      18.780728  \n",
      "3p_State                                                     17.207473  \n",
      "3p_Last_Name                                                 16.519174  \n",
      "3p_Page                                                      14.552606  \n",
      "3p_Month                                                     13.765978  \n",
      "3p_No                                                        13.667650  \n",
      "3p_Year                                                      13.667650  \n",
      "3p_Dollar                                                    13.569322  \n",
      "3p_Day                                                       13.470993  \n",
      "3p_First_Name                                                13.372665  \n",
      "Records of the bureau of the public debt  Conne...           12.782694  \n",
      "Def_6p_Cents                                                 12.684366  \n",
      "Record Name.2                                                12.586037  \n",
      "6p_Cents                                                     11.012783  \n",
      "Def_6_Last_Name                                              10.127827  \n",
      "Def_6p_Town                                                   9.636185  \n",
      "Def_6p_Dollar                                                 8.456244  \n",
      "Def_6p_Page                                                   8.357915  \n",
      "Def_6p_First_Name                                             8.357915  \n",
      "6p_Town                                                       8.357915  \n",
      "Def_6p_No                                                     8.357915  \n",
      "Def_6p_Day                                                    8.357915  \n",
      "Def_6p_Month                                                  8.357915  \n",
      "Def_6p_Year                                                   8.357915  \n",
      "6p_Last_Name                                                  8.161259  \n",
      "Def_6p_State                                                  8.062930  \n",
      "Records of the bureau of the public debt  Conne...            7.669617  \n",
      "Record Name.1                                                 7.472960  \n",
      "6p_No                                                         6.981318  \n",
      "6p_Page                                                       6.981318  \n",
      "6p_Dollar                                                     6.981318  \n",
      "6p_State                                                      6.882989  \n",
      "6p_First_Name                                                 6.882989  \n",
      "6p_Day                                                        6.882989  \n",
      "6p_Month                                                      6.882989  \n",
      "6p_Year                                                       6.882989  \n",
      "Records of the bureau of the public debt  Conne...            6.194690  \n",
      "Record Name                                                   5.998033  \n"
     ]
    }
   ],
   "source": [
    "#missing values\n",
    "CT_missing_summary = post1790CT.isnull().sum().to_frame(name = 'CT_missing_count')\n",
    "CT_missing_summary['CT_missing_percent'] = 100*CT_missing_summary['CT_missing_count']/len(post1790CT)\n",
    "print(\"Missing Value Summary:\")\n",
    "print(CT_missing_summary.sort_values('CT_missing_percent', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4773,
   "id": "663c89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncombined rows \n",
    "CT_amount_fields = ['6p_Dollar', '6p_Cents', 'Def_6p_Dollar', 'Def_6p_Cents','3p_Dollar','3p_Cents']\n",
    "CT_mask_name_missing = post1790CT[['6p_First_Name',\n",
    "    '6p_Last_Name',\n",
    "    'Def_6p_First_Name',\n",
    "    'Def_6_Last_Name',\n",
    "    '3p_First_Name',\n",
    "    '3p_Last_Name'\n",
    "]].isnull().any(axis=1)\n",
    "CT_mask_amount_present = post1790CT[CT_amount_fields].notnull().any(axis=1)\n",
    "CT_mask_uncombined = CT_mask_name_missing & CT_mask_amount_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4774,
   "id": "7bfca78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value counts for all string columns:\n",
      "                                                    CT_unique_values\n",
      "Def_6_Last_Name                                                  427\n",
      "6p_Last_Name                                                     410\n",
      "3p_Last_Name                                                     399\n",
      "3p_First_Name                                                    230\n",
      "Def_6p_First_Name                                                229\n",
      "6p_First_Name                                                    219\n",
      "Def_6p_Town                                                      125\n",
      "6p_Town                                                          123\n",
      "3p_Town                                                          119\n",
      "6p_Occupation                                                     75\n",
      "Def_6p_Occupation                                                 74\n",
      "3p_Occupation                                                     70\n",
      "Record Name.2                                                     47\n",
      "Record Name.1                                                     37\n",
      "Record Name                                                       37\n",
      "Records of the bureau of the public debt  Conne...                30\n",
      "Records of the bureau of the public debt  Conne...                26\n",
      "Records of the bureau of the public debt  Conne...                25\n",
      "6p_Title                                                           9\n",
      "Def_6p_Title                                                       8\n",
      "Def_6p_State                                                       8\n",
      "3p_Title                                                           8\n",
      "6p_State                                                           8\n",
      "3p_State                                                           8\n"
     ]
    }
   ],
   "source": [
    "#typos? (more unique values than there should be)\n",
    "CT_string_cols = post1790CT.select_dtypes(include='object')\n",
    "CT_string_uniques = CT_string_cols.nunique(dropna=False).to_frame(name='CT_unique_values')\n",
    "print(\"Unique value counts for all string columns:\")\n",
    "print(CT_string_uniques.sort_values('CT_unique_values', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4775,
   "id": "d0a8ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to datetime (format)\n",
    "CT_date_cols = [col for col in post1790CT.columns if ('Month' in col.lower()) or ('Year' in col.lower()) or ('Day' in col.lower())]\n",
    "for col in CT_date_cols:\n",
    "    post1790CT[col] = pd.to_datetime(post1790CT[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4776,
   "id": "daa9e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting numbers to number types (format)\n",
    "CT_numeric_pattern = ['Dollar', 'Cents']\n",
    "CT_numeric_obj_cols = [col for col in post1790CT.select_dtypes(include = 'object').columns if any (pat in col for pat in CT_numeric_pattern)]\n",
    "for col in CT_numeric_obj_cols:\n",
    "    post1790CT[col] = pd.to_numeric(post1790CT[col].str.replace(',', ''), errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4777,
   "id": "5f738c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicates:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#duplicates (make sure there's no more)\n",
    "CT_new_dupcount = post1790CT.duplicated().sum()\n",
    "print('number of duplicates:')\n",
    "print(CT_new_dupcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4778,
   "id": "91205d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of negative values: 0\n"
     ]
    }
   ],
   "source": [
    "#detect negatives\n",
    "CT_mask_negative = post1790CT[[col for col in post1790CT.columns if any (pat in col for pat in CT_numeric_pattern)]].lt(0).any(axis = 1)\n",
    "print(f'\\nAmount of negative values: {CT_mask_negative.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4779,
   "id": "da611643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Record Name',\n",
      "       'Records of the bureau of the public debt  Connecticut loan office records  Relating to the loan of 1790',\n",
      "       '6p_Year', '6p_Month', '6p_Day', '6p_No', '6p_Title', '6p_First_Name',\n",
      "       '6p_Last_Name', '6p_Town', '6p_State', '6p_Occupation', '6p_Page',\n",
      "       '6p_Dollar', '6p_Cents', 'Unnamed: 15', 'Record Name.1',\n",
      "       'Records of the bureau of the public debt  Connecticut loan office records  Relating to the loan of 1790.1',\n",
      "       'Def_6p_Year', 'Def_6p_Month', 'Def_6p_Day', 'Def_6p_No',\n",
      "       'Def_6p_Title', 'Def_6p_First_Name', 'Def_6_Last_Name', 'Def_6p_Town',\n",
      "       'Def_6p_State', 'Def_6p_Occupation', 'Def_6p_Page', 'Def_6p_Dollar',\n",
      "       'Def_6p_Cents', 'Unnamed: 31', 'Record Name.2',\n",
      "       'Records of the bureau of the public debt  Connecticut loan office records  Relating to the loan of 1790.2',\n",
      "       '3p_Year', '3p_Month', '3p_Day', '3p_No', '3p_Title', '3p_First_Name',\n",
      "       '3p_Last_Name', '3p_Town', '3p_State', '3p_Occupation', '3p_Page',\n",
      "       '3p_Dollar', '3p_Cents'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(post1790CT.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4780,
   "id": "36ecfd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of times the state is not listed as CT: 248\n"
     ]
    }
   ],
   "source": [
    "#not CT\n",
    "mask_not_CT = (post1790CT['6p_State'] != 'CT') | (post1790CT['Def_6p_State'] != 'CT') | (post1790CT['3p_State'] != 'CT')\n",
    "print(f'\\nAmount of times the state is not listed as CT: {mask_not_CT.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4781,
   "id": "eb094c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to check separately\n",
    "CT_columns_to_check = ['6p_First_Name', '6p_Last_Name', 'Def_6_Last_Name','Def_6p_First_Name','3p_First_Name', '3p_Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in CT_columns_to_check:\n",
    "    CT_unique_vals = post1790CT[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in CT_unique_vals:\n",
    "        result = process.extract(val, CT_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904a74c",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4782,
   "id": "92523215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column   Original        Match       Score\n",
      "0   6p_First_Name    William     William   100.000000\n",
      "1   6p_First_Name     Simeon        Simon   90.909091\n",
      "2   6p_First_Name      Simon       Simeon   90.909091\n",
      "3   6p_First_Name  Nathaniel  Nathaniel G   90.000000\n",
      "4   6p_First_Name   William       William  100.000000\n",
      "..            ...        ...          ...         ...\n",
      "63   3p_Last_Name     Selden      Shelden   92.307692\n",
      "64   3p_Last_Name    Buswell     Bruswell   93.333333\n",
      "65   3p_Last_Name    Shelden       Selden   92.307692\n",
      "66   3p_Last_Name      Riley       Ripley   90.909091\n",
      "67   3p_Last_Name      Wylly       Wyllys   90.909091\n",
      "\n",
      "[68 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame to review\n",
    "CT_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(CT_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4783,
   "id": "a66da2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suspicious rows \n",
    "post1790CT['suspicious row'] = False\n",
    "post1790CT['suspicious reason'] = ''\n",
    "\n",
    "CT_mask_many_missing = post1790.isnull().sum(axis=1) > post1790.shape[1]/4\n",
    "post1790CT.loc[CT_mask_many_missing, 'suspicious row'] = True\n",
    "post1790CT.loc[CT_mask_many_missing, 'suspicious reason'] += 'More than 25% missing'\n",
    "\n",
    "post1790CT.loc[CT_mask_negative, 'suspicious row'] = True\n",
    "post1790CT.loc[CT_mask_negative, 'suspicious reason'] += 'Negative value'\n",
    "\n",
    "post1790CT.loc[CT_mask_uncombined, 'suspicious row'] = True\n",
    "post1790CT.loc[CT_mask_uncombined, 'suspicious reason'] = 'Uncombined Row, name is missing but amount is not'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4784,
   "id": "1f64fe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rare (possibly misspelled) towns: 278\n"
     ]
    }
   ],
   "source": [
    "#Rare places (possible typos)\n",
    "def CT_flag_rare(col_name, threshold):\n",
    "    CT_counts = post1790CT[col_name].fillna(' ').str.strip().value_counts()\n",
    "    CT_rare_vals = CT_counts[CT_counts <= threshold].index\n",
    "    return post1790CT[col_name].fillna(' ').str.strip().isin(CT_rare_vals), CT_rare_vals\n",
    "rare_threshold = 1 \n",
    "\n",
    "\n",
    "CT6_mask_rare_town, CT6_rare_towns = CT_flag_rare('6p_Town', rare_threshold)\n",
    "post1790CT.loc[CT6_mask_rare_town, 'suspicious row'] = True\n",
    "post1790CT.loc[CT6_mask_rare_town, 'suspicious reason'] += 'Rare town (might be spelled wrong)'\n",
    "\n",
    "CTDef6_mask_rare_town, CTDef6_rare_towns = CT_flag_rare('Def_6p_Town', rare_threshold)\n",
    "post1790CT.loc[CTDef6_mask_rare_town, 'suspicious row'] = True\n",
    "post1790CT.loc[CTDef6_mask_rare_town, 'suspicious reason'] += 'Rare town (might be spelled wrong)'\n",
    "\n",
    "CT3_mask_rare_town, CT3_rare_towns = CT_flag_rare('3p_Town', rare_threshold)\n",
    "post1790CT.loc[CT3_mask_rare_town, 'suspicious row'] = True\n",
    "post1790CT.loc[CT3_mask_rare_town, 'suspicious reason'] += 'Rare town (might be spelled wrong)'\n",
    "\n",
    "print(f'\\nNumber of rare (possibly misspelled) towns: {CT_mask_rare_town.sum()+CTDef6_mask_rare_town.sum()+CT3_mask_rare_town.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4785,
   "id": "0dc4b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean vs suspicious\n",
    "clean_post1790CT = post1790CT[~post1790CT['suspicious row']]\n",
    "suspicious_post1790CT = post1790CT[post1790CT['suspicious row']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4786,
   "id": "0b2a3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save clean & suspicious just in case they need to be referred to when scanning errors\n",
    "clean_post1790CT.to_csv(\"cleaned_CT_post1790_CD_ledger.csv\", index=False)\n",
    "suspicious_post1790CT.to_csv(\"suspicious_CT_post1790_CD_ledger.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4787,
   "id": "bcea8b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspicious rows: 261\n",
      "\n",
      "Preview of Suspicious Rows:\n",
      "    Unnamed: 0  6p_Dollar  6p_Cents  6p_def_Dollar  6p_def_Cents  3p_Dollar  \\\n",
      "9            9       66.0      66.0           33.0          34.0       48.0   \n",
      "53          53     1228.0      39.0          614.0          20.0      935.0   \n",
      "67          67       62.0      93.0           31.0          47.0       22.0   \n",
      "75          75     1336.0       5.0          668.0           2.0      959.0   \n",
      "80          80      105.0      88.0           52.0          94.0       76.0   \n",
      "\n",
      "    3p_Cents        town state occupation  ...             county new_state  \\\n",
      "9        NaN  Farmington    CT     Farmer  ...    Hartford County        CT   \n",
      "53      98.0     Norwich    CT        NaN  ...  New London County        CT   \n",
      "67      66.0      Goshen    CT     Farmer  ...  Litchfield County        CT   \n",
      "75      93.0    Hartford    CT   Merchant  ...    Hartford County        CT   \n",
      "80      25.0  Colchester    CT        NaN  ...  New London County        CT   \n",
      "\n",
      "   country name_type  6p_total 6p_def_total 3p_total    Combined_Name  \\\n",
      "9       US      town     66.66        33.34    48.00  Joseph Woodruff   \n",
      "53      US      town   1228.39       614.20   935.98    Daniel L Coit   \n",
      "67      US      town     62.93        31.47    22.66   Solomon Wadham   \n",
      "75      US      town   1336.05       668.02   959.93    Pownal Deming   \n",
      "80      US      town    105.88        52.94    76.25       Elias Peck   \n",
      "\n",
      "   suspicious row                suspicious reason  \n",
      "9            True  Name != First Name + Last Name   \n",
      "53           True  Name != First Name + Last Name   \n",
      "67           True  Name != First Name + Last Name   \n",
      "75           True  Name != First Name + Last Name   \n",
      "80           True  Name != First Name + Last Name   \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#print suspicious rows\n",
    "print(f\"Suspicious rows: {post1790CT['suspicious row'].sum()}\")\n",
    "print(\"\\nPreview of Suspicious Rows:\")\n",
    "print(suspicious_post1790.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4788,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "post1790.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4789,
   "id": "5fc65d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Summary:\n",
      "                   missing_count  missing_percent\n",
      "occupation                  4414        67.451100\n",
      "new_town                    3423        52.307457\n",
      "county                      2995        45.767115\n",
      "town                        2814        43.001222\n",
      "6p_def_Cents                2408        36.797066\n",
      "6p_Cents                    2382        36.399756\n",
      "6p_def_Dollar               2243        34.275672\n",
      "6p_Dollar                   2177        33.267115\n",
      "3p_Cents                    1093        16.702323\n",
      "3p_Dollar                    677        10.345355\n",
      "new_state                     28         0.427873\n",
      "state                         11         0.168093\n",
      "6p_def_total                   0         0.000000\n",
      "Unnamed: 0                     0         0.000000\n",
      "3p_total                       0         0.000000\n",
      "Combined_Name                  0         0.000000\n",
      "suspicious row                 0         0.000000\n",
      "name_type                      0         0.000000\n",
      "6p_total                       0         0.000000\n",
      "state_data                     0         0.000000\n",
      "country                        0         0.000000\n",
      "state_data_index               0         0.000000\n",
      "Last Name                      0         0.000000\n",
      "First Name                     0         0.000000\n",
      "Name                           0         0.000000\n",
      "suspicious reason              0         0.000000\n"
     ]
    }
   ],
   "source": [
    "#missing values\n",
    "missing_summary = post1790.isnull().sum().to_frame(name = 'missing_count')\n",
    "missing_summary['missing_percent'] = 100*missing_summary['missing_count']/len(post1790)\n",
    "print(\"Missing Value Summary:\")\n",
    "print(missing_summary.sort_values('missing_percent', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4790,
   "id": "e2635c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncombined rows \n",
    "amount_fields = ['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents','3p_Dollar','3p_Cents', '6p_total','6p_def_total','3p_total']\n",
    "mask_name_missing = post1790['Name'].isnull()\n",
    "mask_amount_present = post1790[amount_fields].notnull().any(axis=1)\n",
    "mask_uncombined = mask_name_missing & mask_amount_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4791,
   "id": "1e5c188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value counts for all string columns:\n",
      "                   unique_values\n",
      "Name                        3880\n",
      "Combined_Name               3019\n",
      "Last Name                   1691\n",
      "First Name                   741\n",
      "town                         437\n",
      "occupation                   271\n",
      "new_town                     236\n",
      "county                       107\n",
      "state                         21\n",
      "new_state                     15\n",
      "state_data                     9\n",
      "country                        7\n",
      "name_type                      4\n",
      "suspicious reason              3\n"
     ]
    }
   ],
   "source": [
    "#typos? (more unique values than there should be)\n",
    "string_cols = post1790.select_dtypes(include='object')\n",
    "string_uniques = string_cols.nunique(dropna=False).to_frame(name='unique_values')\n",
    "print(\"Unique value counts for all string columns:\")\n",
    "print(string_uniques.sort_values('unique_values', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4792,
   "id": "d7ec6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to datetime (format)\n",
    "date_cols = [col for col in post1790.columns if 'date' in col.lower()]\n",
    "for col in date_cols:\n",
    "    post1790[col] = pd.to_datetime(post1790[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4793,
   "id": "9477a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting numbers to number types (format)\n",
    "numeric_pattern = ['Dollar', 'Cents', 'Total']\n",
    "numeric_obj_cols = [col for col in post1790.select_dtypes(include = 'object').columns if any (pat in col for pat in numeric_pattern)]\n",
    "for col in numeric_obj_cols:\n",
    "    post1790[col] = pd.to_numeric(post1790[col].str.replace(',', ''), errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4794,
   "id": "1491947c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicates:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#duplicates (make sure there's no more)\n",
    "post1790_new_dupcount = post1790.duplicated().sum()\n",
    "print('number of duplicates:')\n",
    "print(post1790_new_dupcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4795,
   "id": "e188c5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007Amount of negative values: 0\n"
     ]
    }
   ],
   "source": [
    "#detect negatives\n",
    "mask_negative = post1790[[col for col in post1790.columns if any (pat in col for pat in numeric_pattern)]].lt(0).any(axis = 1)\n",
    "print(f'\\aAmount of negative values: {mask_negative.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4796,
   "id": "7d44b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of rows where Name != First Name + Last Name: 2999\n"
     ]
    }
   ],
   "source": [
    "#name mismatch\n",
    "post1790['Name'] = post1790['Name'].fillna('')\n",
    "post1790['First Name'] = post1790['First Name'].fillna('')\n",
    "post1790['Last Name'] = post1790['Last Name'].fillna('')\n",
    "print(f'\\nAmount of rows where Name != First Name + Last Name: {mask_name_mismatch.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4797,
   "id": "bbd8785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put together full name\n",
    "post1790['Combined_Name'] = (post1790['First Name'] + ' ' + post1790['Last Name'])\n",
    "mask_name_mismatch = (post1790['Name'] != post1790['Combined_Name']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4798,
   "id": "e6bbbb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of times the country is not listed as US: 27\n"
     ]
    }
   ],
   "source": [
    "#not United States\n",
    "mask_not_US = (post1790['country'] != 'US')\n",
    "print(f'\\nAmount of times the country is not listed as US: {mask_not_US.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4799,
   "id": "51c1513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use correct column name here\n",
    "unique_names = post1790['Name'].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4800,
   "id": "ab3c50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set similarity threshold\n",
    "threshold = 90\n",
    "matches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4801,
   "id": "44b70404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find fuzzy matches\n",
    "for name in unique_names:\n",
    "    result = process.extract(name, unique_names, scorer=fuzz.token_sort_ratio)\n",
    "    for match_name, score, _ in result:\n",
    "        if name != match_name and score >= threshold:\n",
    "            matches.append((name, match_name, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952415cc",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4802,
   "id": "fda5b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Original                Match      Score\n",
      "0          Peleg Sanford       Peleg Sandford  96.296296\n",
      "1           Samuel Marsh         Samuel March  91.666667\n",
      "2          James A Wells       James A Welles  96.296296\n",
      "3          James A Wells          James Wells  91.666667\n",
      "4         John Templeman        Jon Templeman  96.296296\n",
      "..                   ...                  ...        ...\n",
      "321       J H Livingston     D J H Livingston  93.333333\n",
      "322  Hekekiah B Pierpont  Hezekiah B Pierpont  94.736842\n",
      "323          Ephram Hart         Ephraim Hart  95.652174\n",
      "324        Lynde Catline         Lynd Catline  96.000000\n",
      "325      John H Thompson        John Thompson  92.857143\n",
      "\n",
      "[326 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Review results\n",
    "fuzzy_matches = pd.DataFrame(matches, columns=['Original', 'Match', 'Score'])\n",
    "print(fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4803,
   "id": "d440dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rare (possibly misspelled) new towns: 75\n",
      "\n",
      "Number of rare (possibly misspelled) counties: 18\n",
      "\n",
      "Number of rare (possibly misspelled) towns: 194\n"
     ]
    }
   ],
   "source": [
    "#Rare places (possible typos)\n",
    "def flag_rare(col_name, threshold):\n",
    "    counts = post1790[col_name].fillna(' ').str.strip().value_counts()\n",
    "    rare_vals = counts[counts <= threshold].index\n",
    "    return post1790[col_name].fillna(' ').str.strip().isin(rare_vals), rare_vals\n",
    "rare_threshold = 1 \n",
    "mask_rare_new_town, rare_new_towns = flag_rare('new_town', rare_threshold)\n",
    "post1790.loc[mask_rare_new_town, 'suspicious row'] = True\n",
    "post1790.loc[mask_rare_new_town, 'suspicious reason'] += 'Rare new_town (might be spelled wrong)'\n",
    "\n",
    "mask_rare_town, rare_towns = flag_rare('town', rare_threshold)\n",
    "post1790.loc[mask_rare_town, 'suspicious row'] = True\n",
    "post1790.loc[mask_rare_town, 'suspicious reason'] += 'Rare town (might be spelled wrong)'\n",
    "\n",
    "\n",
    "mask_rare_county, rare_counties = flag_rare('county', rare_threshold)\n",
    "post1790.loc[mask_rare_county, 'suspicious row'] = True\n",
    "post1790.loc[mask_rare_county, 'suspicious reason'] += 'Rare county (might be spelled wrong)'\n",
    "print(f'\\nNumber of rare (possibly misspelled) new towns: {mask_rare_new_town.sum()}')\n",
    "print(f'\\nNumber of rare (possibly misspelled) counties: {mask_rare_county.sum()}')\n",
    "print(f'\\nNumber of rare (possibly misspelled) towns: {mask_rare_town.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4804,
   "id": "eced7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suspicious rows \n",
    "post1790['suspicious row'] = False\n",
    "post1790['suspicious reason'] = ''\n",
    "\n",
    "mask_many_missing = post1790.isnull().sum(axis=1) > post1790.shape[1]/4\n",
    "post1790.loc[mask_many_missing, 'suspicious row'] = True\n",
    "post1790.loc[mask_many_missing, 'suspicious reason'] += 'More than 25% missing'\n",
    "\n",
    "post1790.loc[mask_negative, 'suspicious row'] = True\n",
    "post1790.loc[mask_negative, 'suspicious reason'] += 'Negative value'\n",
    "\n",
    "post1790.loc[mask_uncombined, 'suspicious row'] = True\n",
    "post1790.loc[mask_uncombined, 'suspicious reason'] = 'Uncombined Row, name is missing but amount is not'\n",
    "\n",
    "post1790.loc[mask_name_mismatch, 'suspicious row'] = True\n",
    "post1790.loc[mask_name_mismatch, 'suspicious reason']= 'Name != First Name + Last Name '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4805,
   "id": "dbef9b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean vs suspicious\n",
    "clean_post1790 = post1790[~post1790['suspicious row']]\n",
    "suspicious_post1790 = post1790[post1790['suspicious row']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4806,
   "id": "896da559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save clean & suspicious just in case they need to be referred to when scanning errors\n",
    "clean_post1790.to_csv(\"cleaned_aggregated_CD_post1790.csv\", index=False)\n",
    "suspicious_post1790.to_csv(\"suspicious_aggregated_CD_post1790.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4807,
   "id": "2e5220bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspicious rows: 3035\n",
      "\n",
      "Preview of Suspicious Rows:\n",
      "    Unnamed: 0  6p_Dollar  6p_Cents  6p_def_Dollar  6p_def_Cents  3p_Dollar  \\\n",
      "9            9       66.0      66.0           33.0          34.0       48.0   \n",
      "53          53     1228.0      39.0          614.0          20.0      935.0   \n",
      "67          67       62.0      93.0           31.0          47.0       22.0   \n",
      "75          75     1336.0       5.0          668.0           2.0      959.0   \n",
      "80          80      105.0      88.0           52.0          94.0       76.0   \n",
      "\n",
      "    3p_Cents        town state occupation  ...             county new_state  \\\n",
      "9        NaN  Farmington    CT     Farmer  ...    Hartford County        CT   \n",
      "53      98.0     Norwich    CT        NaN  ...  New London County        CT   \n",
      "67      66.0      Goshen    CT     Farmer  ...  Litchfield County        CT   \n",
      "75      93.0    Hartford    CT   Merchant  ...    Hartford County        CT   \n",
      "80      25.0  Colchester    CT        NaN  ...  New London County        CT   \n",
      "\n",
      "   country name_type  6p_total 6p_def_total 3p_total    Combined_Name  \\\n",
      "9       US      town     66.66        33.34    48.00  Joseph Woodruff   \n",
      "53      US      town   1228.39       614.20   935.98    Daniel L Coit   \n",
      "67      US      town     62.93        31.47    22.66   Solomon Wadham   \n",
      "75      US      town   1336.05       668.02   959.93    Pownal Deming   \n",
      "80      US      town    105.88        52.94    76.25       Elias Peck   \n",
      "\n",
      "   suspicious row                suspicious reason  \n",
      "9            True  Name != First Name + Last Name   \n",
      "53           True  Name != First Name + Last Name   \n",
      "67           True  Name != First Name + Last Name   \n",
      "75           True  Name != First Name + Last Name   \n",
      "80           True  Name != First Name + Last Name   \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#print suspicious rows\n",
    "print(f\"Suspicious rows: {post1790['suspicious row'].sum()}\")\n",
    "print(\"\\nPreview of Suspicious Rows:\")\n",
    "print(suspicious_post1790.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5971,
   "id": "011d5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790RI = pd.read_csv('liquidated_debt_certificates_RI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5978,
   "id": "d92f8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1534    False\n",
      "1535    False\n",
      "1536    False\n",
      "1537    False\n",
      "1538    False\n",
      "Length: 1539, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "preRI_mask_strange_date =  (\n",
    "    (pd.to_numeric(pre1790RI['Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790RI['Day_Due'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790RI['Day_Delivered'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {preRI_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5984,
   "id": "5b0e5b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1534    False\n",
      "1535    False\n",
      "1536    False\n",
      "1537    False\n",
      "1538    False\n",
      "Length: 1539, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "preRI_mask_strange_month =  (\n",
    "    (pd.to_numeric(pre1790RI['Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790RI['Month_Due'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790RI['Month_Delivered'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {preRI_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5990,
   "id": "635b9e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years over 1790: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1534    False\n",
      "1535    False\n",
      "1536    False\n",
      "1537    False\n",
      "1538    False\n",
      "Length: 1539, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values over 1790\n",
    "preRI_mask_strange_year =  (\n",
    "    (pd.to_numeric(pre1790RI['Year'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790RI['Year_Due'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790RI['Year_Delivered'], errors='coerce') >1790)\n",
    ")\n",
    "print(f'\\nAmount of years over 1790: {preRI_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11ff72",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6044,
   "id": "3355d6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column  Original     Match       Score\n",
      "0   First_Name   William  Williams   93.333333\n",
      "1   First_Name   William    Wiliam   92.307692\n",
      "2   First_Name   William    Willam   92.307692\n",
      "3   First_Name   Clark &  Clarke &   93.333333\n",
      "4   First_Name      Jack     Jack   100.000000\n",
      "..         ...       ...       ...         ...\n",
      "65   Last_Name  Willbour   Wilbour   93.333333\n",
      "66   Last_Name    Gardne   Gardner   92.307692\n",
      "67   Last_Name    Crooke     Cooke   90.909091\n",
      "68   Last_Name   Bloomer    Boomer   92.307692\n",
      "69   Last_Name    Maxson     Mason   90.909091\n",
      "\n",
      "[70 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "preRI_columns_to_check = ['First_Name', 'Last_Name','First_Name.1','Last_Name.1']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in preRI_columns_to_check:\n",
    "    preRI_unique_vals = pre1790RI[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in preRI_unique_vals:\n",
    "        result = process.extract(val, preRI_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "preRI_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(preRI_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6045,
   "id": "c5c82330",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790PA = pd.read_csv('liquidated_debt_certificates_PA_stelle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6046,
   "id": "0ce95896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "9218     True\n",
      "9219     True\n",
      "9220    False\n",
      "9221    False\n",
      "9222    False\n",
      "Length: 9223, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "prePA_mask_strange_date =  (\n",
    "    (pd.to_numeric(pre1790PA['Date'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790PA['Date_Due'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {prePA_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6047,
   "id": "454014e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "9218    False\n",
      "9219     True\n",
      "9220    False\n",
      "9221    False\n",
      "9222    False\n",
      "Length: 9223, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "prePA_mask_strange_month =  (\n",
    "    (pd.to_numeric(pre1790PA['Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790PA['Month_Due'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {prePA_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6048,
   "id": "2f02ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years over 1790: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "9218    False\n",
      "9219    False\n",
      "9220    False\n",
      "9221    False\n",
      "9222    False\n",
      "Length: 9223, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values over 1790\n",
    "prePA_mask_strange_year =  (\n",
    "    (pd.to_numeric(pre1790PA['Year'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790PA['Year_Due'], errors='coerce') >1790)\n",
    ")\n",
    "print(f'\\nAmount of years over 1790: {prePA_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909e2a9",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6049,
   "id": "363b9a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Column   Original     Match       Score\n",
      "0    First_Name    William    Wiliam   92.307692\n",
      "1    First_Name    William    Willam   92.307692\n",
      "2    First_Name  Christian  Christia   94.117647\n",
      "3    First_Name    Charles  Caharles   93.333333\n",
      "4    First_Name   Ludowick   Ludwick   93.333333\n",
      "..          ...        ...       ...         ...\n",
      "911   Last_Name     Leonad   Leonard   92.307692\n",
      "912   Last_Name     Backer   Beacker   92.307692\n",
      "913   Last_Name     Backer     Baker   90.909091\n",
      "914   Last_Name     Grubbs     Grubb   90.909091\n",
      "915   Last_Name     Faust      Faust  100.000000\n",
      "\n",
      "[916 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "prePA_columns_to_check = ['First_Name', 'Last_Name','First_Name.1','Last_Name.1']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in prePA_columns_to_check:\n",
    "    prePA_unique_vals = pre1790PA[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in prePA_unique_vals:\n",
    "        result = process.extract(val, prePA_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "prePA_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(prePA_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6050,
   "id": "cdf4de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790NY = pd.read_csv('liquidated_debt_certificates_NY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6051,
   "id": "50695de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "7317    False\n",
      "7318    False\n",
      "7319    False\n",
      "7320    False\n",
      "7321    False\n",
      "Length: 7322, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "preNY_mask_strange_date =  (\n",
    "    (pd.to_numeric(pre1790NY['Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790NY['Day_Due'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {preNY_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6052,
   "id": "03441ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "7317    False\n",
      "7318    False\n",
      "7319    False\n",
      "7320    False\n",
      "7321    False\n",
      "Length: 7322, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "preNY_mask_strange_month =  (\n",
    "    (pd.to_numeric(pre1790NY['Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790NY['Month_Due'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {preNY_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6053,
   "id": "14025b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years over 1790: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "7317    False\n",
      "7318    False\n",
      "7319    False\n",
      "7320    False\n",
      "7321    False\n",
      "Length: 7322, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values over 1790\n",
    "preNY_mask_strange_year =  (\n",
    "    (pd.to_numeric(pre1790NY['Year'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790NY['Year_Due'], errors='coerce') >1790)\n",
    ")\n",
    "print(f'\\nAmount of years over 1790: {preNY_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e94662",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6054,
   "id": "1327ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Column      Original          Match       Score\n",
      "0    First_Name          John          John   100.000000\n",
      "1    First_Name       Mathias       Matthias   93.333333\n",
      "2    First_Name         James         James   100.000000\n",
      "3    First_Name      Nathniel      Nathaniel   94.117647\n",
      "4    First_Name        Mathew        Matthew   92.307692\n",
      "..          ...           ...            ...         ...\n",
      "856   Last_Name     De Bevois     De Bevoise   94.736842\n",
      "857   Last_Name      Terhune         Terhune  100.000000\n",
      "858   Last_Name  Van De Voort  Van Der Voort   96.000000\n",
      "859   Last_Name      Kronkite      Kronkhite   94.117647\n",
      "860   Last_Name       Messier         Mesier   92.307692\n",
      "\n",
      "[861 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "preNY_columns_to_check = ['First_Name', 'Last_Name','First_Name.1','Last_Name.1']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in preNY_columns_to_check:\n",
    "    preNY_unique_vals = pre1790NY[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in preNY_unique_vals:\n",
    "        result = process.extract(val, preNY_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "preNY_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(preNY_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6055,
   "id": "5ab91d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790NJ = pd.read_csv('liquidated_debt_certificates_NJ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6056,
   "id": "8d64a1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "5115    False\n",
      "5116    False\n",
      "5117    False\n",
      "5118    False\n",
      "5119    False\n",
      "Length: 5120, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "preNJ_mask_strange_date =  (\n",
    "    (pd.to_numeric(pre1790NJ['Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790NJ['Day_Due'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {preNJ_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6057,
   "id": "7f47a611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "5115    False\n",
      "5116    False\n",
      "5117    False\n",
      "5118    False\n",
      "5119    False\n",
      "Length: 5120, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "preNJ_mask_strange_month =  (\n",
    "    (pd.to_numeric(pre1790NJ['Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790NJ['Month_Due'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {preNJ_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6058,
   "id": "7aa49150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years over 1790: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "5115    False\n",
      "5116    False\n",
      "5117    False\n",
      "5118    False\n",
      "5119    False\n",
      "Length: 5120, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values over 1790\n",
    "preNJ_mask_strange_year =  (\n",
    "    (pd.to_numeric(pre1790NJ['Year'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790NJ['Year_Due'], errors='coerce') >1790)\n",
    ")\n",
    "print(f'\\nAmount of years over 1790: {preNJ_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7bb14b",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6059,
   "id": "8f88d831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Column      Original         Match       Score\n",
      "0    First_Name        Joseph       Joserph   92.307692\n",
      "1    First_Name          John         John   100.000000\n",
      "2    First_Name        Robert         Rbert   90.909091\n",
      "3    First_Name        Stacey         Stacy   90.909091\n",
      "4    First_Name       Garrett        Garret   92.307692\n",
      "..          ...           ...           ...         ...\n",
      "375   Last_Name  Van Voorhees  VanVoorchees   91.666667\n",
      "376   Last_Name  Van Blarieum  Van Blaricum   91.666667\n",
      "377   Last_Name    Van Houter    Van Houten   90.000000\n",
      "378   Last_Name     Wanamaker    Wannamaker   94.736842\n",
      "379   Last_Name         Nagle        Naugle   90.909091\n",
      "\n",
      "[380 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "preNJ_columns_to_check = ['First_Name', 'Last_Name','First_Name.1','Last_Name.1']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in preNJ_columns_to_check:\n",
    "    preNJ_unique_vals = pre1790NJ[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in preNJ_unique_vals:\n",
    "        result = process.extract(val, preNJ_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "preNJ_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(preNJ_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6060,
   "id": "c0c14a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790NH = pd.read_csv('liquidated_debt_certificates_NH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6061,
   "id": "ce908593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "185    False\n",
      "186    False\n",
      "187    False\n",
      "188    False\n",
      "189    False\n",
      "Length: 190, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "preNH_mask_strange_date =  (\n",
    "    (pd.to_numeric(pre1790NH['Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790NH['Day_Due'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {preNH_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6062,
   "id": "eb39ea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "185    False\n",
      "186    False\n",
      "187    False\n",
      "188    False\n",
      "189    False\n",
      "Length: 190, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "preNH_mask_strange_month =  (\n",
    "    (pd.to_numeric(pre1790NH['Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790NH['Month_Due'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {preNH_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6063,
   "id": "f5d4372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years over 1790: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "185    False\n",
      "186    False\n",
      "187    False\n",
      "188    False\n",
      "189    False\n",
      "Length: 190, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values over 1790\n",
    "preNH_mask_strange_year =  (\n",
    "    (pd.to_numeric(pre1790NH['Year'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790NH['Year_Due'], errors='coerce') >1790)\n",
    ")\n",
    "print(f'\\nAmount of years over 1790: {preNH_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f7c3e3",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6064,
   "id": "32cfe875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column    Original       Match      Score\n",
      "0   First_Name  Eliphalett   Eliphalet  94.736842\n",
      "1   First_Name     Joshiah      Josiah  92.307692\n",
      "2   First_Name      Simeon       Simon  90.909091\n",
      "3   First_Name      Josiah     Joshiah  92.307692\n",
      "4   First_Name       Simon      Simeon  90.909091\n",
      "5   First_Name   Eliphalet  Eliphalett  94.736842\n",
      "6    Last_Name     Leavitt      Leavit  92.307692\n",
      "7    Last_Name     Lampson      Lamson  92.307692\n",
      "8    Last_Name      Wiggin     Wiggins  92.307692\n",
      "9    Last_Name     Wiggins      Wiggin  92.307692\n",
      "10   Last_Name      Lamson     Lampson  92.307692\n",
      "11   Last_Name      Leavit     Leavitt  92.307692\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "preNH_columns_to_check = ['First_Name', 'Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in preNH_columns_to_check:\n",
    "    preNH_unique_vals = pre1790NH[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in preNH_unique_vals:\n",
    "        result = process.extract(val, preNH_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "preNH_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(preNH_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6065,
   "id": "fbf8aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790MA = pd.read_csv('liquidated_debt_certificates_MA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6066,
   "id": "dd484cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "2086    False\n",
      "2087    False\n",
      "2088    False\n",
      "2089    False\n",
      "2090    False\n",
      "Length: 2091, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "preMA_mask_strange_date =  (\n",
    "    (pd.to_numeric(pre1790MA['Date'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790MA['Date_Due'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {preMA_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6067,
   "id": "40bdcddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "2086    False\n",
      "2087    False\n",
      "2088    False\n",
      "2089    False\n",
      "2090    False\n",
      "Length: 2091, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "preMA_mask_strange_month =  (\n",
    "    (pd.to_numeric(pre1790MA['Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790MA['Month_Due'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {preMA_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6068,
   "id": "e7bc88b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years over 1790: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "2086    False\n",
      "2087    False\n",
      "2088    False\n",
      "2089    False\n",
      "2090    False\n",
      "Length: 2091, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values over 1790\n",
    "preMA_mask_strange_year =  (\n",
    "    (pd.to_numeric(pre1790MA['Year'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790MA['Year_Due'], errors='coerce') >1790)\n",
    ")\n",
    "print(f'\\nAmount of years over 1790: {preMA_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448bce6",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6069,
   "id": "bb6e3443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Column  Original      Match       Score\n",
      "0    First_Name  Benjamin    Bejamin   93.333333\n",
      "1    First_Name  Ebenezer    Ebeneze   93.333333\n",
      "2    First_Name    Samuel     Samuel  100.000000\n",
      "3    First_Name   William   William   100.000000\n",
      "4    First_Name  Jonathan  Jonathan   100.000000\n",
      "..          ...       ...        ...         ...\n",
      "215   Last_Name    Wysman      Wyman   90.909091\n",
      "216   Last_Name   Bordman   Boardman   93.333333\n",
      "217   Last_Name   Bordman     Borman   92.307692\n",
      "218   Last_Name    Crafts      Craft   90.909091\n",
      "219   Last_Name    Greene      Green   90.909091\n",
      "\n",
      "[220 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "preMA_columns_to_check = ['First_Name', 'Last_Name', 'First_Name.1', 'Last_Name.1']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in preMA_columns_to_check:\n",
    "    preMA_unique_vals = pre1790MA[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in preMA_unique_vals:\n",
    "        result = process.extract(val, preMA_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "preMA_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(preMA_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6070,
   "id": "edfa6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790DE = pd.read_csv('liquidated_debt_certificates_DE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6071,
   "id": "43fb4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "634    False\n",
      "635    False\n",
      "636    False\n",
      "637    False\n",
      "638    False\n",
      "Length: 639, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "preDE_mask_strange_date =  (\n",
    "    (pd.to_numeric(pre1790DE['Date'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790DE['Date_Due'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {preDE_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6072,
   "id": "5dd8e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "634    False\n",
      "635    False\n",
      "636    False\n",
      "637    False\n",
      "638    False\n",
      "Length: 639, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "preDE_mask_strange_month =  (\n",
    "    (pd.to_numeric(pre1790DE['Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790DE['Month_Due'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {preDE_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6073,
   "id": "1cc343ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years over 1790: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "634    False\n",
      "635    False\n",
      "636    False\n",
      "637    False\n",
      "638    False\n",
      "Length: 639, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values over 1790\n",
    "preDE_mask_strange_year =  (\n",
    "    (pd.to_numeric(pre1790DE['Year'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790DE['Year_Due'], errors='coerce') >1790)\n",
    ")\n",
    "print(f'\\nAmount of years over 1790: {preDE_mask_strange_year}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225facd",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6074,
   "id": "18f863a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column     Original        Match       Score\n",
      "0   First_Name      William     William   100.000000\n",
      "1   First_Name    Alexander   Alexander   100.000000\n",
      "2   First_Name   Alexander     Alexander  100.000000\n",
      "3   First_Name     William       William  100.000000\n",
      "4    Last_Name       Baning      Banning   92.307692\n",
      "5    Last_Name      Banning       Baning   92.307692\n",
      "6    Last_Name       Darrah      Darrach   92.307692\n",
      "7    Last_Name      Tatnall     Tatnall   100.000000\n",
      "8    Last_Name     Williams      William   93.333333\n",
      "9    Last_Name     Paterson    Patterson   94.117647\n",
      "10   Last_Name      Caldwel     Caldwell   93.333333\n",
      "11   Last_Name       Elliot      Elliott   92.307692\n",
      "12   Last_Name       Elliot     Elliott    92.307692\n",
      "13   Last_Name       Elliot        Eliot   90.909091\n",
      "14   Last_Name    Patterson     Paterson   94.117647\n",
      "15   Last_Name      Darrach       Darrah   92.307692\n",
      "16   Last_Name        Eliot       Elliot   90.909091\n",
      "17   Last_Name      William     Williams   93.333333\n",
      "18   Last_Name     Caldwell      Caldwel   93.333333\n",
      "19   Last_Name      Fallow        Fallow  100.000000\n",
      "20   Last_Name     Tatnall       Tatnall  100.000000\n",
      "21   Last_Name        Ellis       Elliss   90.909091\n",
      "22   Last_Name       Fallow      Fallow   100.000000\n",
      "23   Last_Name  Shillington  Skillington   90.909091\n",
      "24   Last_Name  Skillington  Shillington   90.909091\n",
      "25   Last_Name      Elliott     Elliott   100.000000\n",
      "26   Last_Name      Elliott       Elliot   92.307692\n",
      "27   Last_Name     McMachin    McMaichin   94.117647\n",
      "28   Last_Name    McMaichin     McMachin   94.117647\n",
      "29   Last_Name       Elliss        Ellis   90.909091\n",
      "30   Last_Name     Elliott       Elliott  100.000000\n",
      "31   Last_Name     Elliott        Elliot   92.307692\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "preDE_columns_to_check = ['First_Name', 'Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in preDE_columns_to_check:\n",
    "    preDE_unique_vals = pre1790DE[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in preDE_unique_vals:\n",
    "        result = process.extract(val, preDE_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "preDE_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(preDE_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6075,
   "id": "50baf4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790CT = pd.read_csv('liquidated_debt_certificates_CT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6076,
   "id": "a9eab079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1096    False\n",
      "1097    False\n",
      "1098    False\n",
      "1099    False\n",
      "1100    False\n",
      "Length: 1101, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "preCT_mask_strange_date =  (\n",
    "    (pd.to_numeric(pre1790CT['Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790CT['Day_Due'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {preCT_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6077,
   "id": "dd869384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1096    False\n",
      "1097    False\n",
      "1098    False\n",
      "1099    False\n",
      "1100    False\n",
      "Length: 1101, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "preCT_mask_strange_month =  (\n",
    "    (pd.to_numeric(pre1790CT['Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790CT['Month_Due'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {preCT_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6078,
   "id": "588d896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years over 1790: 0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1096    False\n",
      "1097    False\n",
      "1098    False\n",
      "1099    False\n",
      "1100    False\n",
      "Length: 1101, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values over 1790\n",
    "preCT_mask_strange_year =  (\n",
    "    (pd.to_numeric(pre1790CT['Year'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790CT['Year_Due'], errors='coerce') >1790)\n",
    ")\n",
    "print(f'\\nAmount of years over 1790: {preCT_mask_strange_year}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c42422f",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6079,
   "id": "ade9b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column     Original        Match      Score\n",
      "0   First_Name      William     Williams  93.333333\n",
      "1   First_Name       Jessee        Jesse  90.909091\n",
      "2   First_Name        Eijah       Elijah  90.909091\n",
      "3   First_Name       Elijah        Eijah  90.909091\n",
      "4   First_Name     Williams      William  93.333333\n",
      "5   First_Name       Elisha        Eisha  90.909091\n",
      "6   First_Name       Ashbel      Ashbell  92.307692\n",
      "7   First_Name      Matthew       Mathew  92.307692\n",
      "8   First_Name      Ashbell       Ashbel  92.307692\n",
      "9   First_Name    Nathaniel   Natnhaniel  94.736842\n",
      "10  First_Name    Nathaniel  Nathaniel G  90.000000\n",
      "11  First_Name     Jedediah    Jeddediah  94.117647\n",
      "12  First_Name        Simon       Simeon  90.909091\n",
      "13  First_Name        Jesse       Jessee  90.909091\n",
      "14  First_Name       Israel        Israe  90.909091\n",
      "15  First_Name       Simeon        Simon  90.909091\n",
      "16  First_Name        Eisha       Elisha  90.909091\n",
      "17  First_Name        Israe       Israel  90.909091\n",
      "18  First_Name    Natnaniel   Natnhaniel  94.736842\n",
      "19  First_Name   Natnhaniel    Nathaniel  94.736842\n",
      "20  First_Name   Natnhaniel    Natnaniel  94.736842\n",
      "21  First_Name       Mathew      Matthew  92.307692\n",
      "22  First_Name    Jeddediah     Jedediah  94.117647\n",
      "23  First_Name  Nathaniel G    Nathaniel  90.000000\n",
      "24   Last_Name      Thomson     Thompson  93.333333\n",
      "25   Last_Name     Thompson      Thomson  93.333333\n",
      "26   Last_Name      Talcott     Tallcott  93.333333\n",
      "27   Last_Name        Riley       Risley  90.909091\n",
      "28   Last_Name       Badger        Bader  90.909091\n",
      "29   Last_Name     Caldwell      Cadwell  93.333333\n",
      "30   Last_Name       Wadham      Wadhams  92.307692\n",
      "31   Last_Name      Holbert       Holber  92.307692\n",
      "32   Last_Name       Beacch        Beach  90.909091\n",
      "33   Last_Name      Cadwell     Caldwell  93.333333\n",
      "34   Last_Name        Beach       Beacch  90.909091\n",
      "35   Last_Name       Gibert      Gilbert  92.307692\n",
      "36   Last_Name        Eells       Eelles  90.909091\n",
      "37   Last_Name        Clark       Clarke  90.909091\n",
      "38   Last_Name  Trothingham  Frothingham  90.909091\n",
      "39   Last_Name     Tallcott      Talcott  93.333333\n",
      "40   Last_Name      Langdon       Landon  92.307692\n",
      "41   Last_Name       Risley        Riley  90.909091\n",
      "42   Last_Name      Stoking     Stocking  93.333333\n",
      "43   Last_Name     Stocking      Stoking  93.333333\n",
      "44   Last_Name       Clarke        Clark  90.909091\n",
      "45   Last_Name       Eelles        Eells  90.909091\n",
      "46   Last_Name       Eelles        Elles  90.909091\n",
      "47   Last_Name      Wadhams       Wadham  92.307692\n",
      "48   Last_Name  Frothingham  Trothingham  90.909091\n",
      "49   Last_Name       Barker        Baker  90.909091\n",
      "50   Last_Name        Baker       Barker  90.909091\n",
      "51   Last_Name        Elles       Eelles  90.909091\n",
      "52   Last_Name      Gilbert       Gibert  92.307692\n",
      "53   Last_Name       Landon      Langdon  92.307692\n",
      "54   Last_Name        Akins       Atkins  90.909091\n",
      "55   Last_Name        Bader       Badger  90.909091\n",
      "56   Last_Name       Atkins        Akins  90.909091\n",
      "57   Last_Name       Holber      Holbert  92.307692\n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "preCT_columns_to_check = ['First_Name', 'Last_Name','First_name.1', 'Last_name.1']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in preCT_columns_to_check:\n",
    "    preCT_unique_vals = pre1790CT[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in preCT_unique_vals:\n",
    "        result = process.extract(val, preCT_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "preCT_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(preCT_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6080,
   "id": "d00ba00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1790Marine = pd.read_csv('Marine_Liquidated_Debt_Certificates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6081,
   "id": "785e5a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "773    False\n",
      "774    False\n",
      "775    False\n",
      "776    False\n",
      "777    False\n",
      "Length: 778, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect date values over 31\n",
    "Marine_mask_strange_date =  (\n",
    "    (pd.to_numeric(pre1790Marine['Day'], errors='coerce') >31) |\n",
    "    (pd.to_numeric(pre1790Marine['Day_Due'], errors='coerce') >31)\n",
    ")\n",
    "print(f'\\nAmount of dates over 31: {Marine_mask_strange_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6082,
   "id": "852dfce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months over 12: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "773    False\n",
      "774    False\n",
      "775    False\n",
      "776    False\n",
      "777    False\n",
      "Length: 778, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect month values over 12\n",
    "Marine_mask_strange_month =  (\n",
    "    (pd.to_numeric(pre1790Marine['Month'], errors='coerce') >12) |\n",
    "    (pd.to_numeric(pre1790Marine['Month_Due'], errors='coerce') >12)\n",
    ")\n",
    "print(f'\\nAmount of months over 12: {Marine_mask_strange_month}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6083,
   "id": "4fda82dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of years over 1790: 0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "773    False\n",
      "774    False\n",
      "775    False\n",
      "776    False\n",
      "777    False\n",
      "Length: 778, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detect year values over 1790\n",
    "Marine_mask_strange_year =  (\n",
    "    (pd.to_numeric(pre1790Marine['Year'], errors='coerce') >1790) |\n",
    "    (pd.to_numeric(pre1790Marine['Year_Due'], errors='coerce') >1790)\n",
    ")\n",
    "print(f'\\nAmount of years over 1790: {Marine_mask_strange_year}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4334683",
   "metadata": {},
   "source": [
    "### Preview of Very Similar Names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6084,
   "id": "e80b0f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column                   Original                      Match  \\\n",
      "0   First_Name                    Richard                   Richard    \n",
      "1   First_Name                  Nathaniel                Nathaniel R   \n",
      "2   First_Name                       John                      John    \n",
      "3   First_Name                     Joseph                      Josep   \n",
      "4   First_Name                     Moses                       Moses   \n",
      "5   First_Name                    Philips                     Philip   \n",
      "6   First_Name                    Philips                    Philip    \n",
      "7   First_Name                     Simeon                      Simon   \n",
      "8   First_Name                Nathaniel R                  Nathaniel   \n",
      "9   First_Name                     Philip                    Philip    \n",
      "10  First_Name                     Philip                    Philips   \n",
      "11  First_Name  Estate of Lambert Wickes    Estate of Lambert Wickes   \n",
      "12  First_Name   Estate of Lambert Wickes  Estate of Lambert Wickes    \n",
      "13  First_Name                      Simon                     Simeon   \n",
      "14  First_Name                      Moses                     Moses    \n",
      "15  First_Name                      Josep                     Joseph   \n",
      "16  First_Name                   Richard                     Richard   \n",
      "17  First_Name                    Philip                      Philip   \n",
      "18  First_Name                    Philip                     Philips   \n",
      "19  First_Name                      John                        John   \n",
      "20   Last_Name                    Ingrham                   Ingraham   \n",
      "21   Last_Name                   Ingraham                    Ingrham   \n",
      "22   Last_Name                      Bower                     Brower   \n",
      "23   Last_Name                     Brower                      Bower   \n",
      "24   Last_Name                   Williams                    William   \n",
      "25   Last_Name                     Morgan                      Moran   \n",
      "26   Last_Name                   Gardiner                    Gardner   \n",
      "27   Last_Name                      Green                     Greene   \n",
      "28   Last_Name                    Gardner                   Gardiner   \n",
      "29   Last_Name                     Morant                      Moran   \n",
      "30   Last_Name            Wooder deceased           Woodrow deceased   \n",
      "31   Last_Name                      Moran                     Morgan   \n",
      "32   Last_Name                      Moran                     Morant   \n",
      "33   Last_Name            Hilton deceased          Hamilton deceased   \n",
      "34   Last_Name            Warner deceased           Gardner deceased   \n",
      "35   Last_Name           Woodrow deceased            Wooder deceased   \n",
      "36   Last_Name                      Downe                     Downer   \n",
      "37   Last_Name           Gardner deceased            Warner deceased   \n",
      "38   Last_Name          Hamilton deceased            Hilton deceased   \n",
      "39   Last_Name                    William                   Williams   \n",
      "40   Last_Name           Rassell deceased           Russell deceased   \n",
      "41   Last_Name                     Greene                      Green   \n",
      "42   Last_Name                     Downer                      Downe   \n",
      "43   Last_Name           Russell deceased           Rassell deceased   \n",
      "\n",
      "         Score  \n",
      "0   100.000000  \n",
      "1    90.000000  \n",
      "2   100.000000  \n",
      "3    90.909091  \n",
      "4   100.000000  \n",
      "5    92.307692  \n",
      "6    92.307692  \n",
      "7    90.909091  \n",
      "8    90.000000  \n",
      "9   100.000000  \n",
      "10   92.307692  \n",
      "11  100.000000  \n",
      "12  100.000000  \n",
      "13   90.909091  \n",
      "14  100.000000  \n",
      "15   90.909091  \n",
      "16  100.000000  \n",
      "17  100.000000  \n",
      "18   92.307692  \n",
      "19  100.000000  \n",
      "20   93.333333  \n",
      "21   93.333333  \n",
      "22   90.909091  \n",
      "23   90.909091  \n",
      "24   93.333333  \n",
      "25   90.909091  \n",
      "26   93.333333  \n",
      "27   90.909091  \n",
      "28   93.333333  \n",
      "29   90.909091  \n",
      "30   90.322581  \n",
      "31   90.909091  \n",
      "32   90.909091  \n",
      "33   93.750000  \n",
      "34   90.322581  \n",
      "35   90.322581  \n",
      "36   90.909091  \n",
      "37   90.322581  \n",
      "38   93.750000  \n",
      "39   93.333333  \n",
      "40   93.750000  \n",
      "41   90.909091  \n",
      "42   90.909091  \n",
      "43   93.750000  \n"
     ]
    }
   ],
   "source": [
    "# columns to check separately\n",
    "Marine_columns_to_check = ['First_Name', 'Last_Name']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in Marine_columns_to_check:\n",
    "    Marine_unique_vals = pre1790Marine[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in Marine_unique_vals:\n",
    "        result = process.extract(val, Marine_unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))\n",
    "\n",
    "# Convert to DataFrame to review\n",
    "Marine_fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(Marine_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6085,
   "id": "462d0a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3f/77w9tyf13fvfq2c4rg1tp9x40000gn/T/ipykernel_3882/672682903.py:1: DtypeWarning: Columns (1,10,12,13,17,18,23,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pre1790 = pd.read_csv('agg_debt_david.csv')\n"
     ]
    }
   ],
   "source": [
    "pre1790 = pd.read_csv('agg_debt_david.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6086,
   "id": "a0d0ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rid of duplicates\n",
    "pre1790.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6087,
   "id": "922afdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicates:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#duplicates (make sure there's no more)\n",
    "pre1790_new_dupcount = pre1790.duplicated().sum()\n",
    "print('number of duplicates:')\n",
    "print(pre1790_new_dupcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6088,
   "id": "dbf44f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Summary:\n",
      "                                       pre_missing_count  pre_missing_percent\n",
      "to whom due | title.1                              94467            99.998941\n",
      "total dollars | notes.1                            94465            99.996824\n",
      "amount | 10th                                      94458            99.989414\n",
      "exchange                                           94359            99.884617\n",
      "total dollars | notes                              94101            99.611509\n",
      "notes                                              94028            99.534234\n",
      "amount in specie | cents                           93690            99.176441\n",
      "amount | 8th                                       93550            99.028242\n",
      "to whom due | last name.1                          93222            98.681035\n",
      "to whom due | first name.1                         93219            98.677859\n",
      "delivered | year                                   92950            98.393107\n",
      "delivered | day                                    92950            98.393107\n",
      "delivered | month                                  92950            98.393107\n",
      "line strike through? | yes?                        91377            96.727993\n",
      "to whom due | title                                86782            91.863912\n",
      "amount | 90th                                      84613            89.567896\n",
      "line strike through? | note                        81662            86.444087\n",
      "time when the debt became due | year               80960            85.700978\n",
      "time when the debt became due | day                80939            85.678748\n",
      "time when the debt became due | month              80936            85.675573\n",
      "letter                                             80930            85.669221\n",
      "amount in specie | dollars                         12599            13.336791\n",
      "to whom due | last name                             4351             4.605792\n",
      "amount | dollars                                     866             0.916713\n",
      "state                                                767             0.811915\n",
      "to whom due | first name                              41             0.043401\n",
      "date of the certificate | day                         34             0.035991\n",
      "date of the certificate | month                       16             0.016937\n",
      "date of the certificate | year                        15             0.015878\n",
      "org_index                                              0             0.000000\n",
      "org_file                                               0             0.000000\n",
      "Unnamed: 0                                             0             0.000000\n"
     ]
    }
   ],
   "source": [
    "#missing\n",
    "pre_missing_summary = pre1790.isnull().sum().to_frame(name='pre_missing_count')\n",
    "pre_missing_summary['pre_missing_percent'] = 100 * pre_missing_summary['pre_missing_count'] / len(pre1790)\n",
    "print(\"Missing Value Summary:\")\n",
    "print(pre_missing_summary.sort_values('pre_missing_percent', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295855f4",
   "metadata": {},
   "source": [
    "### Important note:\n",
    "A lot of these do have 99% missing; I have checked the data set and for the most part these columns to the right of org_index are generally empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6089,
   "id": "5eac4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncombined rows \n",
    "pre_amount_fields = ['amount | dollars', 'amount | 90th']\n",
    "pre_mask_name_missing = pre1790[[\n",
    "    'to whom due | first name',\n",
    "    'to whom due | last name',\n",
    "    'to whom due | first name.1',\n",
    "    'to whom due | last name.1',\n",
    "    'to whom due | title.1',\n",
    "    'to whom due | title'\n",
    "]].isnull().any(axis=1)\n",
    "\n",
    "pre_mask_amount_present = pre1790[pre_amount_fields].notnull().any(axis=1)\n",
    "pre_mask_uncombined = pre_mask_name_missing & pre_mask_amount_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6090,
   "id": "88a76dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value counts for all string columns:\n",
      "                                      pre_unique_values\n",
      "to whom due | last name                           11418\n",
      "to whom due | first name                           3696\n",
      "line strike through? | note                        2252\n",
      "total dollars | notes                               177\n",
      "to whom due | last name.1                           166\n",
      "time when the debt became due | day                 114\n",
      "to whom due | first name.1                          107\n",
      "to whom due | title                                  85\n",
      "notes                                                76\n",
      "time when the debt became due | year                 55\n",
      "exchange                                             36\n",
      "letter                                               23\n",
      "state                                                11\n",
      "org_file                                              6\n",
      "to whom due | title.1                                 2\n"
     ]
    }
   ],
   "source": [
    "#typos? (more unique values than there should be)\n",
    "pre_string_cols = pre1790.select_dtypes(include='object')\n",
    "pre_string_uniques = pre_string_cols.nunique(dropna=False).to_frame(name='pre_unique_values')\n",
    "print(\"Unique value counts for all string columns:\")\n",
    "print(pre_string_uniques.sort_values('pre_unique_values', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6091,
   "id": "7ef69d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3f/77w9tyf13fvfq2c4rg1tp9x40000gn/T/ipykernel_3882/3962744037.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pre1790[col] = pd.to_datetime(pre1790[col], errors='coerce')\n",
      "/var/folders/3f/77w9tyf13fvfq2c4rg1tp9x40000gn/T/ipykernel_3882/3962744037.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pre1790[col] = pd.to_datetime(pre1790[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "#convert dates to datetime (format)\n",
    "pre_date_cols = [col for col in pre1790.columns if ('date' in col.lower()) or ('time' in col.lower())]\n",
    "for col in pre_date_cols:\n",
    "    pre1790[col] = pd.to_datetime(pre1790[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6092,
   "id": "58833a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting numbers to number types (format)\n",
    "pre_numeric_pattern = ['amount']\n",
    "pre_numeric_obj_cols = [col for col in pre1790.select_dtypes(include = 'object').columns if any (pat in col for pat in pre_numeric_pattern)]\n",
    "for col in pre_numeric_obj_cols:\n",
    "    pre1790[col] = pd.to_numeric(pre1790[col].str.replace(',', ''), errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6093,
   "id": "f52b0144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007Amount of negative values: 0\n"
     ]
    }
   ],
   "source": [
    "#detect negatives\n",
    "pre_mask_negative = pre1790[[col for col in pre1790.columns if any(pat in col for pat in pre_numeric_pattern)]].lt(0).any(axis = 1)\n",
    "print(f'\\aAmount of negative values: {pre_mask_negative.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6094,
   "id": "c207d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of dates over 31: 9\n"
     ]
    }
   ],
   "source": [
    "#detect date values over 31\n",
    "pre_mask_strange_date = pd.to_numeric(pre1790['date of the certificate | day'], errors='coerce') >31\n",
    "pre_mask_strange_due_date = pd.to_numeric(pre1790['time when the debt became due | day'], errors='coerce') >31\n",
    "strange_date_sum = pre_mask_strange_date.sum() + pre_mask_strange_due_date.sum()\n",
    "print(f'\\nAmount of dates over 31: {strange_date_sum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6095,
   "id": "b4506edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of months that are over 12: 2505\n"
     ]
    }
   ],
   "source": [
    "#detect month values over 12 \n",
    "pre_mask_strange_month= pd.to_numeric(pre1790['date of the certificate | month'], errors='coerce') >12\n",
    "pre_mask_strange_due_month= pd.to_numeric(pre1790['time when the debt became due | month'], errors='coerce') >12\n",
    "strange_month_sum = pre_mask_strange_month.sum() + pre_mask_strange_due_month.sum()\n",
    "print(f'\\nAmount of months that are over 12: {strange_month_sum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6096,
   "id": "92cfcf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to check separately\n",
    "columns_to_check = ['to whom due | first name', 'to whom due | last name', 'to whom due | first name.1','to whom due | last name.1']\n",
    "\n",
    "threshold = 90\n",
    "all_matches = []\n",
    "\n",
    "for col in columns_to_check:\n",
    "    unique_vals = pre1790[col].dropna().unique().tolist()\n",
    "    \n",
    "    for val in unique_vals:\n",
    "        result = process.extract(val, unique_vals, scorer=fuzz.token_sort_ratio)\n",
    "        \n",
    "        for match_val, score, _ in result:\n",
    "            if val != match_val and score >= threshold:\n",
    "                all_matches.append((col, val, match_val, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6097,
   "id": "54a9c8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Column  Original     Match       Score\n",
      "0      to whom due | first name   William  Williams   93.333333\n",
      "1      to whom due | first name   William    Wiliam   92.307692\n",
      "2      to whom due | first name   William    Willam   92.307692\n",
      "3      to whom due | first name   Eleazer  Elieazer   93.333333\n",
      "4      to whom due | first name      John     John   100.000000\n",
      "...                         ...       ...       ...         ...\n",
      "5309  to whom due | last name.1   Wilkoff    Wikoff   92.307692\n",
      "5310  to whom due | last name.1   Wilkoff    Wiloff   92.307692\n",
      "5311  to whom due | last name.1  Sergeant   Sergant   93.333333\n",
      "5312  to whom due | last name.1   Sergant  Sergeant   93.333333\n",
      "5313  to whom due | last name.1  Sterling   Sterlin   93.333333\n",
      "\n",
      "[5314 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame to review\n",
    "fuzzy_matches = pd.DataFrame(all_matches, columns=['Column', 'Original', 'Match', 'Score'])\n",
    "print(fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6098,
   "id": "bb7bcac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suspicious rows \n",
    "pre1790['listed suspicious row'] = False\n",
    "pre1790['reason for being suspicious'] = ''\n",
    "\n",
    "pre_mask_many_missing = pre1790.isnull().sum(axis=1) > pre1790.shape[1]/4\n",
    "pre1790.loc[pre_mask_many_missing, 'listed suspicious row'] = True\n",
    "pre1790.loc[pre_mask_many_missing, 'reason for being suspicious'] += 'More than 25% missing'\n",
    "\n",
    "pre1790.loc[pre_mask_negative, 'listed suspicious row'] = True\n",
    "pre1790.loc[pre_mask_negative, 'reason for being suspicious'] += 'Negative value'\n",
    "\n",
    "pre1790.loc[pre_mask_uncombined, 'listed suspicious row'] = True\n",
    "pre1790.loc[pre_mask_uncombined, 'reason for being suspicious'] = 'Uncombined Row, name is missing but amount is not'\n",
    "\n",
    "\n",
    "pre1790.loc[pre_mask_strange_date, 'listed suspicious row'] = True\n",
    "pre1790.loc[pre_mask_strange_date, 'reason for being suspicious'] = 'Date is over 31'\n",
    "\n",
    "\n",
    "pre1790.loc[pre_mask_strange_month, 'listed suspicious row'] = True\n",
    "pre1790.loc[pre_mask_strange_month, 'reason for being suspicious'] = 'Month is after December'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6099,
   "id": "d0d12e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean vs suspicious\n",
    "clean_pre1790 = pre1790[~pre1790['listed suspicious row']]\n",
    "suspicious_pre1790 = pre1790[pre1790['listed suspicious row']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6100,
   "id": "bb5477a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save clean & suspicious\n",
    "clean_pre1790.to_csv(\"cleaned_agg_debt_david.csv\", index=False)\n",
    "suspicious_pre1790.to_csv(\"suspicious_agg_debt_david.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6101,
   "id": "a4447ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspicious rows: 94468\n",
      "\n",
      "Preview of Suspicious Rows:\n",
      "   Unnamed: 0 letter date of the certificate | month  \\\n",
      "0           0      A   1970-01-01 00:00:00.000000006   \n",
      "1           1      B   1970-01-01 00:00:00.000000006   \n",
      "2           2      C   1970-01-01 00:00:00.000000007   \n",
      "3           3      D   1970-01-01 00:00:00.000000007   \n",
      "4           4      E   1970-01-01 00:00:00.000000007   \n",
      "\n",
      "  date of the certificate | day date of the certificate | year  \\\n",
      "0 1970-01-01 00:00:00.000000028  1970-01-01 00:00:00.000001783   \n",
      "1 1970-01-01 00:00:00.000000030  1970-01-01 00:00:00.000001783   \n",
      "2 1970-01-01 00:00:00.000000001  1970-01-01 00:00:00.000001783   \n",
      "3 1970-01-01 00:00:00.000000002  1970-01-01 00:00:00.000001783   \n",
      "4 1970-01-01 00:00:00.000000003  1970-01-01 00:00:00.000001783   \n",
      "\n",
      "  to whom due | first name to whom due | last name to whom due | title  \\\n",
      "0                   Thomas               Dickenson                 NaN   \n",
      "1                     Paul                   Noyes                 NaN   \n",
      "2                  William                Redfield                 NaN   \n",
      "3                  Eleazer                  Conant                 NaN   \n",
      "4                 Prentice                  Hoomer               Lieut   \n",
      "\n",
      "  to whom due | first name.1 to whom due | last name.1  ...  \\\n",
      "0                       Ezek                     Lewis  ...   \n",
      "1                        NaN                       NaN  ...   \n",
      "2                        NaN                       NaN  ...   \n",
      "3                        NaN                       NaN  ...   \n",
      "4                        NaN                       NaN  ...   \n",
      "\n",
      "  amount in specie | dollars amount in specie | cents amount | 8th  \\\n",
      "0                        NaN                      NaN          NaN   \n",
      "1                        NaN                      NaN          NaN   \n",
      "2                        NaN                      NaN          NaN   \n",
      "3                        NaN                      NaN          NaN   \n",
      "4                        NaN                      NaN          NaN   \n",
      "\n",
      "  delivered | month  delivered | day  delivered | year  total dollars | notes  \\\n",
      "0               NaN              NaN               NaN                    NaN   \n",
      "1               NaN              NaN               NaN                    NaN   \n",
      "2               NaN              NaN               NaN                    NaN   \n",
      "3               NaN              NaN               NaN                    NaN   \n",
      "4               NaN              NaN               NaN                    NaN   \n",
      "\n",
      "  total dollars | notes.1 listed suspicious row  \\\n",
      "0                     NaN                  True   \n",
      "1                     NaN                  True   \n",
      "2                     NaN                  True   \n",
      "3                     NaN                  True   \n",
      "4                     NaN                  True   \n",
      "\n",
      "                         reason for being suspicious  \n",
      "0  Uncombined Row, name is missing but amount is not  \n",
      "1  Uncombined Row, name is missing but amount is not  \n",
      "2  Uncombined Row, name is missing but amount is not  \n",
      "3  Uncombined Row, name is missing but amount is not  \n",
      "4  Uncombined Row, name is missing but amount is not  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "#print suspicious row summary\n",
    "print(f\"Suspicious rows: {pre1790['listed suspicious row'].sum()}\")\n",
    "print(\"\\nPreview of Suspicious Rows:\")\n",
    "print(suspicious_pre1790.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
