{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 387,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Structures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "outputs": [],
   "source": [
    "# define dictionary to convert between different naming schematics\n",
    "statedict = {'PA': 'Pennsylvania', 'CT': 'Connecticut', 'MA': 'Massachusetts', 'NH': 'New Hampshire', 'DE': 'Delaware',\n",
    "             'NC': 'North Carolina', 'GA': 'Georgia', 'NY': 'New York', 'NJ': 'New Jersey', 'RI': 'Rhode Island',\n",
    "             'VA': 'Virginia', 'MD': 'Maryland', 'SC': 'South Carolina', 'VT': 'Vermont'}\n",
    "statedict_rev = dict(zip(statedict.values(), statedict.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "outputs": [],
   "source": [
    "def parseLocationString(location, nametype):\n",
    "    \"\"\"\n",
    "    function to parse location string that I can use when cleaning data\n",
    "\n",
    "    :param location: string contaiing information about town county state and name_type separated by |\n",
    "    :param nametype: type of location\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if nametype == 'town':\n",
    "        return location.split(\" | \")[0], location.split(\" | \")[1], location.split(\" | \")[2], location.split(\" | \")[3]\n",
    "    elif nametype == 'county':\n",
    "        return \"\", location.split(\" | \")[0], location.split(\" | \")[1], location.split(\" | \")[2]\n",
    "    else:  #nametype == 'state'\n",
    "        return \"\", \"\", location.split(\" | \")[0], location.split(\" | \")[1]\n",
    "\n",
    "\n",
    "def tNameList(lst):\n",
    "    \"\"\"\n",
    "    takes a list of names and returns a string of names separated by \" | \", sorted and with duplicates removed, and with \"\" removed\n",
    "    :param lst: input lst\n",
    "    :return: string with names joined\n",
    "    \"\"\"\n",
    "    return \" | \".join(sorted(list(set([ele for ele in lst if ele != \"\"]))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "outputs": [],
   "source": [
    "# aggregated debt data\n",
    "CD_clean = pd.read_csv('../data_clean/aggregated_CD_post1790.csv', index_col=0).fillna(\"\").drop_duplicates()\n",
    "# all names that were scraped by the scraper\n",
    "scraped_names = pd.read_csv('scrape_tools/name_list_scraped.csv', index_col=0).fillna(\"\").drop_duplicates()\n",
    "# results of scraping\n",
    "match_df = pd.read_csv('scrape_tools/scrape_results.csv', index_col=0).fillna(\"\").drop_duplicates()\n",
    "# table that organizes results of scraping based off our list of names\n",
    "name_df = pd.read_csv('clean_tools/name_list.csv', index_col=0).fillna(\"\").drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Missing Occupations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "outputs": [],
   "source": [
    "# sometimes, an occupation is listed in the name but is not in the occupation column. we want to correct for this by adding the occupaiton title into the occupation column\n",
    "# do this for treasurers\n",
    "CD_clean.loc[CD_clean[CD_clean['Name'].apply(lambda x: 'treasurer' in x.lower())].index, 'occupation'] = [\n",
    "    ele if ele != '' else 'Treasurer' for ele in\n",
    "    CD_clean.loc[CD_clean[CD_clean['Name'].apply(lambda x: 'treasurer' in x.lower())].index, 'occupation']]\n",
    "# do this for administrators\n",
    "CD_clean.loc[\n",
    "    CD_clean[CD_clean['Name'].apply(lambda x: ' adm' in x.lower() or 'adm ' in x.lower())].index, 'occupation'] = [\n",
    "    ele if ele != '' else 'Administrator' for ele in CD_clean.loc[\n",
    "        CD_clean[CD_clean['Name'].apply(lambda x: ' adm' in x.lower() or 'adm ' in x.lower())].index, 'occupation']]\n",
    "# do this for trustees\n",
    "CD_clean.loc[CD_clean[CD_clean['Name'].apply(lambda x: ' trust ' in x.lower())].index, 'occupation'] = [\n",
    "    ele if ele != '' else 'Administrator' for ele in\n",
    "    CD_clean.loc[CD_clean[CD_clean['Name'].apply(lambda x: ' trust ' in x.lower())].index, 'occupation']]\n",
    "# do this for guardians\n",
    "CD_clean.loc[CD_clean[CD_clean['Name'].apply(lambda x: 'guard' in x.lower())].index, 'occupation'] = [\n",
    "    ele if ele != 'Yeoman' else 'Guardian | Yeoman' for ele in\n",
    "    CD_clean.loc[CD_clean[CD_clean['Name'].apply(lambda x: 'guard' in x.lower())].index, 'occupation']]\n",
    "# do this for school committee members\n",
    "CD_clean.loc[CD_clean[CD_clean['Name'].apply(lambda x: 'school' in x.lower())].index, 'occupation'] = [\n",
    "    ele if ele != '' else 'School Committee' for ele in\n",
    "    CD_clean.loc[CD_clean[CD_clean['Name'].apply(lambda x: 'school' in x.lower())].index, 'occupation']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "outputs": [],
   "source": [
    "# add in both names in cases where one row is identified with multiple name\n",
    "CD_merged = pd.merge(CD_clean, name_df,\n",
    "                     how='left',\n",
    "                     on=['Name', 'new_town', 'county', 'new_state', 'country', 'name_type', ])\n",
    "# add in match index and status\n",
    "CD_merged_mind = pd.merge(CD_merged,\n",
    "                          scraped_names[\n",
    "                              ['Fn_Fix', 'Ln_Fix', 'new_town', 'county', 'new_state', 'country', 'name_type', 'url',\n",
    "                               'Match Index', 'Match Status']],\n",
    "                          how='left',\n",
    "                          on=['Fn_Fix', 'Ln_Fix', 'new_town', 'county', 'new_state', 'country', 'name_type'])\n",
    "# combine names\n",
    "CD_merged_mind['Full Search Name'] = CD_merged_mind['Fn_Fix'] + ' ' + CD_merged_mind['Ln_Fix']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(CD_clean.loc[[8, 9]][['Name', 'state_data', 'state_data_index', 'new_town', 'county', 'new_state', 'country', 'name_type',]].to_markdown())\\nprint(name_df.loc[[8, 9]][['Name', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type',]].to_markdown())\\nprint(CD_merged.loc[[8,9,10]][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type',]].to_markdown())\""
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(CD_clean.loc[[8, 9]][['Name', 'state_data', 'state_data_index', 'new_town', 'county', 'new_state', 'country', 'name_type',]].to_markdown())\n",
    "print(name_df.loc[[8, 9]][['Name', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type',]].to_markdown())\n",
    "print(CD_merged.loc[[8,9,10]][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type',]].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(CD_merged.loc[[8]][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type',]].to_markdown())\\nprint(scraped_names.loc[[8]][['Fn_Fix', 'Ln_Fix','county', 'new_state', 'country', 'name_type','Match Index', 'Match Status']].to_markdown())\\nprint(CD_merged_mind.loc[[8]][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'Full Search Name', 'county', 'new_state', 'country', 'name_type','Match Index', 'Match Status']].to_markdown())\""
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(CD_merged.loc[[8]][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type',]].to_markdown())\n",
    "print(scraped_names.loc[[8]][['Fn_Fix', 'Ln_Fix','county', 'new_state', 'country', 'name_type','Match Index', 'Match Status']].to_markdown())\n",
    "print(CD_merged_mind.loc[[8]][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'Full Search Name', 'county', 'new_state', 'country', 'name_type','Match Index', 'Match Status']].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Group Names - Using Ancestry.com Matches\n",
    "basically group_name_df is a list of names we're going to group together and then we perform the grouping process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5s/dvrxt95949x1pm_sjxm85lj00000gn/T/ipykernel_51442/2871475831.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  group_name_df['Rep Name'] = group_name_df['Full Search Name'].apply(lambda x: max(x, key=len))\n"
     ]
    }
   ],
   "source": [
    "# find names that are associated with multiple search names because they're actually the same name, by grouping based on match index (have same match index)\n",
    "# these names are associated with multiple names because of spelling variation\n",
    "# remove names with \"\" Match Index - too many\n",
    "grouped_names = CD_merged_mind[CD_merged_mind['Match Index'] != \"\"].groupby('Match Index').agg(\n",
    "    {'Full Search Name': lambda x: list(set(x))}).reset_index()\n",
    "group_name_df = grouped_names[grouped_names['Full Search Name'].apply(lambda x: len(x) > 1)]\n",
    "# denote the name we use moving forward as the name with the longest length (most information)\n",
    "group_name_df['Rep Name'] = group_name_df['Full Search Name'].apply(lambda x: max(x, key=len))\n",
    "group_name_df = group_name_df.explode('Full Search Name').reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [],
   "source": [
    "# some manual corrections of the actual name we want to use for grouping\n",
    "group_name_df.loc[group_name_df[group_name_df['Full Search Name'].apply(\n",
    "    lambda x: 'Israel Joseph' in x)].index, 'Rep Name'] = 'Israel Joseph'\n",
    "group_name_df.loc[group_name_df[group_name_df['Full Search Name'].apply(\n",
    "    lambda x: 'William Larned' in x or 'William Learned' in x)].index, 'Rep Name'] = 'William Larned'\n",
    "group_name_df.loc[group_name_df[group_name_df['Full Search Name'].apply(\n",
    "    lambda x: 'Mathew Watson' in x or 'Matthew Watson' in x)].index, 'Rep Name'] = 'Mathew Watson'\n",
    "group_name_df.drop(group_name_df[group_name_df['Rep Name'] + group_name_df[\n",
    "    'Full Search Name'] == 'Samuel Vernon 2NdSamuel Vernon Ii'].index, inplace=True)\n",
    "group_name_df.drop(group_name_df[group_name_df['Rep Name'] + group_name_df[\n",
    "    'Full Search Name'] == 'Thomas Cloyd HalseyThomas Lloyd Halsey'].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "outputs": [],
   "source": [
    "# we want to group all the mispelled names together under the same name, and set their information to be the same as the name that is representing them - the rep name\n",
    "# first we find all names that are being grouped under a name that is not theirs\n",
    "group_name_df = group_name_df[group_name_df['Full Search Name'] != group_name_df['Rep Name']]\n",
    "\n",
    "# define new columns that represent the data we will use to group the data for\n",
    "# don't want to change original columns etc so we don't have to change data\n",
    "CD_merged_mind[\n",
    "    ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type', 'Group Match Index',\n",
    "     'Group Match Status', 'Group Match Url']] = CD_merged_mind[\n",
    "    ['Full Search Name', 'new_town', 'county', 'new_state', 'country', 'name_type', 'Match Index', 'Match Status',\n",
    "     'url']]\n",
    "\n",
    "# iterate through names\n",
    "for ind in group_name_df.index:\n",
    "    # obtain data - list of names and indices that we're replacing and the indexes of the data we are changing, and the indices where we're getting the data we're changing it to from\n",
    "    match_ind, full_name, rep_name = group_name_df.loc[ind, ['Match Index', 'Full Search Name', 'Rep Name']]\n",
    "    change_ind = CD_merged_mind[\n",
    "        CD_merged_mind.apply(lambda x: x['Match Index'] == match_ind and (x['Full Search Name'] == full_name or x['Full Search Name'] == rep_name),\n",
    "                             axis=1)].index\n",
    "    info_ind = CD_merged_mind[\n",
    "        CD_merged_mind.apply(lambda x: x['Match Index'] == match_ind and x['Full Search Name'] == rep_name,\n",
    "                             axis=1)].index\n",
    "\n",
    "    # sometimes the particular rep name has multiple types of locations - we want to pick the one that is most specific, so town > county > state\n",
    "    # we will unify these locations later\n",
    "    if CD_merged_mind.loc[info_ind, ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country',\n",
    "                                     'Group Name Type']].drop_duplicates().shape[0] > 1:\n",
    "        # possible data we are replacing with\n",
    "        possibilities = CD_merged_mind.loc[\n",
    "            info_ind, ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type',\n",
    "                       'Group Match Index', 'Group Match Status', 'Group Match Url']].drop_duplicates()\n",
    "        if possibilities[possibilities['Group Name Type'] == 'town'].shape[0] == 1:\n",
    "            possibilities = possibilities[possibilities['Group Name Type'] == 'town'].values.tolist()\n",
    "        elif possibilities[possibilities['Group Name Type'] == 'county'].shape[0] == 1:\n",
    "            possibilities = possibilities[possibilities['Group Name Type'] == 'county'].values.tolist()\n",
    "        elif possibilities[possibilities['Group Name Type'] == 'state'].shape[\n",
    "            0] == 1 or rep_name == 'Benjamin Tallmadge':\n",
    "            possibilities = possibilities[possibilities['Group Name Type'] == 'state'].values.tolist()\n",
    "            if rep_name == 'Benjamin Tallmadge':\n",
    "                possibilities = [ele for ele in possibilities if ele[3] == 'CT']\n",
    "        else:\n",
    "            possibilities = possibilities[possibilities['Group Name Type'] == 'country'].values.tolist()\n",
    "    # if there's only one type of location, no selection process needed\n",
    "    else:\n",
    "        possibilities = CD_merged_mind.loc[\n",
    "            info_ind, ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type',\n",
    "                       'Group Match Index', 'Group Match Status', 'Group Match Url']].drop_duplicates().values.tolist()\n",
    "    # make sure we're only assigning one row of data\n",
    "    assert (len(possibilities) == 1)\n",
    "    CD_merged_mind.loc[\n",
    "        change_ind, ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type',\n",
    "                     'Group Match Index', 'Group Match Status', 'Group Match Url']] = [possibilities[0]]  * len(change_ind)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(CD_merged_mind[CD_merged_mind['Group Name'].apply(lambda x: x in ['Richard Woottan', 'Gassaway Watkins'])][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type','Match Index', 'Match Status','Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type','Group Match Index', 'Group Match Status',]].to_markdown())\""
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(CD_merged_mind[CD_merged_mind['Group Name'].apply(lambda x: x in ['Richard Woottan', 'Gassaway Watkins'])][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type','Match Index', 'Match Status','Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type','Group Match Index', 'Group Match Status',]].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Group Names - Fuzzy Matching\n",
    "used fuzzy matching to find list of names, then edited the list manually (result is name_agg.csv) - then applied process of replacement\n",
    "first  two code blocks show example of how I identified names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nny_names = CD_merged_mind[CD_merged_mind['state'] == 'NY']['Group Name'].unique()\\nny_names = [n for n in ny_names if not pd.isnull(n)]\\nmatch_names = [process.extract(name, ny_names, score_cutoff = 80) for name in ny_names]\\nmatch_names_fin = [m for m in match_names if len(m) != 1]\\ni = -1\\n\""
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ny_names = CD_merged_mind[CD_merged_mind['state'] == 'NY']['Group Name'].unique()\n",
    "ny_names = [n for n in ny_names if not pd.isnull(n)]\n",
    "match_names = [process.extract(name, ny_names, score_cutoff = 80) for name in ny_names]\n",
    "match_names_fin = [m for m in match_names if len(m) != 1]\n",
    "i = -1\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\ni+=1\\nname_options = [n[0] for n in match_names_fin[i]]\\nCD_merged_mind[CD_merged_mind.apply(lambda x: x['Group State'] == 'NY' and x['Group Name'] in name_options, axis = 1)][[#'Name',\\n    'Group Name', 'Group State', 'Group Name Type', 'Group Match Index', 'Group Match Status', 'Group Match Url']].drop_duplicates()\\n\""
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "i+=1\n",
    "name_options = [n[0] for n in match_names_fin[i]]\n",
    "CD_merged_mind[CD_merged_mind.apply(lambda x: x['Group State'] == 'NY' and x['Group Name'] in name_options, axis = 1)][[#'Name',\n",
    "    'Group Name', 'Group State', 'Group Name Type', 'Group Match Index', 'Group Match Status', 'Group Match Url']].drop_duplicates()\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [],
   "source": [
    "# import names that we want to group together\n",
    "# these might not be names that have the same match index, or names that have match index == \"\"\n",
    "# contains location because we can only identify a person uniquely through name + location\n",
    "rep_names = pd.read_csv('clean_tools/name_agg.csv')\n",
    "rep_names['original'] = rep_names['original'].apply(lambda x: x.replace(\"\\t\", \" \"))\n",
    "rep_names['new'] = rep_names['new'].apply(lambda x: x.replace(\"\\t\", \" \"))\n",
    "rep_names['location'] = rep_names['location'].apply(lambda x: x.replace(\"\\t\", \" \") if not pd.isnull(x) else x)\n",
    "# notes - we identified the names using fuzzy matching, and then picked the name that was \"right\" by finding whether it was matched, or using ancestry.com to see which one had the most records that seemed correct\n",
    "# this was quite an involved process - above commented code demonstrates how you would iterate through examining the options"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walter Storey Chandler Walter S Chandler\n",
      "Dorethea Losh Dorothea Losh\n",
      "Welcome Allen William Allen\n"
     ]
    }
   ],
   "source": [
    "# we want to replace the location/info of the original name with the info of the new name\n",
    "for og_name, new_name, loc in zip(rep_names['original'], rep_names['new'], rep_names['location']):\n",
    "    # obtain values that we want to set the person's information to\n",
    "    if pd.isnull(loc):\n",
    "        vals = CD_merged_mind[CD_merged_mind['Group Name'] == new_name][\n",
    "            ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type',\n",
    "             'Group Match Index', 'Group Match Status', 'Group Match Url']].drop_duplicates().values.tolist()\n",
    "    else:\n",
    "        town, county, state, nametype = parseLocationString(loc, loc.split(\" | \")[-1])\n",
    "        vals = CD_merged_mind[CD_merged_mind.apply(\n",
    "            lambda x: x['Group Name'] == new_name and x['Group Town'] == town and x['Group County'] == county and x[\n",
    "                'Group State'] == state and x['Group Name Type'] == nametype, axis=1)][\n",
    "            ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type',\n",
    "             'Group Match Index', 'Group Match Status', 'Group Match Url']].drop_duplicates().values.tolist()\n",
    "    if new_name == 'Henry Huttenstein':\n",
    "        vals = [ele for ele in vals if ele[1] == 'Lancaster']\n",
    "\n",
    "    # obtain index of the name whose information we want to replace\n",
    "    # two cases - for if we need to input location information or not\n",
    "    if CD_merged_mind[CD_merged_mind.apply(lambda x: x['Group Name'] == og_name, axis=1)][\n",
    "        ['Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type']].drop_duplicates().shape[\n",
    "        0] > 1:\n",
    "        # special exception\n",
    "        if og_name == 'Benjamin Brown' or og_name == 'William Wheater':\n",
    "            rep_ind = CD_merged_mind[\n",
    "                CD_merged_mind.apply(lambda x: x['Group Name'] == og_name and x['Group State'] == 'RI', axis=1)].index\n",
    "        else:\n",
    "            rep_ind = CD_merged_mind[CD_merged_mind.apply(\n",
    "                lambda x: x['Group Name'] == og_name and x['Group Town'] == town and x['Group County'] == county and x[\n",
    "                    'Group State'] == state and x['Group Name Type'] == nametype, axis=1)].index\n",
    "    else:\n",
    "        rep_ind = CD_merged_mind[CD_merged_mind.apply(lambda x: x['Group Name'] == og_name, axis=1)].index\n",
    "\n",
    "    # make sure we're only assigning one row of data - otherwise we have issues\n",
    "    if len(vals) == 1:\n",
    "        CD_merged_mind.loc[\n",
    "            rep_ind, ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type',\n",
    "                      'Group Match Index', 'Group Match Status', 'Group Match Url']] = vals[0]\n",
    "    if len(vals) > 1:\n",
    "        print(og_name, new_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(rep_names[rep_names['new'].apply(lambda x: x == 'Hannah Howley' or x == 'John Salter')].to_markdown())\\nprint(CD_merged_mind[CD_merged_mind['Group Name'].apply(lambda x: x == 'Hannah Howley' or x == 'John Salter')][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type','Match Index', 'Match Status','Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type','Group Match Index', 'Group Match Status',]].to_markdown())\""
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(rep_names[rep_names['new'].apply(lambda x: x == 'Hannah Howley' or x == 'John Salter')].to_markdown())\n",
    "print(CD_merged_mind[CD_merged_mind['Group Name'].apply(lambda x: x == 'Hannah Howley' or x == 'John Salter')][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type','Match Index', 'Match Status','Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type','Group Match Index', 'Group Match Status',]].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Group - same name, within state\n",
    "now, we have people who live in the same state with the same name - we want to figure out whether they represent the same identity\n",
    "our criteria is that the information must not contradict (cannot have two different counties/towns), and they must reside within the asme state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [],
   "source": [
    "# now, there are some names that are the same, but have different locations. We think that we can identify these by finding cases where the name is the same, but the locations differ (up to the state level)\n",
    "# example: Man in montgomery MD, Man in MD\n",
    "dup_state = CD_merged_mind[\n",
    "    ['Group Name', 'Group State', 'Group County', 'Group Town', 'Group Name Type']].drop_duplicates().groupby(\n",
    "    ['Group Name', 'Group State']).count().reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [],
   "source": [
    "for ind in dup_state[dup_state['Group County'] > 1].index:\n",
    "    # information from dataframe with potentially duplicated individuals (people with same name, identity but different locations)\n",
    "    name, state = dup_state.loc[ind, ['Group Name', 'Group State']]\n",
    "\n",
    "    # values of all possible name types\n",
    "    vals =  CD_merged_mind[CD_merged_mind.apply(lambda x: x['Group Name'] == name and x['Group State'] == state, axis=1)][\n",
    "        'Group Name Type'].drop_duplicates().tolist()\n",
    "    # list of unique towns\n",
    "    towns = [ele for ele in CD_merged_mind[\n",
    "        CD_merged_mind.apply(lambda x: x['Group Name'] == name and x['Group State'] == state, axis=1)][\n",
    "        'Group Town'].drop_duplicates().tolist() if ele != \"\"]\n",
    "    # list of unique counties\n",
    "    counties = [ele for ele in CD_merged_mind[\n",
    "        CD_merged_mind.apply(lambda x: x['Group Name'] == name and x['Group State'] == state, axis=1)][\n",
    "        'Group County'].drop_duplicates().tolist() if ele != \"\"]\n",
    "\n",
    "    # let towns, counties length equal 1 (excluding \"\") because we don't want contradicting information. for example, montgomery MD and anne arundel MD contradict but annapolis, anne arundel MD and anne arundel MD don't contradict because one is more specific than the other\n",
    "    if len(vals) > 1 and dup_state.loc[ind, 'Group County'] < 3 and len(towns) == 1 and len(counties) == 1:\n",
    "        # find what is the most specific location we have\n",
    "        if 'town' in vals:\n",
    "            change_val = CD_merged_mind.loc[CD_merged_mind.apply(\n",
    "                lambda x: x['Group Name'] == name and x['Group State'] == state and x['Group Name Type'] == 'town',\n",
    "                axis=1), ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Name Type',\n",
    "                          'Group Match Index', 'Group Match Status', 'Group Match Url']].drop_duplicates().values\n",
    "        elif 'county' in vals:\n",
    "            change_val = CD_merged_mind.loc[CD_merged_mind.apply(\n",
    "                lambda x: x['Group Name'] == name and x['Group State'] == state and x['Group Name Type'] == 'county',\n",
    "                axis=1), ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Name Type',\n",
    "                          'Group Match Index', 'Group Match Status', 'Group Match Url']].drop_duplicates().values\n",
    "        else:  # 'state' in vals\n",
    "            change_val = CD_merged_mind.loc[CD_merged_mind.apply(\n",
    "                lambda x: x['Group Name'] == name and x['Group State'] == state and x['Group Name Type'] == 'state',\n",
    "                axis=1), ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Name Type',\n",
    "                          'Group Match Index', 'Group Match Status', 'Group Match Url']].drop_duplicates().values\n",
    "\n",
    "        change_ind = CD_merged_mind[\n",
    "            CD_merged_mind.apply(lambda x: x['Group Name'] == name and x['Group State'] == state, axis=1)].index\n",
    "        CD_merged_mind.loc[change_ind, ['Group Name', 'Group Town', 'Group County', 'Group State', 'Group Name Type',\n",
    "                                        'Group Match Index', 'Group Match Status', 'Group Match Url']] = change_val[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(dup_state[dup_state['Group Name'].apply(lambda x: x in ['Abigail Robbins', 'Abner Johnson'])].to_markdown())\\nprint(CD_merged_mind[CD_merged_mind.apply(lambda x: x['Group Name'] in ['Abigail Robbins', 'Abner Johnson'] and x['Group State'] == 'CT', axis=1)][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type','Match Index', 'Match Status','Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type','Group Match Index', 'Group Match Status',]].to_markdown())\""
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(dup_state[dup_state['Group Name'].apply(lambda x: x in ['Abigail Robbins', 'Abner Johnson'])].to_markdown())\n",
    "print(CD_merged_mind[CD_merged_mind.apply(lambda x: x['Group Name'] in ['Abigail Robbins', 'Abner Johnson'] and x['Group State'] == 'CT', axis=1)][['Name', 'state_data', 'state_data_index', 'Name_Fix', 'Fn_Fix', 'Ln_Fix', 'county', 'new_state', 'country', 'name_type','Match Index', 'Match Status','Group Name', 'Group Town', 'Group County', 'Group State', 'Group Country', 'Group Name Type','Group Match Index', 'Group Match Status',]].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Group Columns and Group Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "outputs": [],
   "source": [
    "# define some columns that we will use later when grouping data - makes tracking stuff easier\n",
    "CD_merged_mind['data_index'] = CD_merged_mind['state_data'] + \"_\" + CD_merged_mind['state_data_index'].astype(str)\n",
    "CD_merged_mind['assets'] = CD_merged_mind['data_index'] + \" : \" + CD_merged_mind['6p_total'].astype(str) + \", \" + CD_merged_mind['6p_def_total'].astype(str) + \", \" + CD_merged_mind['3p_total'].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [],
   "source": [
    "# fill in information for people who we could not search for on ancestry because their name was not formatted as a name - these are the unsearchables from the third cleaning script\n",
    "na_ind = CD_merged_mind[CD_merged_mind['Group Name'].isnull()].index\n",
    "CD_merged_mind.loc[na_ind, 'Group Name'] = CD_merged_mind.loc[na_ind, 'Name']\n",
    "CD_merged_mind.loc[na_ind, 'Full Search Name'] = CD_merged_mind.loc[na_ind, 'Name']\n",
    "CD_merged_mind.loc[na_ind, 'Group Match Index'] = 'Unsearchable (not a name)'\n",
    "CD_merged_mind.loc[na_ind, 'Group Match Url'] = 'Unsearchable (not a name)'\n",
    "CD_merged_mind.loc[na_ind, 'Name_Fix'] = CD_merged_mind.loc[na_ind, 'Name']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "outputs": [],
   "source": [
    "# capitalize nams correctly\n",
    "CD_merged_mind['Group Name'] = CD_merged_mind['Group Name'].apply(\n",
    "    lambda x: \" \".join([ele.capitalize() if \"ii\" not in ele.lower() else ele.upper() for ele in x.split(\" \")]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "outputs": [],
   "source": [
    "# manually fix an entry - i don't know why this was not addressed by the above process, but now it is fixed\n",
    "CD_merged_mind.loc[\n",
    "    CD_merged_mind[CD_merged_mind['Name'].apply(lambda x: 'Bowdle' in x)].index, 'Group Town'] = 'Annapolis'\n",
    "CD_merged_mind.loc[\n",
    "    CD_merged_mind[CD_merged_mind['Name'].apply(lambda x: 'Gassaway Watkins' in x)].index, 'Group Town'] = 'Annapolis'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "outputs": [],
   "source": [
    "# group together everyone with the same name, location and aggregate their assets and information\n",
    "df_final = CD_merged_mind.fillna(\"\").groupby(\n",
    "    ['Group Name', 'Group State', 'Group County', 'Group Town', 'Group Name Type', 'Group Match Index',\n",
    "     'Group Match Url']).agg({'Name_Fix': lambda x: list(set(x)), 'Full Search Name': tNameList, 'assets': tNameList,\n",
    "                              'occupation': tNameList}).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(df_final.loc[[4,8]].drop('Group Match Url', axis = 1).to_markdown())\""
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(df_final.loc[[4,8]].drop('Group Match Url', axis = 1).to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impute Location - Corporations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(df_final[df_final['Name_Fix'].apply(lambda x: any(['Elnathan Keyes' in ele for ele in x]))].drop('Group Match Url', axis = 1).to_markdown())\""
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(df_final[df_final['Name_Fix'].apply(lambda x: any(['Elnathan Keyes' in ele for ele in x]))].drop('Group Match Url', axis = 1).to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "outputs": [],
   "source": [
    "exception_names = []\n",
    "\n",
    "# find cases where we have the same name but in different locations - we think that these are actually the same people so we want to group them together\n",
    "dup_state_2 = df_final.explode(\"Name_Fix\")[\n",
    "    ['Name_Fix', 'Group Name', 'Group State', 'Group County', 'Group Town', 'Group Name Type']].drop_duplicates()\n",
    "dup_state_2['Name_Fix'] = dup_state_2['Name_Fix'].apply(lambda x: x.split(\" | \"))\n",
    "dup_state_2 = dup_state_2.explode('Name_Fix').drop_duplicates().groupby(\n",
    "    ['Name_Fix', 'Group State']).nunique().reset_index()\n",
    "\n",
    "# basically, we want to keep looping through this until the number of exceptions is the same as the number of ungrouped names\n",
    "# exception names are names we can't merge, there's a process by which we can't combine them (basically if they have contradicting info - so Bob is in two different counties, then Bob is an exception)\n",
    "# we have to run the loop multiple times because sometimes a name can be changed multiple times after its grouped\n",
    "while len(exception_names) != dup_state_2[dup_state_2.apply(lambda x: x['Group County'] > 1 and x['Group Name'] > 1, axis=1)].shape[0]:\n",
    "    dup_state_2 = df_final.explode(\"Name_Fix\")[\n",
    "        ['Name_Fix', 'Group Name', 'Group State', 'Group County', 'Group Town', 'Group Name Type']].drop_duplicates()\n",
    "    dup_state_2['Name_Fix'] = dup_state_2['Name_Fix'].apply(lambda x: x.split(\" | \"))\n",
    "    dup_state_2 = dup_state_2.explode('Name_Fix').drop_duplicates().groupby(\n",
    "        ['Name_Fix', 'Group State']).nunique().reset_index()\n",
    "\n",
    "    for ind in dup_state_2[dup_state_2.apply(lambda x: x['Group County'] > 1 and x['Group Name'] > 1, axis=1)].index:\n",
    "        # information from dataframe with potentially duplicated individuals (people with same name, identity but different locations)\n",
    "        name, state = dup_state_2.loc[ind, ['Name_Fix', 'Group State']]\n",
    "\n",
    "        # values of all possible name types\n",
    "        vals = df_final[\n",
    "            df_final.apply(lambda x: any([name in ele for ele in x['Name_Fix']]) and x['Group State'] == state,\n",
    "                           axis=1)]['Group Name Type'].drop_duplicates().tolist()\n",
    "        # list of unique towns\n",
    "        towns = [ele for ele in df_final[\n",
    "            df_final.apply(lambda x: any([name in ele for ele in x['Name_Fix']]) and x['Group State'] == state,\n",
    "                           axis=1)]['Group Town'].drop_duplicates().tolist() if ele != \"\"]\n",
    "        # list of unique counties\n",
    "        counties = [ele for ele in df_final[\n",
    "            df_final.apply(lambda x: any([name in ele for ele in x['Name_Fix']]) and x['Group State'] == state,\n",
    "                           axis=1)]['Group County'].drop_duplicates().tolist() if ele != \"\"]\n",
    "\n",
    "        # let towns, counties length equal 1 (excluding \"\") because we don't want contradicting information. for example, montgomery MD and anne arundel MD contradict but annapolis, anne arundel MD and anne arundel MD don't contradict because one is more specific than the other\n",
    "        if len(towns) <= 1 and len(counties) == 1:\n",
    "            # find\n",
    "            if 'town' in vals:\n",
    "                change_val = df_final.loc[df_final.apply(\n",
    "                    lambda x: any([name in ele for ele in x['Name_Fix']]) and x['Group State'] == state and x[\n",
    "                        'Group Name Type'] == 'town', axis=1), ['Group Town', 'Group County', 'Group State',\n",
    "                                                                'Group Name Type']].drop_duplicates().values\n",
    "            elif 'county' in vals:\n",
    "                change_val = df_final.loc[df_final.apply(\n",
    "                    lambda x: any([name in ele for ele in x['Name_Fix']]) and x['Group State'] == state and x[\n",
    "                        'Group Name Type'] == 'county', axis=1), ['Group Town', 'Group County', 'Group State',\n",
    "                                                                  'Group Name Type']].drop_duplicates().values\n",
    "            else:  # 'state' in vals\n",
    "                change_val = df_final.loc[df_final.apply(\n",
    "                    lambda x: any([name in ele for ele in x['Name_Fix']]) and x['Group State'] == state and x[\n",
    "                        'Group Name Type'] == 'state', axis=1), ['Group Town', 'Group County', 'Group State',\n",
    "                                                                 'Group Name Type']].drop_duplicates().values\n",
    "\n",
    "            change_ind = df_final[\n",
    "                df_final.apply(lambda x: any([name in ele for ele in x['Name_Fix']]) and x['Group State'] == state,\n",
    "                               axis=1)].index\n",
    "            assert (len(change_val) == 1)\n",
    "            df_final.loc[change_ind, ['Group Town', 'Group County', 'Group State', 'Group Name Type']] = change_val[0]\n",
    "        else:\n",
    "            if [name, state] not in exception_names:\n",
    "                exception_names.append([name, state])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(df_final[df_final['Name_Fix'].apply(lambda x: any(['Elnathan Keyes' in ele for ele in x]))].drop('Group Match Url', axis = 1).to_markdown())\""
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(df_final[df_final['Name_Fix'].apply(lambda x: any(['Elnathan Keyes' in ele for ele in x]))].drop('Group Match Url', axis = 1).to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning Name_Fix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(df_final[df_final['Group Name'] == 'Ebenezer Denny'].drop('Group Match Url', axis = 1).to_markdown())\""
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(df_final[df_final['Group Name'] == 'Ebenezer Denny'].drop('Group Match Url', axis = 1).to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5s/dvrxt95949x1pm_sjxm85lj00000gn/T/ipykernel_51442/2420180601.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  other_names['Full Search Name'] = other_names['Full Search Name'].apply(lambda x: x.split(\" | \"))\n"
     ]
    }
   ],
   "source": [
    "# now, we want to find a way to systematize all the names - for example, Bob Rush and Bob Rushe are the same person but in our notation they are denoted as separate people\n",
    "# we will use a dictionary to convert all Bob Rushe's in a particular location into Bob Rush\n",
    "other_names = df_final[['Group Name', 'Group State', 'Group County', 'Group Town', 'Full Search Name']]\n",
    "other_names['Full Search Name'] = other_names['Full Search Name'].apply(lambda x: x.split(\" | \"))\n",
    "other_names = other_names.explode('Full Search Name')\n",
    "namechange_dict = dict(zip(\n",
    "    other_names['Full Search Name'] + other_names['Group Town'] + other_names['Group County'] + other_names[\n",
    "        'Group State'], other_names['Group Name']))\n",
    "# some manual additions due to idosyncracies of cleaning process\n",
    "namechange_dict['DesdeilyNY'] = 'Desdeily'\n",
    "namechange_dict['GrundNY'] = 'Grund'\n",
    "namechange_dict['Thomas Cloyd HalseyProvidenceProvidence CountyRI'] = 'Thomas Lloyd Halsey'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "outputs": [],
   "source": [
    "# more names that we add to the dictionary manually - we have to do this for the exceptions because these people are not accounted for for some weird reason in the original process of creating the dictionary\n",
    "# also a special exception for how we process Samuel Vernon's name\n",
    "for ele in exception_names:\n",
    "    name, state = ele[0], ele[1]\n",
    "    vals = df_final[\n",
    "        df_final.apply(lambda x: any([name in ele for ele in x['Name_Fix']]) and x['Group State'] == state, axis=1)][\n",
    "        ['Group Town', 'Group County', 'Group State']].drop_duplicates()\n",
    "    for ind in vals.index:\n",
    "        town, county, state = vals.loc[ind, 'Group Town'], vals.loc[ind, 'Group County'], vals.loc[ind, 'Group State']\n",
    "        if name + town + county + state not in namechange_dict.keys():\n",
    "            reps = [e for e in namechange_dict.keys() if name in e]\n",
    "            if name == 'Samuel Vernon':\n",
    "                namechange_dict[name + town + county + state] = name\n",
    "            else:\n",
    "                assert (len(list(set([namechange_dict[ele] for ele in reps]))) == 1)\n",
    "                namechange_dict[name + town + county + state] = namechange_dict[reps[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "outputs": [],
   "source": [
    "# now we reformat the name\n",
    "# : separates different institutions associated with someone, so for example, someone might own bonds as an individual Bob and with his friends (Bob and George) so the result is Bob : Bob | George\n",
    "# ASDSD helps us find places where our dictionary fails\n",
    "df_final['Name_Fix_Transfer'] = df_final.apply(lambda x: \" : \".join(list(set([(tNameList([namechange_dict.get(\n",
    "    subele + x['Group Town'] + x['Group County'] + x['Group State'],\n",
    "    \"ASDSD\" + subele + x['Group Town'] + x['Group County'] + x['Group State']) for subele in ele.split(\" | \")]) + \" / \" + ele) for ele\n",
    "    in x['Name_Fix']]))), axis=1)\n",
    "df_final['Name_Fix_Clean'] = df_final.apply(lambda x: \" : \".join(list(set([tNameList([namechange_dict.get(\n",
    "    subele + x['Group Town'] + x['Group County'] + x['Group State'],\n",
    "    \"ASDSD\" + subele + x['Group Town'] + x['Group County'] + x['Group State']) for subele in ele.split(\" | \")])  for ele\n",
    "                                                                              in x['Name_Fix']]))), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "outputs": [],
   "source": [
    "df_final.drop('Name_Fix', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(df_final[df_final['Group Name'] == 'Ebenezer Denny'].drop('Group Match Url', axis = 1).to_markdown())\""
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(df_final[df_final['Group Name'] == 'Ebenezer Denny'].drop('Group Match Url', axis = 1).to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "outputs": [],
   "source": [
    "#CD_merged_mind[CD_merged_mind['Name'].apply(lambda x: 'Daniel Hartung' in x)]\n",
    "#CD_merged_mind[CD_merged_mind['Name'].apply(lambda x: 'Dorothea Losh' in x)]\n",
    "#CD_merged_mind[CD_merged_mind['Name'].apply(lambda x: 'Joseph Stiles' in x)]\n",
    "#CD_merged_mind[CD_merged_mind['Name'].apply(lambda x: 'Walter S' in x)]\n",
    "#CD_merged_mind[CD_merged_mind['Name'].apply(lambda x: 'William Allen' in x)]\n",
    "#CD_merged_mind[CD_merged_mind['Name'].apply(lambda x: 'William Govett' in x)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "outputs": [],
   "source": [
    "#df_final.drop('Group Match Url', axis = 1).loc[[591, 728, 1667, 1877, 3668, 3686, 3761]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manual Adjustments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "outputs": [
    {
     "data": {
      "text/plain": "['John Gale', 'Love Stone', 'Nathaniel Irwin']"
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_list = df_final[df_final.duplicated(['Group Name', 'Group State', 'Group County', 'Group Town', 'Group Name Type'])][\n",
    "    'Group Name'].tolist()\n",
    "sorted(rep_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "outputs": [
    {
     "data": {
      "text/plain": "           Group Name Group State       Group County Group Town  \\\n1825        John Gale          MD    Somerset County              \n1826        John Gale          MD    Somerset County              \n2404       Love Stone          SC  Charleston County              \n2405       Love Stone          SC  Charleston County              \n2661  Nathaniel Irwin          PA       Bucks County              \n2662  Nathaniel Irwin          PA       Bucks County              \n\n     Group Name Type   Group Match Index  \\\n1825          county         1040 | 1041   \n1826          county  1040 | 1041 | 2205   \n2404          county                       \n2405          county                       \n2661          county  1988 | 2126 | 2127   \n2662          county                1988   \n\n                                        Group Match Url Full Search Name  \\\n1825  https://www.ancestrylibrary.com/search/collect...        John Gale   \n1826  https://www.ancestrylibrary.com/search/collect...        John Gale   \n2404  https://www.ancestrylibrary.com/search/collect...       Love Stone   \n2405  https://www.ancestrylibrary.com/search/collect...       Love Stone   \n2661  https://www.ancestrylibrary.com/search/collect...  Nathaniel Irwin   \n2662  https://www.ancestrylibrary.com/search/collect...  Nathaniel Irwin   \n\n                                                 assets  \\\n1825  MD_243 : 2148.66, 1074.34, 1409.32 | MD_244 : ...   \n1826                    PA_1080 : 176.58, 88.29, 201.48   \n2404                   SC_394 : 881.66, 2838.33, 856.64   \n2405  SC_10 : 216.67, 108.33, 207.64 | SC_410 : 0.0,...   \n2661  PA_1117 : 0.0, 0.0, 26.02 | PA_949 : 617.36, 3...   \n2662                     PA_693 : 276.68, 138.35, 93.77   \n\n                                             occupation  \\\n1825                        Executor of Ebenezer Finlay   \n1826                                                      \n2404                   Administrators of Joseph Darrell   \n2405                                              Widow   \n2661  Administer Estate of Richard Walker Deceased |...   \n2662                                                      \n\n                                      Name_Fix_Transfer  \\\n1825  John Gale / John Gale : Ebenezer Finlays | Joh...   \n1826                              John Gale / John Gale   \n2404  Joseph Vesey | Love Stone / Joseph Vesey | Lov...   \n2405                            Love Stone / Love Stone   \n2661  Nathaniel Irwin | Richard Walker / Nathaniel I...   \n2662                  Nathaniel Irwin / Nathaniel Irwin   \n\n                                         Name_Fix_Clean  \n1825           Ebenezer Finlays | John Gale : John Gale  \n1826                                          John Gale  \n2404                          Joseph Vesey | Love Stone  \n2405                                         Love Stone  \n2661  Nathaniel Irwin : Nathaniel Irwin | Richard Wa...  \n2662                                    Nathaniel Irwin  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Group Name</th>\n      <th>Group State</th>\n      <th>Group County</th>\n      <th>Group Town</th>\n      <th>Group Name Type</th>\n      <th>Group Match Index</th>\n      <th>Group Match Url</th>\n      <th>Full Search Name</th>\n      <th>assets</th>\n      <th>occupation</th>\n      <th>Name_Fix_Transfer</th>\n      <th>Name_Fix_Clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1825</th>\n      <td>John Gale</td>\n      <td>MD</td>\n      <td>Somerset County</td>\n      <td></td>\n      <td>county</td>\n      <td>1040 | 1041</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>John Gale</td>\n      <td>MD_243 : 2148.66, 1074.34, 1409.32 | MD_244 : ...</td>\n      <td>Executor of Ebenezer Finlay</td>\n      <td>John Gale / John Gale : Ebenezer Finlays | Joh...</td>\n      <td>Ebenezer Finlays | John Gale : John Gale</td>\n    </tr>\n    <tr>\n      <th>1826</th>\n      <td>John Gale</td>\n      <td>MD</td>\n      <td>Somerset County</td>\n      <td></td>\n      <td>county</td>\n      <td>1040 | 1041 | 2205</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>John Gale</td>\n      <td>PA_1080 : 176.58, 88.29, 201.48</td>\n      <td></td>\n      <td>John Gale / John Gale</td>\n      <td>John Gale</td>\n    </tr>\n    <tr>\n      <th>2404</th>\n      <td>Love Stone</td>\n      <td>SC</td>\n      <td>Charleston County</td>\n      <td></td>\n      <td>county</td>\n      <td></td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Love Stone</td>\n      <td>SC_394 : 881.66, 2838.33, 856.64</td>\n      <td>Administrators of Joseph Darrell</td>\n      <td>Joseph Vesey | Love Stone / Joseph Vesey | Lov...</td>\n      <td>Joseph Vesey | Love Stone</td>\n    </tr>\n    <tr>\n      <th>2405</th>\n      <td>Love Stone</td>\n      <td>SC</td>\n      <td>Charleston County</td>\n      <td></td>\n      <td>county</td>\n      <td></td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Love Stone</td>\n      <td>SC_10 : 216.67, 108.33, 207.64 | SC_410 : 0.0,...</td>\n      <td>Widow</td>\n      <td>Love Stone / Love Stone</td>\n      <td>Love Stone</td>\n    </tr>\n    <tr>\n      <th>2661</th>\n      <td>Nathaniel Irwin</td>\n      <td>PA</td>\n      <td>Bucks County</td>\n      <td></td>\n      <td>county</td>\n      <td>1988 | 2126 | 2127</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Nathaniel Irwin</td>\n      <td>PA_1117 : 0.0, 0.0, 26.02 | PA_949 : 617.36, 3...</td>\n      <td>Administer Estate of Richard Walker Deceased |...</td>\n      <td>Nathaniel Irwin | Richard Walker / Nathaniel I...</td>\n      <td>Nathaniel Irwin : Nathaniel Irwin | Richard Wa...</td>\n    </tr>\n    <tr>\n      <th>2662</th>\n      <td>Nathaniel Irwin</td>\n      <td>PA</td>\n      <td>Bucks County</td>\n      <td></td>\n      <td>county</td>\n      <td>1988</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Nathaniel Irwin</td>\n      <td>PA_693 : 276.68, 138.35, 93.77</td>\n      <td></td>\n      <td>Nathaniel Irwin / Nathaniel Irwin</td>\n      <td>Nathaniel Irwin</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[df_final['Group Name'].apply(lambda x: x in rep_list)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "outputs": [],
   "source": [
    "# now, we have a case where the same person and location appears multiple times, so we need to combine them into one person. we do that here\n",
    "# above we confirm the people for who we have to do this for\n",
    "df_final.loc[\n",
    "    df_final[df_final['Group Name'] == 'Love Stone'].index, ['Group Match Url', 'Name_Fix_Clean', 'Name_Fix_Transfer',\n",
    "                                                             'assets', 'occupation']] = [\n",
    "    'https://www.ancestrylibrary.com/search/collections/5058/?name=Love_Stone&name_x=1_1&residence=_charleston-south carolina-usa_552&residence_x=_1-0',\n",
    "    'Joseph Vesey | Love Stone : Love Stone',\n",
    "    'Joseph Vesey | Love Stone / Joseph Vesey | Love Stone : Love Stone / Love Stone',\n",
    "    'SC_10 : 216.67, 108.33, 207.64 | SC_394 : 881.66, 2838.33, 856.64',\n",
    "    'Administrators of Joseph Darrell | Widow']\n",
    "\n",
    "df_final.loc[\n",
    "    df_final[df_final['Group Name'] == 'John Gale'].index, ['Group Match Url', 'Group Match Index', 'Name_Fix_Clean',\n",
    "                                                            'Name_Fix_Transfer',\n",
    "                                                            'assets', 'occupation']] = [\n",
    "    'https://www.ancestrylibrary.com/search/collections/5058/?name=John_Gale&name_x=1_1&residence=_Maryland-usa_23&residence_x=_1-0',\n",
    "    '984 | 985', 'Ebenezer Finlays | John Gale : John Gale',\n",
    "    'John Gale / John Gale : Ebenezer Finlays | John Gale / Ebenezer Finlays | John Gale',\n",
    "    'MD_243 : 2148.66, 1074.34, 1409.32 | MD_244 : 1036.86, 518.43, 683.74 | PA_1080 : 176.58, 88.29, 201.48',\n",
    "    ' | Executor of Ebenezer Finlay']\n",
    "\n",
    "df_final.loc[\n",
    "    df_final[df_final['Group Name'] == 'Nathaniel Irwin'].index, ['Group Match Index', 'Group Match Url',\n",
    "                                                                  'Name_Fix_Clean', 'Name_Fix_Transfer',\n",
    "                                                                                    'assets', 'occupation']] = ['1988',\n",
    "                                                                                                                'https://www.ancestrylibrary.com/search/collections/5058/?name=Nathaniel_Irwin&name_x=s_s&residence=_bucks-pennsylvania-usa_403&residence_x=_1-0',\n",
    "                                                                                                                'Nathaniel Irwin : Nathaniel Irwin | Richard Walker',\n",
    "                                                                                                                'Nathaniel Irwin | Richard Walker / Nathaniel Irwin | Richard Walker : Nathaniel Irwin / Nathaniel Irwin',\n",
    "                                                                                                                'PA_693 : 276.68, 138.35, 93.77 | PA_1117 : 0.0, 0.0, 26.02 | PA_949 : 617.36, 308.69, 179.16',\n",
    "                                                                                                                'Administer Estate of Richard Walker Deceased']\n",
    "\n",
    "\"\"\"df_final.loc[\n",
    "    df_final[df_final['Group Name'] == 'Moses Brown'].index, ['Group Match Index', 'Group Match Url', 'Name_Fix_Clean',\n",
    "                                                              'Name_Fix_Transfer',\n",
    "                                                              'assets', 'occupation']] = ['2472',\n",
    "                                                                                          'https://www.ancestrylibrary.com/search/collections/5058/?name=Moses_Brown&name_x=1_1&residence=_providence-providence-rhode island-usa_5531&residence_x=_1-0',\n",
    "                                                                                          'Moses Brown | Nicholas Brown : John Francis | Moses Brown : Moses Brown',\n",
    "                                                                                          'Moses Brown | Nicholas Brown / Mess Brown | Moses Brown | Nicholas Brown : Moses Brown / Moses Brown : Moses Brown | Nicholas Brown / Moses Brown | Nicholas Brown : John Francis | Moses Brown / John Francis | MOses Brown : Moses Brown / Moses Brown',\n",
    "                                                                                          'RI_126 : 568.96, 284.47, 242.46 | RI_285 : 480.0, 240.0, 24095.11 | RI_334 : 266.67, 133.33, 72.0 | RI_516 : 942.65, 7889.63, 9392.12 | RI_598 : 4675.35, 1805.23, 2092.76 | RI_604 : 18067.23, 9033.61, 4878.15',\n",
    "                                                                                          'Esquire | Extors to the Late Nicholas Brown Esq Deceased']\n",
    "\"\"\"\n",
    "df_final.loc[df_final[df_final['Group Name'].apply(lambda x: 'Peleg San' in x)].index, ['Group Name', 'Group State',\n",
    "                                                                                        'Group County', 'Group Town',\n",
    "                                                                                        'Group Name Type',\n",
    "                                                                                        'Group Match Index',\n",
    "                                                                                        'Group Match Url',\n",
    "                                                                                        'Name_Fix_Clean',\n",
    "                                                                                        'Name_Fix_Transfer',\n",
    "                                                                                        'Full Search Name', 'assets',\n",
    "                                                                                        'occupation']] = [\n",
    "    'Peleg Sanford', 'CT', 'Hartford County', 'Hartford', 'town', '13',\n",
    "    'https://www.ancestrylibrary.com/search/collections/5058/?name=Peleg_Sanford&name_x=ps_ps&residence=_hartford-hartford-connecticut-usa_999&residence_x=_1-1-a',\n",
    "    'Peleg Sanford', 'Peleg Sandford : Peleg Sandford / Peleg Sanford : Peleg Sanford / Peleg Sanford', 'Peleg Sanford | Peleg Sandford',\n",
    "    'CT_13 : 1000.17, 500.09, 1500.32 | CT_280 : 506.93, 253.47, 500.15 | CT_308 : 1200.0, 0.0, 0.0 | CT_672 : 389.47, 194.74, 177.76 | CT_836 : 39.82, 19.92, 0.0 | NY_1773 : 0.0, 0.0, 2665.61 | NY_2107 : 0.0, 0.0, 288.0 | NY_1773 : 0.0, 0.0, 2665.61 | NY_2107 : 0.0, 0.0, 288.0',\n",
    "    'Merchant']\n",
    "\n",
    "\"\"\"df_final.loc[\n",
    "    df_final[df_final['Group Name'] == 'Tristram Bowdle'].index, ['Group Match Url', 'Name_Fix_Clean', 'Name_Fix_Transfer', 'Full Search Name',\n",
    "                                                                  'assets']] = [\n",
    "    'https://www.ancestrylibrary.com/search/collections/5058/?name=Tristram_Bowdle&name_x=ps_ps&residence=_anne+arundel-maryland-usa_169&residence_x=_1-1',\n",
    "    'Gassaway Watkins | Tristram Bowdle : Tristram Bowdle',\n",
    "    'Gassaway Watkins | Tristram Bowdle / Gassaway Watkins | Tristiam Bowdle | Tristram Bowdle : Tristram Bowdle / Tristram Bowdle',\n",
    "    'Tristiam Bowdle | Tristram Bowdle',\n",
    "    'MD_590 : 38.93, 62.48, 108.28 | MD_591 : 124.96, 0.0, 0.0']\"\"\"\n",
    "\n",
    "df_final.drop_duplicates(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Group Names - incorrect states\n",
    "basically because of the way we impute state info sometimes we have the wrong state for an individual (when a state is not listed for someone and we input the state for which the debt file is from, sometimes that state is wrong) - so we correct that when we identify cases where one name is in two states\n",
    "we do some figuring out to make sure the two people are actually different"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nname_list = []\\nfor name in df_final[\\'Group Name\\'].value_counts()[df_final[\\'Group Name\\'].value_counts()>1].index:\\n    states = [ele for ele in df_final.fillna(\"\")[df_final[\\'Group Name\\'] == name][\\'Group State\\'].unique().tolist() if ele != \\'\\']\\n    counties = [ele for ele in df_final.fillna(\"\")[df_final[\\'Group Name\\'] == name][\\'Group County\\'].unique().tolist() if ele != \\'\\']\\n    if len(states) > 1 and len(counties) <= len(states) - 1:\\n        name_list.append(name)\\n'"
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at list below\n",
    "# go through and inspect to see whether they're the same\n",
    "\"\"\"\n",
    "name_list = []\n",
    "for name in df_final['Group Name'].value_counts()[df_final['Group Name'].value_counts()>1].index:\n",
    "    states = [ele for ele in df_final.fillna(\"\")[df_final['Group Name'] == name]['Group State'].unique().tolist() if ele != '']\n",
    "    counties = [ele for ele in df_final.fillna(\"\")[df_final['Group Name'] == name]['Group County'].unique().tolist() if ele != '']\n",
    "    if len(states) > 1 and len(counties) <= len(states) - 1:\n",
    "        name_list.append(name)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(df_final[df_final['Group Name'] == 'Adam Gilchrist'][['Group Name', 'Group State', 'Group County', 'Group Town', 'Group Name Type', 'Group Match Index']].to_markdown())\""
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(df_final[df_final['Group Name'] == 'Adam Gilchrist'][['Group Name', 'Group State', 'Group County', 'Group Town', 'Group Name Type', 'Group Match Index']].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "outputs": [],
   "source": [
    "# next, we have people who are the same, but live in different states (have the same name). these people have different states because earlier when we were cleaning code (in the first notebook), we imputed the state that someone lived in when the state was missing as the state of the debt file but sometimeds, these people are not from that state\n",
    "# list of people\n",
    "state_group_names = pd.read_csv('clean_tools/group_name_state.csv')\n",
    "# in cases where we have people with the same name, and both names only have location information at the state level, we specify here which state we're choosing - basde off preliminary analysis\n",
    "pickstate = {'Samuel W Johnson': 'NY', 'Josiah Watson': 'VA', 'Gerrard Alexander': 'VA', 'Benjamin Tallmadge': 'CT',\n",
    "             'Edward Chinn': 'NY', 'Forman Mount': 'PA', 'Josiah Watson': 'VA', 'Thomas Robinson': 'DE',\n",
    "             'Thomas Ross': 'SC', 'William Applegate': 'NJ'}\n",
    "for ind in state_group_names.index:\n",
    "    # get the name and the index/dataframe associated with the name\n",
    "    group_name = state_group_names.loc[ind, 'Group Name']\n",
    "    df_ind = df_final[df_final['Group Name'] == group_name].index\n",
    "    df_final_sub = df_final.loc[df_ind]\n",
    "    rep_vals = [group_name]\n",
    "    # if the group name type is state for all appearances of that individual then we refer to the pickstate dictionary to get the state we want to keep\n",
    "    if len(df_final.loc[df_ind, 'Group Name Type'].unique()) == 1 and df_final.loc[df_ind, 'Group Name Type'].unique()[\n",
    "        0] == 'state':\n",
    "        rep_vals.extend(df_final_sub[df_final_sub['Group State'].apply(lambda x: x == pickstate[group_name])][\n",
    "                            ['Group State', 'Group County', 'Group Town', 'Group Name Type', 'Group Match Index',\n",
    "                             'Group Match Url']].values.tolist()[0])\n",
    "        for col in ['Full Search Name', 'assets', 'occupation','Name_Fix_Transfer', 'Name_Fix_Clean']:\n",
    "            # have to handle the way we combine the name differently for Name_Fix column\n",
    "            if col != 'Name_Fix_Clean' and col != 'Name_Fix_Transfer':\n",
    "                rep_vals.append(tNameList(\" | \".join(df_final_sub.loc[df_ind, col].tolist()).split(\" | \")))\n",
    "            else:\n",
    "                rep_vals.append(\" : \".join(list(set(\" : \".join(df_final_sub.loc[df_ind, col].tolist()).split(\" : \")))))\n",
    "    else:\n",
    "        # pick the geography level that's most specific\n",
    "        rep_vals.extend(df_final_sub[df_final_sub['Group Name Type'].apply(lambda x: x == 'town' or x == 'county')][\n",
    "                            ['Group State', 'Group County', 'Group Town', 'Group Name Type', 'Group Match Index',\n",
    "                             'Group Match Url']].values.tolist()[0])\n",
    "        for col in ['Full Search Name', 'assets', 'occupation','Name_Fix_Transfer', 'Name_Fix_Clean']:\n",
    "            # have to handle the way we combine the name differently for Name_Fix column\n",
    "            if col != 'Name_Fix_Clean' and col != 'Name_Fix_Transfer':\n",
    "                rep_vals.append(tNameList(\" | \".join(df_final_sub.loc[df_ind, col].tolist()).split(\" | \")))\n",
    "            else:\n",
    "                rep_vals.append(\" : \".join(list(set(\" : \".join(df_final_sub.loc[df_ind, col].tolist()).split(\" : \")))))\n",
    "    # replace the index with the value\n",
    "    df_final.loc[df_ind] = rep_vals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "outputs": [],
   "source": [
    "# remove people from the location that was removed\n",
    "df_final.drop_duplicates(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(df_final[df_final['Group Name'] == 'Adam Gilchrist'][['Group Name', 'Group State', 'Group County', 'Group Town', 'Group Name Type', 'Group Match Index']].to_markdown())\""
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(df_final[df_final['Group Name'] == 'Adam Gilchrist'][['Group Name', 'Group State', 'Group County', 'Group Town', 'Group Name Type', 'Group Match Index']].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Villages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3089    South Carolina\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t...\n",
      "Name: Match State, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# another case where we have to clean the data manually because somehow this entry was not cleaned properly in the third notebook\n",
    "print(match_df.loc[\n",
    "          match_df[match_df['Home in 1790 (City, County, State)'].apply(lambda x: '\\n' in x)].index, 'Match State'])\n",
    "match_df.loc[match_df[match_df['Home in 1790 (City, County, State)'].apply(\n",
    "    lambda x: '\\n' in x)].index, 'Match State'] = 'South Carolina'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "outputs": [],
   "source": [
    "# next, we want to define a \"village\" category that tells us what part of Philly/Charleston/New York someone lived in, if it's in their ancestry.com data\n",
    "# we only do this for these 3 towns\n",
    "village_ind = match_df[match_df['Match County'].apply(\n",
    "    lambda x: 'philadelphia' in x.lower() or 'charleston' in x.lower() or 'new york' in x.lower())]['Match Town'].index\n",
    "match_df.loc[village_ind, 'Match Village'] = [ele if ele != 'Philadelphia City' else '' for ele in match_df.loc[village_ind, 'Match Town'] ]\n",
    "match_df.loc[village_ind, 'Match Town'] = [\n",
    "    'Philadelphia' if 'philadelphia' in ele.lower() else 'Charleston' if 'charleston' in ele.lower() else 'New York City'\n",
    "    for ele in match_df.loc[village_ind, 'Match County']]\n",
    "match_df.fillna(\"\", inplace=True)\n",
    "# change match type based on village\n",
    "match_df['Match Type'] = match_df.apply(lambda x: 'village' if x['Match Village'] != '' else x['Match Type'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(match_df[match_df['Name'] == 'Thomas Vail'].to_markdown())\""
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(match_df[match_df['Name'] == 'Thomas Vail'].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Occupations from Ancestry"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(match_df[match_df['Name'] == 'Comfort (Wd) Clock | Wd Combert Clock'].to_markdown())\""
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(match_df[match_df['Name'] == 'Comfort (Wd) Clock | Wd Combert Clock'].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "outputs": [],
   "source": [
    "# next, we're going to clean the match dataframe containing results from ancestry.com\n",
    "# the first way we identify an entry that needs to be cleaned is if it has parentheses but no commas - the occupation is inside the parentheses\n",
    "opt_one_ind = match_df[match_df['Name'].apply(lambda x: '(' in x and ',' not in x)].index\n",
    "# we extract the occupation within the name, add it to an occupation column we create and then remove the occupation from the name\n",
    "match_df.loc[opt_one_ind, 'Occupation'] = match_df.loc[opt_one_ind, 'Name'].apply(\n",
    "    lambda x: tNameList([ele[ele.find(\"(\") + 1:ele.find(\")\")] for ele in x.split(\" | \") if '(' in ele]))\n",
    "match_df.loc[opt_one_ind, 'Name'] = match_df.loc[opt_one_ind].apply(lambda x: tNameList(\n",
    "    [(ele[0:ele.find(\"(\") - 1] + ele[ele.find(\")\") + 1:]) if '(' in ele else ele.replace(x['Occupation'], '') for ele in\n",
    "     x['Name'].split(\" | \")]), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "outputs": [
    {
     "data": {
      "text/plain": "'print(match_df.loc[[145]].to_markdown())'"
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(match_df.loc[[145]].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "outputs": [],
   "source": [
    "# next, we have a few particular occupations that are noted with a comma in between names\n",
    "esq_ind = match_df[\n",
    "    match_df['Name'].apply(lambda x: ',' in x and '(' not in x and not any(char.isdigit() for char in x))].index\n",
    "# there are only judges esquires or colonels, so we check and add these to the occupations columns if they're there\n",
    "match_df.loc[esq_ind, 'Occupation'] = match_df.loc[esq_ind, 'Name'].apply(lambda x: 'Esquire' if 'Esq' in x else '')\n",
    "match_df.loc[esq_ind, 'Occupation'] = match_df.loc[esq_ind].apply(\n",
    "    lambda x: tNameList((x['Occupation'] + \" | Colonel\").split(\" | \")) if 'Col' in x['Name'] else x['Occupation'],\n",
    "    axis=1)\n",
    "match_df.loc[esq_ind, 'Occupation'] = match_df.loc[esq_ind].apply(\n",
    "    lambda x: tNameList((x['Occupation'] + \" | Judge\").split(\" | \")) if 'Exce' in x['Name'] or 'Judge' in x['Name'] else\n",
    "    x['Occupation'], axis=1)\n",
    "# remove the parts of the name that contain the occupations\n",
    "match_df.loc[esq_ind, 'Name'] = match_df.loc[esq_ind].apply(lambda x: tNameList([ele.replace(',', '').replace('Esquire',\n",
    "                                                                                                              '').replace(\n",
    "    'Esqr', '').replace('Esq.', '').replace('Esq', '').replace('Colonel', '').replace('Col', '').replace('  ',\n",
    "                                                                                                         ' ').replace(\n",
    "    '.', '').replace('His Excely ', '').replace('r|', 'r |').replace('y|', 'y |').replace('n|', 'n |').strip() for ele\n",
    "                                                                                 in x['Name'].split(\" | \")]), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "outputs": [],
   "source": [
    "# finally, we have a few particular occupations that are noted with a comma and parentheses in between names\n",
    "both_ind = match_df[match_df['Name'].apply(lambda x: '(' in x and ',' in x)]['Name'].index\n",
    "# first we remove the occupation inside the parentheses and remove it from the name\n",
    "match_df.loc[both_ind, 'Occupation'] = match_df.loc[both_ind, 'Name'].apply(\n",
    "    lambda x: tNameList([ele[ele.find(\"(\") + 1:ele.find(\")\")] for ele in x.split(\" | \") if '(' in ele]))\n",
    "match_df.loc[both_ind, 'Name'] = match_df.loc[both_ind].apply(lambda x: tNameList(\n",
    "    [(ele[0:ele.find(\"(\") - 1] + ele[ele.find(\")\") + 1:]) if '(' in ele else ele.replace(x['Occupation'], '') for ele in\n",
    "     x['Name'].split(\" | \")]), axis=1)\n",
    "# next, the only occupations that use the comma are esquire,colonel and judge so we just follow the same steps as before\n",
    "match_df.loc[both_ind, 'Occupation'] = match_df.loc[both_ind].apply(\n",
    "    lambda x: tNameList((x['Occupation'] + \" | Esquire\").split(\" | \")) if 'Esq' in x['Name'] else x['Occupation'],\n",
    "    axis=1)\n",
    "match_df.loc[both_ind, 'Occupation'] = match_df.loc[both_ind].apply(\n",
    "    lambda x: tNameList((x['Occupation'] + \" | Colonel\").split(\" | \")) if 'Col' in x['Name'] else x['Occupation'],\n",
    "    axis=1)\n",
    "match_df.loc[both_ind, 'Occupation'] = match_df.loc[both_ind].apply(\n",
    "    lambda x: tNameList((x['Occupation'] + \" | Judge\").split(\" | \")) if 'Exce' in x['Name'] or 'Judge' in x['Name'] else\n",
    "    x['Occupation'], axis=1)\n",
    "# remove those occupations from the name\n",
    "match_df.loc[both_ind, 'Name'] = match_df.loc[both_ind].apply(lambda x: tNameList([ele.replace(',', '').replace(\n",
    "    'Esquire', '').replace('Esqr', '').replace('Esq.', '').replace('Esq', '').replace('Colonel', '').replace('Col',\n",
    "                                                                                                             '').replace(\n",
    "    '  ', ' ').replace('.', '').replace('His Excely ', '').replace('r|', 'r |').replace('y|', 'y |').replace('n|',\n",
    "                                                                                                             'n |').strip()\n",
    "                                                                                   for ele in x['Name'].split(\" | \")]),\n",
    "                                                              axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "outputs": [],
   "source": [
    "# Finally, we have a few occupations - judges, reverends, majors, doctors and colonels that are not noted with anything - they are just aprt of the name, so we go through these one by one, add the occupation and remove the occupation names from the actual name column\n",
    "# judges\n",
    "honor_index = match_df[match_df['Name'].apply(lambda x: 'Honr.' in x or 'Honorable' in x or 'Honererable' in x)].index\n",
    "match_df.loc[honor_index, 'Occupation'] = match_df.fillna(\"\").loc[honor_index, 'Occupation'].apply(\n",
    "    lambda x: tNameList((x + \" | Judge\").split(\" | \")))\n",
    "match_df.loc[honor_index, 'Name'] = match_df.loc[honor_index].apply(lambda x: tNameList(\n",
    "    [ele.replace(\"Honr.\", \"\").replace(\"Honorable\", \"\").replace(\"Honererable\", \"\").replace(\"  \", \" \").strip() for ele in\n",
    "     x['Name'].split(\" | \")]), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "outputs": [],
   "source": [
    "# reverends\n",
    "rev_index = match_df[match_df['Name'].apply(lambda x: 'Revd' in x or 'Reverend' in x)].index\n",
    "match_df.loc[rev_index, 'Occupation'] = match_df.fillna(\"\").loc[rev_index, 'Occupation'].apply(\n",
    "    lambda x: tNameList((x + \" | Reverend\").split(\" | \")))\n",
    "match_df.loc[rev_index, 'Name'] = match_df.loc[rev_index].apply(lambda x: tNameList(\n",
    "    [ele.replace(\"Revd\", \"\").replace(\"Reverend\", \"\").replace(\"  \", \" \").strip() for ele in x['Name'].split(\" | \")]),\n",
    "                                                                axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "outputs": [],
   "source": [
    "# majors\n",
    "maj_index = match_df[match_df['Name'].apply(lambda x: 'Majr' in x or 'Major' in x)].index\n",
    "match_df.loc[maj_index, 'Occupation'] = match_df.fillna(\"\").loc[maj_index, 'Occupation'].apply(\n",
    "    lambda x: tNameList((x + \" | Major\").split(\" | \")))\n",
    "match_df.loc[maj_index, 'Name'] = match_df.loc[maj_index].apply(lambda x: tNameList(\n",
    "    [ele.replace(\"Majr\", \"\").replace(\"Major\", \"\").replace(\"  \", \" \").strip() for ele in x['Name'].split(\" | \")]),\n",
    "                                                                axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "outputs": [],
   "source": [
    "# doctors\n",
    "doctor_index = match_df[\n",
    "    match_df['Name'].apply(lambda x: 'Dr ' in x or 'Doctor' in x or 'Docr' in x or 'Doctr' in x or 'Dortoe' in x)].index\n",
    "match_df.loc[doctor_index, 'Occupation'] = match_df.fillna(\"\").loc[doctor_index, 'Occupation'].apply(\n",
    "    lambda x: tNameList((x + \" | Doctor\").split(\" | \")))\n",
    "match_df.loc[doctor_index, 'Name'] = match_df.loc[doctor_index].apply(lambda x: tNameList([ele.replace(\"Doctor\",\n",
    "                                                                                                       \"\").replace(\n",
    "    \"Docr\", \"\").replace('Docr', '').replace('Dortoe', '').replace('Dr ', '').replace(\"  \", \" \").strip() for ele in\n",
    "                                                                                           x['Name'].split(\" | \")]),\n",
    "                                                                      axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "outputs": [],
   "source": [
    "# captains/colonels\n",
    "officer_index = match_df[match_df['Name'].apply(lambda\n",
    "                                                    x: 'Col.' in x or 'Cols' in x or 'Colonel' in x or 'Coln' in x or 'Colo' in x or 'General' in x or 'Capt' in x or 'Captain' in x)].index\n",
    "match_df.loc[officer_index, 'Occupation'] = match_df.fillna(\"\").loc[officer_index, 'Occupation'].apply(\n",
    "    lambda x: tNameList((x + \" | Military Officer\").split(\" | \")))\n",
    "match_df.loc[officer_index, 'Name'] = match_df.loc[officer_index].apply(lambda x: tNameList([ele.replace(\n",
    "    \"Col.\", \"\").replace('Cols', '').replace('Colonel', '').replace('Coln', '').replace('Colo', '').replace('General',\n",
    "                                                                                                           '').replace(\n",
    "    'Captain', '').replace('Capt', '').replace(\"  \", \" \").strip() for ele in x['Name'].split(\" | \")]), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "outputs": [
    {
     "data": {
      "text/plain": "400"
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of occupations gained\n",
    "match_df[~match_df['Occupation'].isnull()].shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Improve Scraper Match"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "outputs": [],
   "source": [
    "# next, we have a case where sometimes, one group name is matched to multiple people on ancestry, but we can actually reduce the number of people matched to by checking whether there are name(s) in the matched people from ancestry that correspond exactly to our \"Group Name\" column\n",
    "# if we can reduce the number of matches we do so, otherwise we keep the original matches\n",
    "mult_ind = df_final[df_final['Group Match Index'].apply(\n",
    "    lambda x: 'Unsearchable' not in x and x != '' and len(x.split(\" | \")) > 1)].index\n",
    "# getting match information\n",
    "df_final.loc[mult_ind, 'temp'] = df_final.loc[mult_ind].apply(\n",
    "    lambda x: [ind + \" | \" + match_df.loc[int(ind), 'Name'] for ind in x['Group Match Index'].split(\" | \")], axis=1)\n",
    "# filtering to see if we can reduce the number of matches\n",
    "df_final.loc[mult_ind, 'temp'] = df_final.loc[mult_ind].apply(\n",
    "    lambda x: [ele.split(\" | \")[0] for ele in x['temp'] if x['Group Name'] in ele], axis=1)\n",
    "# changing the match indices if there is a direct name correspondence - otherwise we just keep the original match indices\n",
    "df_final.loc[mult_ind, 'Group Match Index'] = df_final.loc[mult_ind].apply(\n",
    "    lambda x: tNameList(x['temp']) if len(x['temp']) > 0 else x['Group Match Index'], axis=1)\n",
    "df_final.drop('temp', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Eliminate Broad Location Matches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "outputs": [],
   "source": [
    "match_df2 = match_df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "outputs": [],
   "source": [
    "match_df = match_df.loc[sorted(list(set([int(ele) for ele in df_final['Group Match Index'].apply(lambda x: x.split(\" | \") if x != '' and x != 'Unsearchable (not a name)' else []).explode().tolist() if not pd.isnull(ele)])))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(df_final.loc[[1775]].drop('Group Match Url', axis = 1).to_markdown())\\nprint(match_df.loc[[2862,2863,2864]].to_markdown())\""
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(df_final.loc[[1775]].drop('Group Match Url', axis = 1).to_markdown())\n",
    "print(match_df.loc[[2862,2863,2864]].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "outputs": [],
   "source": [
    "# next, we want to eliminate cases in the match dataframe where for some reason, the location given in the match dataframe is too broad and we can eliminate some of them\n",
    "# we can do this because we now have more information about the location of the person, based off affiliated corporatiosn\n",
    "for ind in df_final[df_final['Group Match Index'].apply(lambda x: \"|\" in x)].index:\n",
    "    # get relevant data from our data and ancestry match data\n",
    "    match_data = match_df.loc[[int(ele) for ele in df_final.loc[ind, 'Group Match Index'].split(\" | \")]]\n",
    "    town, county = df_final.loc[ind, 'Group Town'], df_final.loc[ind, 'Group County']\n",
    "    match_town, match_county = [ele for ele in list(set(match_data['Match Town'].tolist())) if ele != \"\"], [ele for ele\n",
    "                                                                                                            in list(\n",
    "            set(match_data['Match County'].tolist())) if ele != \"\"]\n",
    "    # if there is more than one town, and one of the towns matches our data's town, we only keep that town\n",
    "    if len(match_town) > 1 and town in match_town:\n",
    "        match_ind = match_data[match_data['Match Town'] == town]['index_new'].tolist()\n",
    "        # print(ind, match_ind, tNameList([str(ele) for ele in match_ind]))\n",
    "        df_final.loc[ind, 'Group Match Index'] = tNameList([str(ele) for ele in match_ind])\n",
    "\n",
    "    # if there is more than one county, and one of the counties matches our data's county, we only keep that county\n",
    "    elif len(match_county) == 2 and county in match_county:\n",
    "        match_ind = match_data[match_data['Match County'] == county]['index_new'].tolist()\n",
    "        # print(ind, match_ind, tNameList([str(ele) for ele in match_ind]))\n",
    "        df_final.loc[ind, 'Group Match Index'] = tNameList([str(ele) for ele in match_ind])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(df_final[df_final['Group Name'] == 'Benjamin Gallup'].drop('Group Match Url', axis = 1).to_markdown())\\nprint(match_df[match_df['Name'] == 'Benjn Gallop'].to_markdown())\""
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(df_final[df_final['Group Name'] == 'Benjamin Gallup'].drop('Group Match Url', axis = 1).to_markdown())\n",
    "print(match_df[match_df['Name'] == 'Benjn Gallop'].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Census to Impute Location"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "outputs": [],
   "source": [
    "# finally, we want to mark places where the ancestry.com match locations don't match up with what we have, and places where we imput location\n",
    "df_final['imputed_location'] = ''\n",
    "df_final['location conflict'] = ''\n",
    "ordering_dict = {'state': 0, 'county': 1, 'town': 2, 'village': 3, '' : -1}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "outputs": [],
   "source": [
    "def sameLocation(locations):\n",
    "    \"\"\"\n",
    "    This function takes in a list of locations and returns the location level that everything is the same at\n",
    "    :param locations: list of locations from the match data\n",
    "    :return: same location + location type\n",
    "    \"\"\"\n",
    "    states = list(set([loc[0] for loc in locations]))\n",
    "    counties = list(set([loc[1] for loc in locations]))\n",
    "    towns = list(set([loc[2] for loc in locations]))\n",
    "    villages = list(set([loc[3] if len(loc) > 3 else '' for loc in locations]))\n",
    "\n",
    "    loc = locations[0]\n",
    "    if len(villages) == 1 and '' not in villages:\n",
    "        return [loc, 'village']\n",
    "    elif len(towns) == 1 and '' not in towns:\n",
    "        return [[loc[0],loc[1],loc[2],''], 'town']\n",
    "    elif len(counties) == 1 and '' not in counties:\n",
    "        return [[loc[0],loc[1],'',''], 'county']\n",
    "    elif len(states) == 1 and '' not in states:\n",
    "        return [[loc[0],'',''], 'state']\n",
    "    else:\n",
    "        return ['No Match']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "outputs": [],
   "source": [
    "# add the location an individual has from ancestry.com if they only have one match\n",
    "temp_ind = df_final[df_final.apply(\n",
    "    lambda x: 'Unsearchable' not in x['Group Match Index'] and x['Group Match Index'] != '' and len(\n",
    "        x['Group Match Index'].split(\" | \")) == 1, axis=1)].index\n",
    "\n",
    "# we only add location if we think that the location ancestry.com has is more specific than what we have\n",
    "df_final.loc[temp_ind, 'temp'] = df_final.loc[temp_ind].apply(lambda x: match_df.loc[int(x['Group Match Index'])][\n",
    "    ['Match State', 'Match County', 'Match Town', 'Match Village']].values.tolist() if ordering_dict[\n",
    "                                                                                           x['Group Name Type']] <\n",
    "                                                                                       ordering_dict[match_df.loc[int(x[\n",
    "                                                                                                                          'Group Match Index']), 'Match Type']] else \"\",\n",
    "                                                              axis=1)\n",
    "\n",
    "# add location an individual has on ancestry.com if they have more than one match\n",
    "# pick indices\n",
    "mult_ind = df_final[df_final.apply(\n",
    "    lambda x: 'Unsearchable' not in x['Group Match Index'] and x['Group Match Index'] != '' and len(\n",
    "        x['Group Match Index'].split(\" | \")) > 1, axis=1)].index\n",
    "# find whether the multiple matches have the same location\n",
    "df_final.loc[mult_ind, 'temp'] = df_final.loc[mult_ind].apply(lambda x: sameLocation(match_df.loc[[int(ele) for ele in x['Group Match Index'].split(\" | \")], ['Match State', 'Match County', 'Match Town', 'Match Village']].values.tolist()), axis=1)\n",
    "# figure out the location type of the ancestry.com location\n",
    "df_final.loc[mult_ind, 'temp status'] = df_final.loc[mult_ind, 'temp'].apply(lambda x: x[1] if len(x)>1 else '')\n",
    "# remove from the location\n",
    "df_final.loc[mult_ind, 'temp'] = df_final.loc[mult_ind].apply(lambda x: x['temp'][0] if ordering_dict[x['temp status']]>ordering_dict[x['Group Name Type']] else '', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "outputs": [],
   "source": [
    "# people for whom ancestry.com just messed up the matching - the state, county etc is wrong, so we want to remove these people from the match\n",
    "rem_ind = df_final[df_final.fillna(\"\")['temp'] != \"\"][df_final[df_final.fillna(\"\")['temp'] != \"\"].apply(\n",
    "    lambda x: statedict[x['Group State']] != x['temp'][0] and x['Group State'] != 'NY', axis=1)].index\n",
    "df_final.loc[rem_ind, 'Group Match Index'] = ''\n",
    "\n",
    "# places where the county that is given on ancestry is different from the county we have\n",
    "county_loc_conflict = df_final[df_final.fillna(\"\")['temp'] != \"\"][df_final[df_final.fillna(\"\")['temp'] != \"\"].apply(\n",
    "    lambda x: x['Group County'] != x['temp'][1] and x['Group County'] != '' and x['Group Match Index'] != '',\n",
    "    axis=1)].index\n",
    "df_final.loc[county_loc_conflict, 'location conflict'] = 'county'\n",
    "\n",
    "# places where the town that is given on ancestry is different from the tow  we have\n",
    "town_loc_conflict = df_final[df_final.fillna(\"\")['temp'] != \"\"][df_final[df_final.fillna(\"\")['temp'] != \"\"].apply(\n",
    "    lambda x: x['Group Town'] != x['temp'][2] and x['Group Town'] != '' and x['Group Match Index'] != '' and x[\n",
    "        'location conflict'] == '', axis=1)].index\n",
    "df_final.loc[town_loc_conflict, 'location conflict'] = 'town'\n",
    "\n",
    "# see if we can add location when we only have one match\n",
    "rep_ind = df_final[df_final.fillna(\"\")['temp'] != \"\"][df_final[df_final.fillna(\"\")['temp'] != \"\"].apply(\n",
    "    lambda x: x['location conflict'] == '' and x['Group Match Index'] != '', axis=1)].index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "outputs": [],
   "source": [
    "# places where the town that is given on ancestry is different from the town we have\n",
    "town_loc_conflict = df_final[df_final.fillna(\"\")['temp'] != \"\"][df_final[df_final.fillna(\"\")['temp'] != \"\"].apply(\n",
    "    lambda x: x['Group Town'] != x['temp'][2] and x['Group Town'] != '' and x['Group Match Index'] != '' and x[\n",
    "        'location conflict'] == '', axis=1)].index\n",
    "df_final.loc[town_loc_conflict, 'location conflict'] = 'town'\n",
    "\n",
    "# see if we can add location when we can recover the location\n",
    "rep_ind = df_final[df_final.fillna(\"\")['temp'] != \"\"][df_final[df_final.fillna(\"\")['temp'] != \"\"].apply(\n",
    "    lambda x: x['location conflict'] == '' and x['Group Match Index'] != '', axis=1)].index\n",
    "df_final.loc[rep_ind, 'imputed_location'] = df_final.loc[rep_ind].apply(\n",
    "    lambda x: match_df.loc[int(x['Group Match Index'])]['Match Type'] if pd.isnull(x['temp status']) else x[\n",
    "        'temp status'], axis=1)\n",
    "\n",
    "# add in imputed data\n",
    "df_final.loc[rep_ind, 'Group State'] = df_final.loc[rep_ind, 'temp'].apply(lambda x: statedict_rev[x[0]])\n",
    "df_final.loc[rep_ind, 'Group County'] = df_final.loc[rep_ind, 'temp'].apply(lambda x: x[1] + ' County')\n",
    "df_final.loc[rep_ind, 'Group Town'] = df_final.loc[rep_ind, 'temp'].apply(lambda x: x[2])\n",
    "df_final.loc[rep_ind, 'Group Village'] = df_final.loc[rep_ind, 'temp'].apply(lambda x: x[3])\n",
    "df_final.fillna(\"\", inplace=True)\n",
    "df_final.drop('temp', axis=1, inplace=True)\n",
    "df_final.drop('temp status', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Occupation Column Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "outputs": [],
   "source": [
    "# next, we're going to add the occupation information from ancestry.com into the occupation column in our main data\n",
    "match_df['Occupation'].fillna('', inplace=True)\n",
    "df_final['occupation'] = df_final.apply(lambda x: tNameList((\" | \".join(\n",
    "    [match_df.loc[int(ele), 'Occupation'] for ele in x['Group Match Index'].split(\" | \")]) + \" | \" + x[\n",
    "                                                                 'occupation']).split(\" | \")) if x[\n",
    "                                                                                                     'Group Match Index'] != '' and\n",
    "                                                                                                 x[\n",
    "                                                                                                     'Group Match Index'] != 'Unsearchable (not a name)' else\n",
    "x['occupation'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "outputs": [],
   "source": [
    "# import dictionary to clean occupations\n",
    "occ_data = pd.read_csv('clean_tools/occ_correction.csv')\n",
    "occ_dict = dict(zip(occ_data['Original'], occ_data['Corrected']))\n",
    "# manual additions to occupation dictionary because we can't work with commas in a csv file\n",
    "occ_dict[''] = ''\n",
    "occ_dict['Notary, Scrivenor & Broker'] = 'Broker'\n",
    "occ_dict['Notary, Scrivener & Broker'] = 'Broker'\n",
    "occ_dict['Notary, Scrivener, & Broker'] = 'Broker'\n",
    "# change occupations\n",
    "df_final['occupation'] = df_final['occupation'].apply(\n",
    "    lambda x: tNameList([str(occ_dict[ele]) for ele in x.split(\" | \")]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "outputs": [
    {
     "data": {
      "text/plain": "\"print(occ_data[occ_data['Corrected'].apply(lambda x: x in ['Merchant'])].head(9)[['Original', 'Corrected']].to_markdown())\""
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(occ_data[occ_data['Corrected'].apply(lambda x: x in ['Merchant'])].head(9)[['Original', 'Corrected']].to_markdown())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reset Match Data Index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5s/dvrxt95949x1pm_sjxm85lj00000gn/T/ipykernel_51442/706461425.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  match_list_no_dup.rename({'index_old': 'index_temp'}, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# finally, we're going to create a new column in the match dataframe where all the indices of the people who are not matched to anyone are removed, so our match index goes from 0 to the total number of matches\n",
    "# first we remove the people who are not matched to anyone\n",
    "match_df = match_df.loc[sorted(list(set([int(ele) for ele in df_final['Group Match Index'].apply(lambda x: x.split(\" | \") if x != '' and x != 'Unsearchable (not a name)' else []).explode().tolist() if not pd.isnull(ele)])))]\n",
    "\n",
    "\n",
    "for ind in df_final[df_final['Group Match Index'].apply(lambda x: \"|\" in x)].index:\n",
    "    match_data = match_df.loc[[int(ele) for ele in df_final.loc[ind, 'Group Match Index'].split(\" | \")]]\n",
    "    town, county = df_final.loc[ind, 'Group Town'], df_final.loc[ind, 'Group County']\n",
    "    match_town, match_county = [ele for ele in list(set(match_data['Match Town'].tolist())) if ele != \"\"], [ele for ele\n",
    "                                                                                                            in list(\n",
    "            set(match_data['Match County'].tolist())) if ele != \"\"]\n",
    "    if len(match_town) == 2 and town in match_town:\n",
    "        match_ind = match_data[match_data['Match Town'] == town]['index_new'].tolist()\n",
    "        df_final.loc[ind, 'Group Match Index'] = tNameList([str(ele) for ele in match_ind])\n",
    "    elif len(match_county) == 2 and county in match_county:\n",
    "        match_ind = match_data[match_data['Match County'] == county]['index_new'].tolist()\n",
    "        df_final.loc[ind, 'Group Match Index'] = tNameList([str(ele) for ele in match_ind])\n",
    "\n",
    "match_df.drop(['index_temp', 'index_new'], inplace=True, axis=1)\n",
    "\n",
    "# next, we want to remove entries in match_list that are duplicated, and create a dictionary that maps the old indices in df_list to the new indices, after we drop duplicates in match_list\n",
    "\n",
    "# save old index\n",
    "match_df['index_old'] = match_df.index\n",
    "# drop duplicates, create temporary index column\n",
    "match_list_no_dup = match_df.drop_duplicates(subset=[ele for ele in match_df.columns if ele != 'index_old'])\n",
    "match_list_no_dup.rename({'index_old': 'index_temp'}, axis=1, inplace=True)\n",
    "\n",
    "# create mapping between old index, and temporary new index\n",
    "# the temporary new index removes indices of repeated values without renumbering anything\n",
    "match_dict_df = pd.merge(match_df.reset_index(),\n",
    "                         match_list_no_dup,\n",
    "                         how='left').set_index('index')\n",
    "match_dict_df['index_old'] = match_dict_df.index\n",
    "\n",
    "# now, we want to renumber the temporary index so that it is sequential and doesn't skip any numbers\n",
    "# we call this the new index\n",
    "gen_newind = match_dict_df[['index_temp']].drop_duplicates().reset_index(drop=True).copy()\n",
    "gen_newind['index_new'] = gen_newind.index\n",
    "# merge in new index to merged dataframe, map old index to new index\n",
    "match_dict_df = pd.merge(match_dict_df, gen_newind)\n",
    "match_dict = dict(zip(match_dict_df['index_old'], match_dict_df['index_new']))\n",
    "\n",
    "# change from old indices to new indices in df_list dataframe\n",
    "df_final['Group Match Index'] = df_final['Group Match Index'].apply(\n",
    "    lambda x: tNameList([str(match_dict[int(ele)]) for ele in x.split(' | ')]) if x not in [\"\",\n",
    "                                                                                            'Unsearchable (not a name)'] else \"\")\n",
    "# change match_list dataframe so that it removes duplicates and is indexed by the new index method\n",
    "match_df = pd.merge(match_list_no_dup, gen_newind)\n",
    "match_df['index_new'] = match_df['index_new'].apply(lambda x: str(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregate Asset Totals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "outputs": [],
   "source": [
    "# find how many people own a particular asset\n",
    "# add that as suffix at end of debt asset\n",
    "asset_count_dict = df_final['assets'].apply(lambda x: [ele.split(\" : \")[0] for ele in x.split(\" | \")]).explode().value_counts().to_dict()\n",
    "asset_count_dict\n",
    "df_final['assets'] = df_final['assets'].apply(lambda x: \" | \".join([ele.split(\" : \")[0] + \"_\" + str(asset_count_dict[ele.split(\" : \")[0]]) + \" : \" + ele.split(\" : \")[1] for ele in x.split(\" | \")]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "outputs": [],
   "source": [
    "# total debt assets (not adjusted for ownership - sum is more than total amount of debt held\n",
    "df_final['6p_total'] = df_final['assets'].apply(lambda x: sum([pd.to_numeric(ele.split(\" : \")[1].split(\",\")[0]) for ele in x.split(\" | \")]))\n",
    "df_final['6p_def_total'] = df_final['assets'].apply(lambda x: sum([pd.to_numeric(ele.split(\" : \")[1].split(\",\")[1]) for ele in x.split(\" | \")]))\n",
    "df_final['unpaid_interest'] = df_final['assets'].apply(lambda x: sum([pd.to_numeric(ele.split(\" : \")[1].split(\",\")[2]) for ele in x.split(\" | \")]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "outputs": [],
   "source": [
    "# total debt assets (adjusted for ownership, assuming equal ownership)\n",
    "df_final['6p_total_adj'] = df_final['assets'].apply(lambda x: sum([pd.to_numeric(ele.split(\" : \")[1].split(\",\")[0])/pd.to_numeric(ele.split(\" : \")[0].split(\"_\")[2]) for ele in x.split(\" | \")]))\n",
    "df_final['6p_def_total_adj'] = df_final['assets'].apply(lambda x: sum([pd.to_numeric(ele.split(\" : \")[1].split(\",\")[1])/pd.to_numeric(ele.split(\" : \")[0].split(\"_\")[2]) for ele in x.split(\" | \")]))\n",
    "df_final['unpaid_interest_adj'] = df_final['assets'].apply(lambda x: sum([pd.to_numeric(ele.split(\" : \")[1].split(\",\")[2])/pd.to_numeric(ele.split(\" : \")[0].split(\"_\")[2]) for ele in x.split(\" | \")]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "outputs": [],
   "source": [
    "df_final['final_total'] = df_final['6p_total'] + df_final['6p_def_total']\n",
    "df_final['final_total_adj'] = df_final['6p_total_adj'] + df_final['6p_def_total_adj']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final Data Export"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "outputs": [],
   "source": [
    "match_df.drop('index_temp', axis = 1).to_csv(\"../data_clean/match_data_CD.csv\")\n",
    "df_final.reset_index(drop = True).to_csv(\"../data_clean/final_data_CD.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "outputs": [
    {
     "data": {
      "text/plain": "                                  Name     Home in 1790 (City, County, State)  \\\n0     Benjn Trumbull | Benja Trunabull           Bolton, Tolland, Connecticut   \n1                        Richard Green       Foster, Providence, Rhode Island   \n2                       Thomas Hopkins        Hartford, Hartford, Connecticut   \n3                          John Morgan        Hartford, Hartford, Connecticut   \n4                           John Lewis    Wethersfield, Hartford, Connecticut   \n...                                ...                                    ...   \n3589                       Seth Warner  Belchertown, Hampshire, Massachusetts   \n3590                          Wm Pikin               Fawn, York, Pennsylvania   \n3591            Seth Dean | Selle Cran              Barnard, Windsor, Vermont   \n3592                  Daniel Wadsworth        Hartford, Hartford, Connecticut   \n3593                       John Burgin          Ipswich, Essex, Massachusetts   \n\n     Free White Persons - Males - 16 and over Free White Persons - Females  \\\n0                                           1                            1   \n1                                           1                            2   \n2                                                                            \n3                                                                            \n4                                           1                            3   \n...                                       ...                          ...   \n3589                                        2                            2   \n3590                                        1                            2   \n3591                                        1                            4   \n3592                                        1                            3   \n3593                                        1                            3   \n\n     Number of Household Members Free White Persons - Males - Under 16  \\\n0                              2                                         \n1                              5                                     2   \n2                                                                        \n3                                                                        \n4                              6                                     2   \n...                          ...                                   ...   \n3589                           4                                         \n3590                           3                                         \n3591                           9                                     4   \n3592                           5                                         \n3593                           4                                         \n\n     Number of Slaves Number of All Other Free Persons Match Type  \\\n0                                                            town   \n1                                                            town   \n2                                                            town   \n3                                                            town   \n4                                                            town   \n...               ...                              ...        ...   \n3589                                                         town   \n3590                                                         town   \n3591                                                         town   \n3592                                                 1       town   \n3593                                                         town   \n\n        Match Town       Match County    Match State Match Village Occupation  \\\n0           Bolton     Tolland County    Connecticut                            \n1           Foster  Providence County   Rhode Island                            \n2         Hartford    Hartford County    Connecticut                            \n3         Hartford    Hartford County    Connecticut                            \n4     Wethersfield    Hartford County    Connecticut                            \n...            ...                ...            ...           ...        ...   \n3589   Belchertown   Hampshire County  Massachusetts                            \n3590          Fawn        York County   Pennsylvania                            \n3591       Barnard     Windsor County        Vermont                            \n3592      Hartford    Hartford County    Connecticut                            \n3593       Ipswich       Essex County  Massachusetts                            \n\n     index_new  \n0            0  \n1            1  \n2            2  \n3            3  \n4            4  \n...        ...  \n3589      3589  \n3590      3590  \n3591      3591  \n3592      3592  \n3593      3593  \n\n[3594 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Home in 1790 (City, County, State)</th>\n      <th>Free White Persons - Males - 16 and over</th>\n      <th>Free White Persons - Females</th>\n      <th>Number of Household Members</th>\n      <th>Free White Persons - Males - Under 16</th>\n      <th>Number of Slaves</th>\n      <th>Number of All Other Free Persons</th>\n      <th>Match Type</th>\n      <th>Match Town</th>\n      <th>Match County</th>\n      <th>Match State</th>\n      <th>Match Village</th>\n      <th>Occupation</th>\n      <th>index_new</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Benjn Trumbull | Benja Trunabull</td>\n      <td>Bolton, Tolland, Connecticut</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>town</td>\n      <td>Bolton</td>\n      <td>Tolland County</td>\n      <td>Connecticut</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Richard Green</td>\n      <td>Foster, Providence, Rhode Island</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>2</td>\n      <td></td>\n      <td></td>\n      <td>town</td>\n      <td>Foster</td>\n      <td>Providence County</td>\n      <td>Rhode Island</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Thomas Hopkins</td>\n      <td>Hartford, Hartford, Connecticut</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>town</td>\n      <td>Hartford</td>\n      <td>Hartford County</td>\n      <td>Connecticut</td>\n      <td></td>\n      <td></td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>John Morgan</td>\n      <td>Hartford, Hartford, Connecticut</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>town</td>\n      <td>Hartford</td>\n      <td>Hartford County</td>\n      <td>Connecticut</td>\n      <td></td>\n      <td></td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>John Lewis</td>\n      <td>Wethersfield, Hartford, Connecticut</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>2</td>\n      <td></td>\n      <td></td>\n      <td>town</td>\n      <td>Wethersfield</td>\n      <td>Hartford County</td>\n      <td>Connecticut</td>\n      <td></td>\n      <td></td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3589</th>\n      <td>Seth Warner</td>\n      <td>Belchertown, Hampshire, Massachusetts</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>town</td>\n      <td>Belchertown</td>\n      <td>Hampshire County</td>\n      <td>Massachusetts</td>\n      <td></td>\n      <td></td>\n      <td>3589</td>\n    </tr>\n    <tr>\n      <th>3590</th>\n      <td>Wm Pikin</td>\n      <td>Fawn, York, Pennsylvania</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>town</td>\n      <td>Fawn</td>\n      <td>York County</td>\n      <td>Pennsylvania</td>\n      <td></td>\n      <td></td>\n      <td>3590</td>\n    </tr>\n    <tr>\n      <th>3591</th>\n      <td>Seth Dean | Selle Cran</td>\n      <td>Barnard, Windsor, Vermont</td>\n      <td>1</td>\n      <td>4</td>\n      <td>9</td>\n      <td>4</td>\n      <td></td>\n      <td></td>\n      <td>town</td>\n      <td>Barnard</td>\n      <td>Windsor County</td>\n      <td>Vermont</td>\n      <td></td>\n      <td></td>\n      <td>3591</td>\n    </tr>\n    <tr>\n      <th>3592</th>\n      <td>Daniel Wadsworth</td>\n      <td>Hartford, Hartford, Connecticut</td>\n      <td>1</td>\n      <td>3</td>\n      <td>5</td>\n      <td></td>\n      <td></td>\n      <td>1</td>\n      <td>town</td>\n      <td>Hartford</td>\n      <td>Hartford County</td>\n      <td>Connecticut</td>\n      <td></td>\n      <td></td>\n      <td>3592</td>\n    </tr>\n    <tr>\n      <th>3593</th>\n      <td>John Burgin</td>\n      <td>Ipswich, Essex, Massachusetts</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>town</td>\n      <td>Ipswich</td>\n      <td>Essex County</td>\n      <td>Massachusetts</td>\n      <td></td>\n      <td></td>\n      <td>3593</td>\n    </tr>\n  </tbody>\n</table>\n<p>3594 rows  15 columns</p>\n</div>"
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_df.drop('index_temp', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "outputs": [
    {
     "data": {
      "text/plain": "             Group Name Group State       Group County  Group Town  \\\n0              Desdeily          NY                                  \n1                 Grund          NY                                  \n2           Aaron Bourn          RI     Bristol County     Bristol   \n3            Aaron Bull          CT    Hartford County    Hartford   \n4     Aaron Caldwell II          CT    Hartford County    Hartford   \n...                 ...         ...                ...         ...   \n3946   Zebulon Waterman          CT  New London County  Colchester   \n3947  Zephaniah Andrews          RI  Providence County  Providence   \n3948    Zephaniah Brown          RI  Providence County  Providence   \n3949    Zephaniah Davis          CT     Tolland County      Hebron   \n3950    Zuriel Waterman          RI  Providence County    Cranston   \n\n     Group Name Type Group Match Index  \\\n0              state                     \n1              state                     \n2               town              2435   \n3               town                74   \n4               town                     \n...              ...               ...   \n3946            town               521   \n3947            town              2231   \n3948            town              2236   \n3949            town               386   \n3950            town              2484   \n\n                                        Group Match Url  \\\n0                                                         \n1                                                         \n2     https://www.ancestrylibrary.com/search/collect...   \n3     https://www.ancestrylibrary.com/search/collect...   \n4     https://www.ancestrylibrary.com/search/collect...   \n...                                                 ...   \n3946  https://www.ancestrylibrary.com/search/collect...   \n3947  https://www.ancestrylibrary.com/search/collect...   \n3948  https://www.ancestrylibrary.com/search/collect...   \n3949  https://www.ancestrylibrary.com/search/collect...   \n3950  https://www.ancestrylibrary.com/search/collect...   \n\n                          Full Search Name  \\\n0                                 Desdeily   \n1                                    Grund   \n2                              Aaron Bourn   \n3                               Aaron Bull   \n4     Aaron Cadwell Ii | Aaron Caldwell Ii   \n...                                    ...   \n3946                      Zebulon Waterman   \n3947                     Zephaniah andrews   \n3948                       Zephaniah Brown   \n3949                       Zephaniah Davis   \n3950                       Zuriel Waterman   \n\n                                                 assets     occupation  ...  \\\n0                         NY_1947_1 : 0.0, 0.0, 5140.86                 ...   \n1     NY_1865_1 : 0.0, 0.0, 10000.0 | NY_1866_1 : 0....                 ...   \n2                     RI_322_1 : 206.37, 103.18, 258.26          Baker  ...   \n3                          CT_78_1 : 61.3, 30.66, 16.05  Administrator  ...   \n4                             CT_98_1 : 9.25, 4.63, 0.0                 ...   \n...                                                 ...            ...  ...   \n3946                   CT_588_1 : 204.4, 102.21, 218.26         Farmer  ...   \n3947  RI_388_1 : 35.27, 17.63, 0.0 | RI_85_1 : 1056....          Mason  ...   \n3948  RI_299_1 : 303.36, 151.68, 116.31 | RI_90_1 : ...       Merchant  ...   \n3949                     CT_431_1 : 51.47, 25.73, 32.42         Farmer  ...   \n3950                          RI_405_1 : 7.3, 3.65, 0.0         Farmer  ...   \n\n     location conflict Group Village 6p_total 6p_def_total unpaid_interest  \\\n0                                        0.00         0.00         5140.86   \n1                                        0.00         0.00        19986.00   \n2                                      206.37       103.18          258.26   \n3                                       61.30        30.66           16.05   \n4                                        9.25         4.63            0.00   \n...                ...           ...      ...          ...             ...   \n3946                                   204.40       102.21          218.26   \n3947                                  1152.50       576.24          748.84   \n3948                                  1610.06       805.02          626.19   \n3949                                    51.47        25.73           32.42   \n3950                                     7.30         3.65            0.00   \n\n      6p_total_adj  6p_def_total_adj  unpaid_interest_adj  final_total  \\\n0             0.00              0.00              5140.86         0.00   \n1             0.00              0.00             19986.00         0.00   \n2           206.37            103.18               258.26       309.55   \n3            61.30             30.66                16.05        91.96   \n4             9.25              4.63                 0.00        13.88   \n...            ...               ...                  ...          ...   \n3946        204.40            102.21               218.26       306.61   \n3947       1152.50            576.24               748.84      1728.74   \n3948       1610.06            805.02               626.19      2415.08   \n3949         51.47             25.73                32.42        77.20   \n3950          7.30              3.65                 0.00        10.95   \n\n      final_total_adj  \n0                0.00  \n1                0.00  \n2              309.55  \n3               91.96  \n4               13.88  \n...               ...  \n3946           306.61  \n3947          1728.74  \n3948          2415.08  \n3949            77.20  \n3950            10.95  \n\n[3893 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Group Name</th>\n      <th>Group State</th>\n      <th>Group County</th>\n      <th>Group Town</th>\n      <th>Group Name Type</th>\n      <th>Group Match Index</th>\n      <th>Group Match Url</th>\n      <th>Full Search Name</th>\n      <th>assets</th>\n      <th>occupation</th>\n      <th>...</th>\n      <th>location conflict</th>\n      <th>Group Village</th>\n      <th>6p_total</th>\n      <th>6p_def_total</th>\n      <th>unpaid_interest</th>\n      <th>6p_total_adj</th>\n      <th>6p_def_total_adj</th>\n      <th>unpaid_interest_adj</th>\n      <th>final_total</th>\n      <th>final_total_adj</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Desdeily</td>\n      <td>NY</td>\n      <td></td>\n      <td></td>\n      <td>state</td>\n      <td></td>\n      <td></td>\n      <td>Desdeily</td>\n      <td>NY_1947_1 : 0.0, 0.0, 5140.86</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>5140.86</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>5140.86</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Grund</td>\n      <td>NY</td>\n      <td></td>\n      <td></td>\n      <td>state</td>\n      <td></td>\n      <td></td>\n      <td>Grund</td>\n      <td>NY_1865_1 : 0.0, 0.0, 10000.0 | NY_1866_1 : 0....</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>19986.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>19986.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aaron Bourn</td>\n      <td>RI</td>\n      <td>Bristol County</td>\n      <td>Bristol</td>\n      <td>town</td>\n      <td>2435</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Aaron Bourn</td>\n      <td>RI_322_1 : 206.37, 103.18, 258.26</td>\n      <td>Baker</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>206.37</td>\n      <td>103.18</td>\n      <td>258.26</td>\n      <td>206.37</td>\n      <td>103.18</td>\n      <td>258.26</td>\n      <td>309.55</td>\n      <td>309.55</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Aaron Bull</td>\n      <td>CT</td>\n      <td>Hartford County</td>\n      <td>Hartford</td>\n      <td>town</td>\n      <td>74</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Aaron Bull</td>\n      <td>CT_78_1 : 61.3, 30.66, 16.05</td>\n      <td>Administrator</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>61.30</td>\n      <td>30.66</td>\n      <td>16.05</td>\n      <td>61.30</td>\n      <td>30.66</td>\n      <td>16.05</td>\n      <td>91.96</td>\n      <td>91.96</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Aaron Caldwell II</td>\n      <td>CT</td>\n      <td>Hartford County</td>\n      <td>Hartford</td>\n      <td>town</td>\n      <td></td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Aaron Cadwell Ii | Aaron Caldwell Ii</td>\n      <td>CT_98_1 : 9.25, 4.63, 0.0</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>9.25</td>\n      <td>4.63</td>\n      <td>0.00</td>\n      <td>9.25</td>\n      <td>4.63</td>\n      <td>0.00</td>\n      <td>13.88</td>\n      <td>13.88</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3946</th>\n      <td>Zebulon Waterman</td>\n      <td>CT</td>\n      <td>New London County</td>\n      <td>Colchester</td>\n      <td>town</td>\n      <td>521</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Zebulon Waterman</td>\n      <td>CT_588_1 : 204.4, 102.21, 218.26</td>\n      <td>Farmer</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>204.40</td>\n      <td>102.21</td>\n      <td>218.26</td>\n      <td>204.40</td>\n      <td>102.21</td>\n      <td>218.26</td>\n      <td>306.61</td>\n      <td>306.61</td>\n    </tr>\n    <tr>\n      <th>3947</th>\n      <td>Zephaniah Andrews</td>\n      <td>RI</td>\n      <td>Providence County</td>\n      <td>Providence</td>\n      <td>town</td>\n      <td>2231</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Zephaniah andrews</td>\n      <td>RI_388_1 : 35.27, 17.63, 0.0 | RI_85_1 : 1056....</td>\n      <td>Mason</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>1152.50</td>\n      <td>576.24</td>\n      <td>748.84</td>\n      <td>1152.50</td>\n      <td>576.24</td>\n      <td>748.84</td>\n      <td>1728.74</td>\n      <td>1728.74</td>\n    </tr>\n    <tr>\n      <th>3948</th>\n      <td>Zephaniah Brown</td>\n      <td>RI</td>\n      <td>Providence County</td>\n      <td>Providence</td>\n      <td>town</td>\n      <td>2236</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Zephaniah Brown</td>\n      <td>RI_299_1 : 303.36, 151.68, 116.31 | RI_90_1 : ...</td>\n      <td>Merchant</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>1610.06</td>\n      <td>805.02</td>\n      <td>626.19</td>\n      <td>1610.06</td>\n      <td>805.02</td>\n      <td>626.19</td>\n      <td>2415.08</td>\n      <td>2415.08</td>\n    </tr>\n    <tr>\n      <th>3949</th>\n      <td>Zephaniah Davis</td>\n      <td>CT</td>\n      <td>Tolland County</td>\n      <td>Hebron</td>\n      <td>town</td>\n      <td>386</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Zephaniah Davis</td>\n      <td>CT_431_1 : 51.47, 25.73, 32.42</td>\n      <td>Farmer</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>51.47</td>\n      <td>25.73</td>\n      <td>32.42</td>\n      <td>51.47</td>\n      <td>25.73</td>\n      <td>32.42</td>\n      <td>77.20</td>\n      <td>77.20</td>\n    </tr>\n    <tr>\n      <th>3950</th>\n      <td>Zuriel Waterman</td>\n      <td>RI</td>\n      <td>Providence County</td>\n      <td>Cranston</td>\n      <td>town</td>\n      <td>2484</td>\n      <td>https://www.ancestrylibrary.com/search/collect...</td>\n      <td>Zuriel Waterman</td>\n      <td>RI_405_1 : 7.3, 3.65, 0.0</td>\n      <td>Farmer</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>7.30</td>\n      <td>3.65</td>\n      <td>0.00</td>\n      <td>7.30</td>\n      <td>3.65</td>\n      <td>0.00</td>\n      <td>10.95</td>\n      <td>10.95</td>\n    </tr>\n  </tbody>\n</table>\n<p>3893 rows  23 columns</p>\n</div>"
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}