{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one cleans all files in pre1790 debt certs (ie. who the gov needs to pay back and when)\n",
    "90th is a cent (ie. instead of 100 cents per dollar, 90 cents per dollar)\n",
    "Aggregated columns: \"state\", \"date_issued\", \"title\", \"fname\", \"lname\", \"deceased\", \"date_due\", \"dollar\", \"90th\", \"specie\", \"striked\", \"note\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpers\n",
    "def deNaN(series):\n",
    "    \"\"\"\n",
    "    amends pandas series by replacing NaN values with empty strings\n",
    "    :param series: pandas series\n",
    "    \"\"\"\n",
    "\n",
    "    return series.apply(lambda x: \"\" if type(x) != str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamloughead/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/liamloughead/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/liamloughead/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/liamloughead/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/liamloughead/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/liamloughead/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Load and prune the top metadata of the docs\n",
    "\n",
    "#NJ: mon | day | yr | title | fname | lname | mon | day | yr | $ | 90th | strike | note\n",
    "nj = pd.read_excel(\"../../data_raw/pre1790/liquidated_debt_certificates_NJ.xlsx\")\n",
    "nj = nj[10:5117].drop(columns=[\"Record Name\", \"Records of the New Jersey Continental Loan Office, 1777-1790\", \"Unnamed: 2\", \"Unnamed: 9\", \"F\", \"Unnamed: 11\", \"Unnamed: 19\"])\n",
    "\n",
    "#NY: mon | day | yr | fname | lname | title | mon | day | yr | $ | 90th | strike | note | notes\n",
    "ny = pd.read_excel(\"../../data_raw/pre1790/liquidated_debt_certificates_NY.xlsx\")\n",
    "ny = ny[11:7319].drop(columns=[\"Record Name\", \"Records of the New Jersey and New York Continental Loan Offices 1777-1790\", \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 10\", \"Unnamed: 11\", \"Unnamed: 12\"])\n",
    "\n",
    "#NH: mon | day | yr | fname | lname | title | mon | day | yr | $ | 90th | strike | note | notes\n",
    "nh = pd.read_excel(\"../../data_raw/pre1790/liquidated_debt_certificates_NH.xlsx\")\n",
    "nh = nh[11:190].drop(columns=[\"Record Name\", \"Records of the Connecticut, New Hampshire, and Rhode Island Continental Loan Office, 1777-1789\", \"Unnamed: 2\", \"Unnamed: 3\"])\n",
    "\n",
    "#MA: mon | day | yr | fname | lname | title | mon | day | yr | $ | 90th | strike | note\n",
    "ma = pd.read_excel(\"../../data_raw/pre1790/liquidated_debt_certificates_MA.xlsx\")\n",
    "ma = ma[11:2090].drop(columns=[\"Record Name\", \"Records of the Massachusetts Continental Loan Office, 1777-1791\", \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 20\"])\n",
    "\n",
    "#DE: day | mon | yr | title | fname | lname | day | mon | yr | $ | 90th | strike | note\n",
    "de = pd.read_excel(\"../../data_raw/pre1790/liquidated_debt_certificates_DE.xlsx\")\n",
    "de = de[11:637].drop(columns=[\"Record Name\", \n",
    "    \"Mr Paterson remarks that the certificate No. 57 says interest payable from the 1st of March 1780 instead of 1st May 1780, 123 From the 1st of January 1780 instead of 14th January, 234 is in the name of James James    John James\", \"Unnamed: 2\"])\n",
    "\n",
    "#CT: mon | day | yr | fname | lname | title | mon | day | yr | $ | 90th | strike | note | notes\n",
    "ct = pd.read_excel(\"../../data_raw/pre1790/liquidated_debt_certificates_CT.xlsx\")\n",
    "ct = ct[11:1095].drop(columns=[\"Record Name\", \"Records of the Connecticut, New Hampshire, and Rhode Island Continental Loan Office, 1777-1789\", \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 10\", \"Unnamed: 11\", \"Unnamed: 12\", \"Unnamed: 19\"])\n",
    "\n",
    "#PA_stelle: yr | mon | day | title | fname | lname | yr | mon | day | $ | 90th | strike | notes\n",
    "pa1 = pd.read_excel(\"../../data_raw/pre1790/liquidated_debt_certificates_PA_stelle.xlsx\")\n",
    "pa1 = pa1[11:9221].drop(columns=[\"Record Name\", \"Benjamin Steller commisisioner for Pennsylvania Register NO. 1. From No. 1 to 4403\", \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 10\", \"Unnamed: 11\", \"Unnamed: 12\"])\n",
    "\n",
    "#PA_story: yr | mon | day | title | fname | lname | yr | mon | day | $ | 90th | specie amount (2 cols) | strike | notes\n",
    "pa2 = pd.read_excel(\"../../data_raw/pre1790/liquidated_debt_certificates_PA_story.xlsx\")\n",
    "pa2 = pa2[11:966].drop(columns=[\"Record Name\", \"Records of the Pennsylvania Continental Loan Office, 1785-1786\", \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 15\", \"Unnamed: 16\"])\n",
    "\n",
    "#RI: mon | day | yr | fname | lname | title | mon | day | yr | $ | 90th\n",
    "ri = pd.read_excel(\"../../data_raw/pre1790/liquidated_debt_certificates_RI.xlsx\")\n",
    "ri = ri[11:1537].drop(columns=[\"Record Name\", \"Records of the Connecticut, New Hampshire, and Rhode Island Continental Loan Office, 1777-1789\", \"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 10\", \"Unnamed: 11\", \"Unnamed: 12\", \"Unnamed: 18\"])\n",
    "\n",
    "#NOT STATE ONES\n",
    "#marine - the word \"Reg\" shows up in majority of rows in the left total dollars column - will need to get rid of those\n",
    "#mon | day | yr | fname | lname | title | mon | day | yr | $ | 90th | total dollars (2 cols) | strike? | note | notes\n",
    "marine = pd.read_excel(\"../../data_raw/pre1790/Marine_Liquidated_Debt_Certificates.xlsx\")\n",
    "marine = marine[11:776].drop(columns=[\"Record Name\", \"Registers of Liquidated Debt Certificates for the Marine Department, 1786-89\", \"Unnamed: 2\", \"Unnamed: 3\"])\n",
    "\n",
    "#pierce - Last, first, value, state\n",
    "pierce = pd.read_excel(\"../../data_raw/pre1790/Pierce_Certs_cleaned_2019.xlsx\")\n",
    "pierce = pierce[1:93308].drop(columns=[\"CN\", \"Group\", \"To Whom Issued\", \"Officer\"])\n",
    "\n",
    "#office - State (# 1-9), yr, mon, day, title, fn, ln, dollar, specie\n",
    "office = pd.read_excel(\"../../data_raw/pre1790/loan_office_certificates_9_states.xlsx\")\n",
    "office = office[1:80913].drop(columns=[\"Title 2\", \"First Name 2\", \"Last Name 2\"])\n",
    "\n",
    "#aggregate data table - im making the dates into a format readable and writable by datetime module\n",
    "#\"state\", \"date_issued\", \"title\", \"fname\", \"lname\", \"deceased\", \"date_due\", \"dollar\", \"90th\", \"specie\", \"striked\", \"note\" -- specie is optional, very few files have it but we should probably keep it anyway\n",
    "agg_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning process:\n",
    "1. fix all records (ie. remove extraneous information + combine them into agg)\n",
    "   - possibilites of stuff to remove: \"Estate of\", \"Heirs of\",\n",
    "   - possibilites of stuff to fix (ie. find the right name for): \"and Co.\", \"Owners of\",\n",
    "   - first or last name missing: either make the other one undefined, or the entire name is in the first or last name column and it needs to be spread out\n",
    "   - occupation could be in the name\n",
    "   - some last names have spaces in them (specifically Van) - replace them with spaces\n",
    "   - so it needs to look like:\n",
    "     - if fname split or lname split != 1:\n",
    "       - if its just lname contains van, replace \"Van \" with \"Van-\"\n",
    "       - check and auto remove Estate of, Heirs of\n",
    "       - prompt for \"Owners of\" + \"and Co.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrections.json file format:\n",
    "# [\n",
    "#     {\n",
    "#         \"state_code\": \"nj\",\n",
    "#         \"i\": 1,\n",
    "#         \"name_correct\": \"\",\n",
    "#         \"date_correct\": 38945783 #ordinal\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "enable_manual_corrections = input(\"Enable manual correction system (yes, no)? (DO NOT ENABLE IF YOU ARE NOT READY TO MAKE MANUAL CORRECTIONS) > \")\n",
    "enable_manual_corrections = True if enable_manual_corrections == \"yes\" else False\n",
    "\n",
    "def retrieve_manual_correction(state_code, index):\n",
    "    if not os.path.exists(\"corrections.json\"):\n",
    "        f = open(\"corrections.json\", \"w\")\n",
    "        f.write(\"[]\")\n",
    "        f.close()\n",
    "    file = json.load(open(\"corrections.json\", \"r\"))\n",
    "    for obj in file:\n",
    "        if obj[\"state_code\"] == state_code and obj[\"i\"] == index:\n",
    "            return (obj[\"name_correct\"], obj[\"date_correct\"])\n",
    "    return None\n",
    "\n",
    "def save_manual_correction(state_code, index, name_correct, date_correct):\n",
    "    if not enable_manual_corrections: return\n",
    "    if not os.path.exists(\"corrections.json\"):\n",
    "        f = open(\"corrections.json\", \"w\")\n",
    "        f.write(\"[]\")\n",
    "        f.close()\n",
    "    file = json.load(open(\"corrections.json\", \"r\"))\n",
    "    file.append({\n",
    "        \"state_code\": state_code,\n",
    "        \"i\": index,\n",
    "        \"name_correct\": name_correct,\n",
    "        \"date_correct\": date_correct\n",
    "    })\n",
    "    f = open(\"corrections.json\", \"w\")\n",
    "    json.dump(file, f)\n",
    "    f.close()\n",
    "\n",
    "def process_date(yr, mon, day, i: bool, state_code, index):\n",
    "    try:\n",
    "        d = datetime.date(int(yr), int(mon), int(day))\n",
    "        return (d.toordinal(), False)\n",
    "    except Exception as e:\n",
    "        if \"10: ''\" in str(e): #ie. the \"Invalid literal for base 10: ''\" error, which means blank, which means just make it 0\n",
    "            return (0, False)\n",
    "        manual = retrieve_manual_correction(state_code, index)\n",
    "        if manual == None:\n",
    "            if 'month must' in str(e): #ie. month must be in range 1..12 - just swap month and day\n",
    "                d = datetime.date(yr, day, mon)\n",
    "                return (d.toordinal(), False)\n",
    "            new = input(f\"{state_code}: {'RE, ' if ('range' in str(e)) else ''}{'Issued: ' if i else 'Expiries: '} {yr} {mon} {day} (yr-mon-day):\")\n",
    "            if new == \"\" and i == False:\n",
    "                return (0, False)\n",
    "            d = datetime.date(int(new.split()[0]), int(new.split()[1]), int(new.split()[2]))\n",
    "            return (d.toordinal(), True)\n",
    "        else:\n",
    "            return (int(manual[1].split('-')[0]) if i else int(manual[1].split('-')[1]), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_note_present(note):\n",
    "    if note != \"\":\n",
    "        if \"Lo\" in note or \"Ro\" in note:\n",
    "            return False\n",
    "        try:\n",
    "            float(note.strip())\n",
    "            return False\n",
    "        except:\n",
    "            pass\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def process(i, state_code, mon, day, yr, title, fname, lname, dmon, dday, dyr, dollar, specie, ninety, strike, note):\n",
    "    title, fname, lname = title.strip(), fname.strip(), lname.strip()\n",
    "    #Replace anything that could come up\n",
    "    lname = lname.replace(\"Van \", \"Van-\")\n",
    "    lname = lname.replace(\" Van\", \"-Van\")\n",
    "    fname = fname.replace(\"Van \", \"Van-\")\n",
    "    fname = fname.replace(\" Van\", \"-Van\")\n",
    "    fname = fname.replace(\"Estate of \", \"\").replace(\"Heirs of \", \"\").replace(\"Heir of \", \"\")\n",
    "    fname = fname.replace(\" & Co\", \"\").replace(\" & co\", \"\").replace(\" and Co\", \"\").replace(\" and co\", \"\")\n",
    "    lname = lname.replace(\" & Co\", \"\").replace(\" & co\", \"\").replace(\" and Co\", \"\").replace(\" and co\", \"\")\n",
    "    if len(fname.split()) == 1 and lname == \"\": lname = \"undefined\" # if there is no last name, make it undefined\n",
    "    if len(fname.split()) == 2:\n",
    "        if len(fname.split()[1]) == 1: fname = fname.split()[0] # if middle initial in fname, drop it\n",
    "        elif len(fname.split()[1]) > 3: fname = fname.replace(\" \", \"-\") # usually means 2 names\n",
    "    if len(lname.split()) == 2:\n",
    "        if len(lname.split()[1]) == 1: lname = lname.split()[0] # if initial in lname, drop it\n",
    "        elif len(lname.split()[1]) > 3: lname = lname.replace(\" \", \"-\") # usually means 2 names\n",
    "    if fname == \"\" and lname == \"\": return None # Drop ones with no name data\n",
    "    note = \"\" if \"not sure\" in str(note) else str(note)\n",
    "    note = \"\" if \"RO\" in str(note) else str(note)\n",
    "    note = \"\" if \"ro\" in str(note) else str(note)\n",
    "    try: # drop notes that are just numbers\n",
    "        for ns in note.split(\".\"):\n",
    "            int(ns)\n",
    "        note = \"\"\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    isdeceased = \"deceased\" in fname or \"deceased\" in lname\n",
    "    if ('&' in fname) or (' and' in fname) or ('|' in fname):\n",
    "        #Means there is co-ownership\n",
    "        to_add = []\n",
    "        sepr = \"\"\n",
    "        if (\"&\" in fname): sepr = \"&\"\n",
    "        if (\" and\" in fname): sepr = \"and\"\n",
    "        if (\"|\" in fname): sepr = \"|\"\n",
    "        idate, iman = process_date(yr, mon, day, True, state_code, i)\n",
    "        expdate, eman = process_date(dyr, dmon, dday, False, state_code, i)\n",
    "        if iman or eman: save_manual_correction(state_code, i, \"\", str(idate) + \"-\" + str(edate))\n",
    "        for i in range(len(fname.split(sepr))):\n",
    "            to_add.append(pd.Series([\n",
    "                state_code,\n",
    "                idate,\n",
    "                title, fname.split(sepr)[i].strip(), \"undefined\",\n",
    "                isdeceased,\n",
    "                expdate,\n",
    "                dollar, ninety, specie, strike\n",
    "            ]))\n",
    "        return to_add\n",
    "    idate, iman = process_date(yr, mon, day, True, state_code, i)\n",
    "    edate, eman = process_date(dyr, dmon, dday, False, state_code, i)\n",
    "    if iman or eman: save_manual_correction(state_code, i, \"\", str(idate) + \"-\" + str(edate))\n",
    "    if len(fname.split()) != 1 or len(lname.split()) != 1 or check_note_present(note):\n",
    "        correction = retrieve_manual_correction(state_code, i)\n",
    "        if correction == None:\n",
    "            corrected = input(f\"{state_code}, Title: '{title}' F: '{fname}' L: '{lname}' ({note})> \")\n",
    "            if corrected == \"n\":\n",
    "                save_manual_correction(state_code, i, \"DROP\", str(idate) + \"-\" + str(edate))\n",
    "                return None\n",
    "            if corrected == \"s\": return 's'\n",
    "            if corrected == \"c\": corrected = title + \" \" + fname + \" \" + lname\n",
    "            if len(corrected.split()) == 2:\n",
    "                fname, lname = corrected.split()\n",
    "            if len(corrected.split()) == 3:\n",
    "                title, fname, lname = corrected.split()\n",
    "            save_manual_correction(state_code, i, corrected, str(idate) + \"-\" + str(edate))\n",
    "        else:\n",
    "            if correction[0] == \"DROP\": return None\n",
    "            if len(correction[0].split()) == 2:\n",
    "                fname, lname = correction[0].split()\n",
    "            if len(correction[0].split()) == 3:\n",
    "                title, fname, lname = correction[0].split()\n",
    "            print(correction[1].split(\"-\"))\n",
    "            idate, edate = correction[1].split(\"-\")\n",
    "            idate, edate = int(idate), int(edate)\n",
    "    return [pd.Series([\n",
    "        state_code,\n",
    "        idate,\n",
    "        title, fname, lname,\n",
    "        isdeceased,\n",
    "        edate,\n",
    "        dollar, ninety, specie, strike\n",
    "    ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate - loop through each dataframe, run the process function on it, then add it to agg_df\n",
    "dfs = {\"nj\": nj, \"nh\": nh, \"ny\": ny, \"ma\": ma, \"de\": de, \"ct\": ct, \"pa1\": pa1, \"pa2\": pa2, \"ri\": ri}\n",
    "\n",
    "for state in dfs.keys():\n",
    "    df = dfs[state]\n",
    "    for index, row in df.iterrows():\n",
    "        row = row.replace(np.nan,'',regex=True)\n",
    "        out = None\n",
    "        if state == 'nj':\n",
    "            # mon | day | yr | title | fname | lname | mon | day | yr | $ | 90th | strike | note\n",
    "            out = process(index, state,\n",
    "                row[0], row[1], row[2], row[3], row[4],\n",
    "                row[5], row[6], row[7], row[8], row[9], \"\",\n",
    "                row[10], row[11], row[12])\n",
    "        if state == 'ny' or state == 'nh' or state == \"ct\":\n",
    "            # mon | day | yr | fname | lname | title | mon | day | yr | $ | 90th | strike | note | notes\n",
    "            out = process(index, state,\n",
    "                row[0], row[1], row[2], row[5], row[4],\n",
    "                row[3], row[6], row[7], row[8], row[9], \"\",\n",
    "                row[10], row[11], row[12])\n",
    "        if state == 'ma':\n",
    "            #mon | day | yr | fname | lname | title | mon | day | yr | $ | 90th | strike | note\n",
    "            out = process(index, state,\n",
    "                row[0], row[1], row[2], row[5], row[4],\n",
    "                row[3], row[6], row[7], row[8], row[9], \"\",\n",
    "                row[10], row[11], row[12])\n",
    "        if state == \"de\":\n",
    "            #day | mon | yr | title | fname | lname | day | mon | yr | $ | 90th | strike | note\n",
    "            out = process(index, state,\n",
    "                row[1], row[0], row[2], row[3], row[4],\n",
    "                row[5], row[7], row[6], row[8], row[9], \"\",\n",
    "                row[10], row[11], row[12])\n",
    "        if state == \"pa1\":\n",
    "            # yr | mon | day | title | fname | lname | yr | mon | day | $ | 90th | strike | notes\n",
    "            out = process(index, state,\n",
    "                row[1], row[2], row[0], row[3], row[4],\n",
    "                row[5], row[7], row[8], row[6], row[9], \"\",\n",
    "                row[10], row[11], row[12])\n",
    "        if state == \"pa2\":\n",
    "            # yr | mon | day | title | fname | lname | yr | mon | day | $ | 90th | specie amount (2 cols) | strike | notes\n",
    "            out = process(index, state,\n",
    "                row[1], row[2], row[0], row[3], row[4],\n",
    "                row[5], row[7], row[8], row[6], row[9], row[11] + \".\" + row[12],\n",
    "                row[10], row[13], row[14])\n",
    "        if state == \"ri\":\n",
    "            # mon | day | yr | fname | lname | title | mon | day | yr | $ | 90th\n",
    "            out = process(index, state,\n",
    "                row[0], row[1], row[2], row[5], row[4],\n",
    "                row[3], row[6], row[7], row[8], row[9], \"\",\n",
    "                row[10], \"\", \"\")\n",
    "        if out == None: continue\n",
    "        if out == \"s\":\n",
    "            print(\"manual stop\")\n",
    "            break\n",
    "        for new_row in out:\n",
    "            agg_df = pd.concat([agg_df, new_row.to_frame().T], ignore_index=True)\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear the agg_df\n",
    "agg_df = agg_df.iloc[0:0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "01843e40f215bf95274bc2c8c3e35c535d55c23ad112577253f312d1e860a459"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
