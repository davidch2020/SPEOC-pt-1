{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one cleans all files in pre1790 debt certs (ie. who the gov needs to pay back and when)\n",
    "90th is a cent (ie. instead of 100 cents per dollar, 90 cents per dollar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import ssl\n",
    "\n",
    "from nameparser import HumanName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_6579/2089390861.py:2: DtypeWarning: Columns (1,7,9,10,12,14,15,16,19,20,21,24,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  og_df = pd.read_csv(\"../../cleaning_CD/pre1790/data/final_agg_debt.csv\")\n"
     ]
    }
   ],
   "source": [
    "#Load the aggregated file\n",
    "og_df = pd.read_csv(\"../../cleaning_CD/pre1790/data/final_agg_debt.csv\")\n",
    "\n",
    "#Load the changes dataframe\n",
    "corrections_df = None\n",
    "if not os.path.exists(\"../../cleaning_CD/pre1790/name_changes_liam.csv\"):\n",
    "    corrections_df = pd.DataFrame({'og_title': pd.Series(dtype='str'),\n",
    "                       'og_fname': pd.Series(dtype='str'),\n",
    "                       'og_lname': pd.Series(dtype='str'),\n",
    "                       'new_title': pd.Series(dtype='str'),\n",
    "                       'new_fname': pd.Series(dtype='str'),\n",
    "                       'new_lname': pd.Series(dtype='str'),\n",
    "                       'cleaning_case': pd.Series(dtype='int'),\n",
    "                       'file_loc': pd.Series(dtype='str'),\n",
    "                       'org_index': pd.Series(dtype='int')})\n",
    "else:\n",
    "    corrections_df = pd.read_csv(\"../../cleaning_CD/pre1790/name_changes_liam.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    " - retrieve_correction: Get the correction for the title, fname and lname in the dataframe\n",
    " - save_correction: Save the correction, given the original and new names\n",
    " - process_date: (Unused) Correct dates by prompting the user\n",
    " - text_contains_human_name: Returns an array of human names in the supplied text, empty array if no human names (https://unbiased-coder.com/extract-names-python-nltk/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Ask running user if they want to enable manual corrections\n",
    "enable_manual_corrections = input(\"Enable manual correction system (yes, no)? (DO NOT ENABLE IF YOU ARE NOT READY TO MAKE MANUAL CORRECTIONS) > \")\n",
    "enable_manual_corrections = True if enable_manual_corrections == \"yes\" else False\n",
    "\n",
    "def retrieve_correction(og_title, og_fname, og_lname):\n",
    "    '''\n",
    "    Looks for a correction in the corrections dataframe\n",
    "    '''\n",
    "    for index, row in corrections_df.iterrows():\n",
    "        if row[\"og_title\"] == og_title and row[\"og_fname\"] == og_fname and row[\"og_lname\"] == og_lname:\n",
    "            return (row[\"new_title\"], row[\"new_fname\"], row[\"new_lname\"])\n",
    "    return None\n",
    "\n",
    "def save_manual_correction(og_title, og_fname, og_lname, new_title, new_fname, new_lname, clean_case, file, org_i, is_manual):\n",
    "    \"\"\"\n",
    "    Saves a correction to the correction df\n",
    "    \"\"\"\n",
    "    if is_manual and not enable_manual_corrections: return\n",
    "    corrections_df.loc[len(corrections_df.index)] = [\n",
    "        og_title, og_fname, og_lname,\n",
    "        new_title, new_fname, new_lname,\n",
    "        clean_case, file, org_i]\n",
    "\n",
    "#Download the necessary NLTK models for the below function\n",
    "#Change the below to True to use the workaround in case downloads don't work\n",
    "if True:\n",
    "    try:\n",
    "        _unverified = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        ssl._create_default_https_context = _unverified\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "def get_tags(text):\n",
    "    nltk_results = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    tags = {}\n",
    "    for nltk_result in nltk_results:\n",
    "        if type(nltk_result) == Tree:\n",
    "            name = ''\n",
    "            for nltk_result_leaf in nltk_result.leaves():\n",
    "                name += nltk_result_leaf[0] + ' '\n",
    "            tags[name] = nltk_result.label()\n",
    "    return tags\n",
    "\n",
    "def process_date(yr, mon, day, is_issued_date: bool, state_code, index):\n",
    "    \"\"\" Dates in the files can sometimes be invalid, specifically:\\n\n",
    "     - month and year are swapped\\n\n",
    "     - Typos in the year column (ex. 17780)\\n\n",
    "     - Dates that are impossible (Feburary 31, there are only 28 days in feburary)\\n\n",
    "    Args:\n",
    "        yr (int): Year\n",
    "        mon (int): Month\n",
    "        day (int): Day\n",
    "        is_issued_date (bool): specifies whether this date is the date a certificate is issued or the date is the maturity.\n",
    "        state_code (str): state code\n",
    "        index (int): index of row\n",
    "\n",
    "    Returns:\n",
    "        (int: ordinal of the date (datetime.toordinal(s)), bool: did a manual correction need to be made?)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        d = datetime.date(int(yr), int(mon), int(day))\n",
    "        return (d.toordinal(), False)\n",
    "    except Exception as e:\n",
    "        if \"10: ''\" in str(e): #ie. the \"Invalid literal for base 10: ''\" error, which means blank, which means just make it 0\n",
    "            return (0, False)\n",
    "        manual = retrieve_manual_correction(state_code, index)\n",
    "        if manual == None:\n",
    "            if 'month must' in str(e): #ie. month must be in range 1..12 - just swap month and day\n",
    "                d = datetime.date(yr, day, mon)\n",
    "                return (d.toordinal(), False)\n",
    "            new = input(f\"{state_code}: {'RE, ' if ('range' in str(e)) else ''}{'Issued: ' if is_issued_date else 'Expiries: '} {yr} {mon} {day} (yr-mon-day):\")\n",
    "            if new == \"\" and is_issued_date == False:\n",
    "                return (0, False)\n",
    "            d = datetime.date(int(new.split()[0]), int(new.split()[1]), int(new.split()[2]))\n",
    "            return (d.toordinal(), True)\n",
    "        else:\n",
    "            return (int(manual[1].split('-')[0]) if is_issued_date else int(manual[1].split('-')[1]), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Roxbury ': 'ORGANIZATION'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups_removed = og_df.drop_duplicates(subset=[\"to whom due | first name\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of uncleanable entries below. These include:\n",
    " - Names that are more than 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Super fast method - instead of going through it and adding to a new dataset,\n",
    "#use apply with a simple function that doesn't include long strings in a new dataset\n",
    "og_df = og_df[og_df['to whom due | first name'].apply(lambda name: len(str(name).split()) > 5) == False]\n",
    "og_df = og_df[og_df['to whom due | last name'].apply(lambda name: len(str(name).split()) > 5) == False]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives 4 & 8: Standardizing Estate/Town/State/Heir of\n",
    "\n",
    "For state and town of, leave in the state and town in to describe the organization type, ie. First name: \"State of New York\", Last name: \"\" -> First name: \"State\", Last name: \"New York\"\n",
    "\n",
    "For estate and heir of, just get rid of Estate of and Heir of, ie. First name: \"Estate of William Garrett\", Last name: \"\" -> First name: \"William\", Last name: \"Garrett\"\n",
    "\n",
    "Uses fuzzy to make sure that spelling mistakes don't trip it up\n",
    "\n",
    "Standardizes names AND ticks the \"organization?\" flag if state or town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_debt = pd.DataFrame(columns=og_df.columns)\n",
    "agg_debt[\"organization?\"] = False\n",
    "\n",
    "manual_corrections = [\n",
    "    {\"og_fname\": \"State of William Sweet\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"William\", \n",
    "     \"new_lname\": \"Sweet\"},\n",
    "    {\"og_fname\": \"Estateof Doct James Front\",\n",
    "     \"new_title\": \"Doct\",\n",
    "     \"new_fname\": \"James\",\n",
    "     \"new_lname\": \"Front\"},\n",
    "    {\"og_fname\": \"Estate of Capt John Williams\",\n",
    "     \"new_title\": \"Capt\",\n",
    "     \"new_fname\": \"John\",\n",
    "     \"new_lname\": \"Williams\"}\n",
    "]\n",
    "\n",
    "def handle_ofs(row):\n",
    "    og_fname = str(row[\"to whom due | first name\"])\n",
    "    og_lname = str(row[\"to whom due | last name\"])\n",
    "    title = str(row[\"to whom due | title\"])\n",
    "    \n",
    "    for c in manual_corrections:\n",
    "        if c[\"og_fname\"] == og_fname:\n",
    "            row[\"to whom due | first name\"] = c[\"new_fname\"]\n",
    "            row[\"to whom due | last name\"] = c[\"new_lname\"]\n",
    "            row[\"to whom due | title\"] = c[\"new_title\"]\n",
    "            return row\n",
    "    \n",
    "    og_fname = og_fname.replace(\"the \", \"\").replace(\"The \", \"\")\n",
    "    og_lname = og_lname.replace(\"the \", \"\").replace(\"The \", \"\")\n",
    "    \n",
    "    if len(og_fname.split()) > 2:\n",
    "        prefix = og_fname.split()[0] + og_fname.split()[1]\n",
    "        prefix = prefix.lower()\n",
    "        if fuzz.ratio(prefix, \"state of\") >= 88 and \"est\" not in prefix: #\"not in\" so that this one won't pick up \"Estate of\"\n",
    "            lname =  \"-\".join(og_fname.split()[2:])\n",
    "            fname = \"State\"\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 8, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "            row[\"organization?\"] = True\n",
    "        elif fuzz.ratio(prefix, \"town of\") >= 88:\n",
    "            lname =  \"-\".join(og_fname.split()[2:])\n",
    "            fname = \"Town\"\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 8, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "            row[\"organization?\"] = True\n",
    "        elif fuzz.ratio(prefix, \"estate of\") >= 85 and \"est\" in prefix: #\"in prefix\" so that this one won't pick up \"State of\"\n",
    "            #print(og_fname.split()[2:])\n",
    "            name = \" \".join(og_fname.split()[2:])\n",
    "            fname =  name.split()[0]\n",
    "            lname = name.split()[1:] if len(name.split()) > 1 else \"\"\n",
    "            if len(lname) == 0 and row[\"to whom due | last name\"] != \"\": lname = row[\"to whom due | last name\"]\n",
    "            if type(lname) == list: lname = \" \".join(lname)\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 4, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "        elif fuzz.ratio(prefix, \"heir of\") >= 85 or fuzz.ratio(prefix, \"heirs of\") >= 85:\n",
    "            name = \" \".join(og_fname.split()[2:])\n",
    "            fname =  name.split()[0]\n",
    "            lname = name.split()[1:] if len(name.split()) > 1 else \"\"\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 4, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = og_df.apply(lambda row: handle_ofs(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective 14: Standardizing organization names entirely in the first name colummn\n",
    "\n",
    "This is very similiar to State and Town of, except it is supposed to catch ALL organizations using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_all_orgs(row):\n",
    "    og_fname = str(row[\"to whom due | first name\"])\n",
    "    og_lname = str(row[\"to whom due | last name\"])\n",
    "    title = row[\"to whom due | title\"]\n",
    "    \n",
    "    fname, lname = \"\", \"\"\n",
    "    if len(og_fname.split()) > 2 and ((\"of \" in og_fname) or (\" of\" in og_fname)):\n",
    "        tags = get_tags(og_fname)\n",
    "        is_org = False\n",
    "        print(tags)\n",
    "        for token, tag in tags.items():\n",
    "            if tag == \"ORGANIZATION\" or tag == \"GPE\": #Geo political entity\n",
    "                is_org = True\n",
    "        if not is_org: return row\n",
    "        row[\"organization?\"] = True\n",
    "        before_of, after_of = og_fname.split(\"of\")\n",
    "        fname = before_of.strip().replace(\"-\", \"\")\n",
    "        lname = after_of.strip().replace(\"-\", \"\")\n",
    "        save_manual_correction(title, og_fname, og_lname, title, fname, lname, 14, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        row[\"to whom due | first name\"] = fname\n",
    "        row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_all_orgs(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections_df = corrections_df.iloc[0:0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective 9: Names that are entirely in the first or last name column\n",
    "\n",
    "The following checks if one column is completley blank and there seems to be a name in the other, if so use HumanName to automatically parse it and put first and last names where they belong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'organization?'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3621\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'organization?'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_6579/568804152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0magg_debt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_debt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcorrect_full_names_in_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8837\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8838\u001b[0m         )\n\u001b[0;32m-> 8839\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8841\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_6579/568804152.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0magg_debt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg_debt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcorrect_full_names_in_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_6579/568804152.py\u001b[0m in \u001b[0;36mcorrect_full_names_in_column\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcorrect_full_names_in_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"organization?\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;31m#ignore orgnizations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"to whom due | first name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"to whom due | last name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3623\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3624\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3625\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'organization?'"
     ]
    }
   ],
   "source": [
    "def correct_full_names_in_column(row):\n",
    "    if row[\"organization?\"] == True: return row #ignore orgnizations\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    name = None\n",
    "    if lname == \"\" and len(fname.split()) >= 2:\n",
    "        name = HumanName(fname)\n",
    "    if fname == \"\" and len(lname.split()) >= 2:\n",
    "        name = HumanName(lname)\n",
    "    if name == None:\n",
    "        return row\n",
    "    else:\n",
    "        save_manual_correction(row[\"to whom due | title\"], fname, lname, row[\"to whom due | title\"], name.first, name.last, 9, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        row[\"to whom due | first name\"] = name.first\n",
    "        row[\"to whom due | last name\"] = name.last\n",
    "        return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: correct_full_names_in_column(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective 7: Filling in blank columns\n",
    "\n",
    "This one is simple: Just make any blank column UNDEFINED. Note that this has to run AFTER objective 9 (Names that are entirely in the first or last name column fixes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_blank_name_cols(row):\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    if fname == \"\": fname = \"UNDEFINED\" # if there is no first name, make it undefined\n",
    "    elif lname == \"\": lname = \"UNDEFINED\" # if there is no last name, make it undefined\n",
    "    else: return row # if both aren't blank, return the row now\n",
    "    save_manual_correction(row[\"to whom due | title\"], row[\"to whom due | first name\"], row[\"to whom due | last name\"], row[\"to whom due | title\"], fname, lname, 7, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "    row[\"to whom due | first name\"] = fname\n",
    "    row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = og_df.apply(lambda row: handle_blank_name_cols(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective 12: Deceased individuals\n",
    "\n",
    "Checks if \"dec'd\" or other words that indicated a deceased individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_6579/698127720.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0magg_debt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mog_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_deceased\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8837\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8838\u001b[0m         )\n\u001b[0;32m-> 8839\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8841\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_6579/698127720.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0magg_debt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mog_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_deceased\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_6579/698127720.py\u001b[0m in \u001b[0;36mcheck_deceased\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"to whom due | first name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"to whom due | last name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfullname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\" dead\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\" decease\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\" passed\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\" dec'd\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\" dec.\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\" decd\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\" deceasd\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "agg_debt[\"deceased?\"] = False\n",
    "\n",
    "def check_deceased(row):\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    fullname = str(fname) + \" \" + str(lname)\n",
    "    for word in fullname.lower().split():\n",
    "        if \" dead\" or \" decease\" or \" passed\" or \" dec'd\" or \" dec.\" or \" decd\" or \" deceasd\" in word:\n",
    "            row[\"deceased?\"] = True\n",
    "            fname = fname.replace(word, \"\")\n",
    "            lname = lname.replace(word, \"\")\n",
    "            save_manual_correction(row[\"to whom due | title\"], row[\"to whom due | first name\"], row[\"to whom due | last name\"], row[\"to whom due | title\"], fname, lname, 12, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = og_df.apply(lambda row: check_deceased(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: Arch William Yard, Last: UNDEFINED, Title: \n"
     ]
    }
   ],
   "source": [
    "def check_note_present(note):\n",
    "    \"\"\"Checks if a transcriber note is just a number or actually useful\n",
    "\n",
    "    Args:\n",
    "        note (str): the note\n",
    "\n",
    "    Returns:\n",
    "        bool: if the transcriber note is useful\n",
    "    \"\"\"\n",
    "    if note != \"\":\n",
    "        if \"Lo\" in note or \"Ro\" in note:\n",
    "            return False\n",
    "        try:\n",
    "            float(note.strip())\n",
    "            return False\n",
    "        except:\n",
    "            pass\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def add_dash_to_prefix(name, prefix):\n",
    "    name = name.replace(prefix + \" \", prefix + \"-\")\n",
    "    name = name.replace(\" \" + prefix, \"-\" + prefix)\n",
    "    return name\n",
    "\n",
    "agg_cols = list(og_df.columns)\n",
    "agg_cols.append(\"deceased?\")\n",
    "agg_df = pd.DataFrame(columns=agg_cols)\n",
    "\n",
    "for index, row in og_df.iterrows():\n",
    "    row = row.replace(np.nan,'',regex=True)\n",
    "    row[\"deceased?\"] = False\n",
    "    title, fname, lname = row[\"to whom due | title\"].strip(), row[\"to whom due | first name\"].strip(), row[\"to whom due | last name\"].strip()\n",
    "    if len(fname.split()) == 1 and len(lname.split()) == 1:\n",
    "        agg_df.loc[len(agg_df.index)] = row\n",
    "        #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "        continue\n",
    "    #\"Van <something>\" and Zee last name and first name replacements\n",
    "    lname = add_dash_to_prefix(lname, \"Van\")\n",
    "    fname = add_dash_to_prefix(fname, \"Van\")\n",
    "    lname = add_dash_to_prefix(lname, \"Zee\")\n",
    "    fname = add_dash_to_prefix(fname, \"Zee\")\n",
    "    lname = add_dash_to_prefix(lname, \"Zie\")\n",
    "    fname = add_dash_to_prefix(fname, \"Zie\")\n",
    "    #Le, Mc, De name prefixes/suffixes\n",
    "    lname = add_dash_to_prefix(lname, \"Le\")\n",
    "    fname = add_dash_to_prefix(fname, \"Le\")\n",
    "    lname = add_dash_to_prefix(lname, \"De\")\n",
    "    fname = add_dash_to_prefix(fname, \"De\")\n",
    "    lname = add_dash_to_prefix(lname, \"Mc\")\n",
    "    fname = add_dash_to_prefix(fname, \"Mc\")\n",
    "\n",
    "    #Get rid of \"the\" prefixes\n",
    "    fname = fname.replace(\"The \", \"\", 1)\n",
    "    fname = fname.replace(\"the \", \"\", 1)\n",
    "    \n",
    "    #Jr, Sr, 1st, 2nd\n",
    "    lname = add_dash_to_prefix(lname, \"Jr\")\n",
    "    fname = add_dash_to_prefix(fname, \"Jr\")\n",
    "    lname = add_dash_to_prefix(lname, \"Sr\")\n",
    "    fname = add_dash_to_prefix(fname, \"Sr\")\n",
    "    lname = add_dash_to_prefix(lname, \"1st\")\n",
    "    fname = add_dash_to_prefix(fname, \"1st\")\n",
    "    lname = add_dash_to_prefix(lname, \"2nd\")\n",
    "    fname = add_dash_to_prefix(fname, \"2nd\")\n",
    "    lname = add_dash_to_prefix(lname, \"2d\")\n",
    "    fname = add_dash_to_prefix(fname, \"2d\")\n",
    "    #And co handling\n",
    "    fname = fname.replace(\" & Co\", \"\").replace(\" & co\", \"\").replace(\" and Co\", \"\").replace(\" and co\", \"\")\n",
    "    lname = lname.replace(\" & Co\", \"\").replace(\" & co\", \"\").replace(\" and Co\", \"\").replace(\" and co\", \"\")\n",
    "    \n",
    "    #Deceased handling\n",
    "    fullname = fname + \" \" + lname\n",
    "    for word in fullname.split():\n",
    "        if \"dead\" or \"decease\" or \"passed\" or \"dec'd\" or \"dec.\" or \"decd\" in word:\n",
    "            row[\"deceased?\"] = True\n",
    "            fname.replace(word, \"\")\n",
    "            lname.replace(word, \"\")\n",
    "    \n",
    "    #State of/Hiers of/Estate of/Town of handling - makes first name \"<thing>\", last name: \"<name>\"\n",
    "    #use fuzz because there are misspellings of Estate of and Heirs of\n",
    "    if len(fname.split()) > 2:\n",
    "        #State of/town of - \"<thing>\" \n",
    "        prefix = fname.split()[0] + fname.split()[1]\n",
    "        prefix = prefix.lower()\n",
    "        if fuzz.ratio(prefix, \"state of\") >= 88:\n",
    "            lname =  \"-\".join(fname.split()[2:])\n",
    "            fname = \"State\"\n",
    "        elif fuzz.ratio(prefix, \"town of\") >= 88:\n",
    "            lname =  \"-\".join(fname.split()[2:])\n",
    "            fname = \"Town\"\n",
    "        elif fuzz.ratio(prefix, \"estate of\") >= 85:\n",
    "            name = fname.replace(fname.split()[0] + fname.split()[1], \"\")\n",
    "            lname =  name.split()[0]\n",
    "            fname = name.split()[1]\n",
    "        elif fuzz.ratio(prefix, \"heir of\") >= 85:\n",
    "            name = fname.replace(fname.split()[0] + fname.split()[1], \"\")\n",
    "            lname =  name.split()[0]\n",
    "            fname = name.split()[1]\n",
    "    \n",
    "    if \" or \" in row[\"to whom due | last name\"]: continue\n",
    "    \n",
    "    if fname == \"\": fname = \"UNDEFINED\" # if there is no first name, make it undefined\n",
    "    if lname == \"\": lname = \"UNDEFINED\" # if there is no last name, make it undefined\n",
    "    \n",
    "    #if len(fname.split()) > 5 or len(lname.split()) > 5: continue # do not even try with ones that are crazy long\n",
    "    \n",
    "    if len(fname.split()) == 2:\n",
    "        #drop the dot - for example: \"James F.\" -> \"James F\"\n",
    "        if len(fname.replace(\".\", \"\").split()[1]) == 1: fname = fname.split()[0] # if middle initial in fname, drop it\n",
    "        elif len(fname.split()[1]) >= 3: # usually means 2 names\n",
    "            fname = fname.replace(\" \", \"-\")\n",
    "            if len(lname.split()) == 0: #usually means that first and last names are put into just first name column\n",
    "                lname = fname.split(\"-\")[1]\n",
    "                fname = fname.split(\"-\")[0]\n",
    "    #Do the same above for the last name\n",
    "    if len(lname.split()) == 2:\n",
    "        if len(lname.replace(\".\", \"\").split()[1]) == 1: lname = lname.split()[0] # if initial in lname, drop it\n",
    "        elif len(lname.split()[1]) >= 3: lname = lname.replace(\" \", \"-\") # usually means 2 names\n",
    "    if fname == \"\" and lname == \"\": continue # Drop ones with no name data\n",
    "    \n",
    "    if ('&' in fname) or (' and' in fname) or ('|' in fname):\n",
    "        #Means there is co-ownership\n",
    "        to_add = []\n",
    "        sepr = \"\"\n",
    "        if (\"&\" in fname): sepr = \"&\"\n",
    "        if (\" and\" in fname): sepr = \"and\"\n",
    "        if (\"|\" in fname): sepr = \"|\"\n",
    "        for i in range(len(fname.split(sepr))):\n",
    "            row[\"to whom due | first name\"] = fname.split(sepr)[i].strip()\n",
    "            row[\"to whom due | last name\"] = \"undefined\"\n",
    "            agg_df.loc[len(agg_df.index)] = row\n",
    "            #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "        continue\n",
    "    if len(fname.split()) != 1 or len(lname.split()) != 1:\n",
    "        print(f\"First: {fname}, Last: {lname}, Title: {title}\")\n",
    "        correction = retrieve_manual_correction(title + \" \" + fname + \" \" + lname)\n",
    "        if correction != None:\n",
    "            title_new, first_new, last_new, drop = correction\n",
    "            if drop: continue\n",
    "            row[\"to whom due | title\"] = title_new\n",
    "            row[\"to whom due | first name\"] = first_new\n",
    "            row[\"to whom due | last name\"] = last_new\n",
    "            agg_df.loc[len(agg_df.index)] = row\n",
    "            #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "        else:\n",
    "            new = input(f\"In {row['org_file']}, First: {fname}, Last: {lname}, Title: {title} >>> \")\n",
    "            if new == \"s\":\n",
    "                break\n",
    "            elif new == \"k\":\n",
    "                fullname = title + \" \" + fname + \" \" + lname\n",
    "                save_manual_correction(fullname, fullname.replace(\" \", \"-\"), False)\n",
    "            elif new == \"\":\n",
    "                print(\"dropping\")\n",
    "                save_manual_correction(title + \" \" + fname + \" \" + lname, \" \", True)\n",
    "            else:\n",
    "                split = new.split()\n",
    "                nt, nf, nl = \"\", \"\", \"\"\n",
    "                if len(split) == 2:\n",
    "                    nf, nl = new.split()\n",
    "                if len(split) == 3:\n",
    "                    nt, nf, nl = new.split()\n",
    "                save_manual_correction(title + \" \" + fname + \" \" + lname, nt + \" \" + nf + \" \" + nl, False)\n",
    "    else:\n",
    "        agg_df.loc[len(agg_df.index)] = row\n",
    "        #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop that covers Objective 1 (aggregate data files)\n",
    "def element_to_int(ele): # handles all kinds of Nans (returns 0 for nans)\n",
    "    if type(ele) == np.float64:\n",
    "        ele = round(ele)\n",
    "    if ele == np.nan: return 0\n",
    "    if str(ele) == \"nan\": return 0\n",
    "    return round(np.float64(ele))\n",
    "\n",
    "def get_dollar(row): #gets the dollar from a row by checking both dollar columns\n",
    "    dollar = 0\n",
    "    ninety = 0\n",
    "    #if dollar (90th) is a decimal, then split it\n",
    "    if '.' in str(element_to_int(row[11])): # \"amount | dollar\"\n",
    "        split = str(element_to_int(row[11])).split(\".\")\n",
    "        dollar, ninety = element_to_int(split[0]), element_to_int(split[1])\n",
    "    elif str(row[11]) == \"\": # \"amount | dollar\"\n",
    "        if '.' in str(element_to_int(row[24])): # \"amount | specie\"\n",
    "            split = str(element_to_int(row[24])).split() # \"amount | specie\"\n",
    "            dollar, ninety = element_to_int(split[0]), element_to_int(split[1])\n",
    "    else:\n",
    "        dollar = element_to_int(row[11]) # \"amount | dollar\"\n",
    "        ninety = element_to_int(row[12]) # \"amount | 90th\"\n",
    "    return float(str(dollar) + \".\" + str(ninety))\n",
    "\n",
    "def new_tup(old_row, new_dol, new_ninety, new_title): # returns a new tuple, specifically for totaled debt amounts (since you can't assign new values in tuples)\n",
    "    return (old_row[0], old_row[1], old_row[2], old_row[3], old_row[4], old_row[5], old_row[6],\n",
    "            new_title, old_row[8], old_row[9], old_row[10], new_dol, new_ninety, old_row[13],\n",
    "            old_row[14], old_row[15], old_row[16], old_row[17], old_row[18], old_row[19],\n",
    "            old_row[20], old_row[21], old_row[22], old_row[23], old_row[24], old_row[25],\n",
    "            old_row[26], old_row[27], old_row[28], old_row[29], old_row[30], old_row[31])\n",
    "\n",
    "agg_df = pd.DataFrame(columns=og_df.columns)\n",
    "last_f, last_l, last_t = \"\", \"\", \"\"\n",
    "last_row = None\n",
    "#save the sum of money\n",
    "current_sum = 0\n",
    "for row in og_df.itertuples(name=None, index=False): #main processing function\n",
    "    fname, lname = str(row[5]).strip(), str(row[6]).strip()\n",
    "    last_t = last_t if str(row[7]).strip().lower() == \"nan\" else str(row[7]).strip()\n",
    "    if fname == last_f and lname == last_l: #If the next name is the same as the last one, add onto the amount\n",
    "        dol = get_dollar(row)\n",
    "        print(f\"adding {dol} to {fname} {lname}'s total\")\n",
    "        current_sum += dol\n",
    "    else: #If the next name is not the same as the last one:\n",
    "        if current_sum > 0: #If the sum is more than 0 (ie. this is the end of consecutive same-name entries), then only add this on\n",
    "            print(f\"{last_row[5]} {last_row[6]} is consecutively owed {current_sum}\")\n",
    "            #consecutive has ended\n",
    "            split = str(current_sum).split(\".\")\n",
    "            agg_df.loc[len(agg_df.index)] = new_tup(last_row, int(split[0]), int(split[1]), last_t if last_t != \"\" else \"\")\n",
    "            current_sum = 0\n",
    "        else: #If the sum is not more than 0 (ie. this is one unique entry, add it on now)\n",
    "            #Normal\n",
    "            agg_df.loc[len(agg_df.index)] = last_row\n",
    "    last_f, last_l = fname, lname\n",
    "    last_row = row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "01843e40f215bf95274bc2c8c3e35c535d55c23ad112577253f312d1e860a459"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
