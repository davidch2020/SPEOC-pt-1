{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one cleans all files in pre1790 debt certs (ie. who the gov needs to pay back and when)\n",
    "90th is a cent (ie. instead of 100 cents per dollar, 90 cents per dollar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "import nltk\n",
    "\n",
    "#Solution to get around certificate error: https://www.youtube.com/watch?v=IBmZAYR0pns\n",
    "import ssl\n",
    "try:\n",
    "    e = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = e\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpers\n",
    "def deNaN(series):\n",
    "    \"\"\"\n",
    "    amends pandas series by replacing NaN values with empty strings\n",
    "    :param series: pandas series\n",
    "    \"\"\"\n",
    "\n",
    "    return series.apply(lambda x: \"\" if type(x) != str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_3156/1953515890.py:2: DtypeWarning: Columns (1,7,9,10,12,14,15,19,20,21,23,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  og_df = pd.read_csv(\"../../cleaning_CD/pre1790/data/final_agg_debt.csv\")\n"
     ]
    }
   ],
   "source": [
    "#Load  the aggregated file\n",
    "og_df = pd.read_csv(\"../../cleaning_CD/pre1790/data/final_agg_debt.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning process:\n",
    "1. fix all records (ie. remove extraneous information + combine them into agg)\n",
    "   - possibilites of stuff to remove: \"Estate of\", \"Heirs of\",\n",
    "   - possibilites of stuff to fix (ie. find the right name for): \"and Co.\", \"Owners of\",\n",
    "   - first or last name missing: either make the other one undefined, or the entire name is in the first or last name column and it needs to be spread out\n",
    "   - occupation could be in the name\n",
    "   - some last names have spaces in them (specifically Van) - replace them with spaces\n",
    "   - so it needs to look like:\n",
    "     - if fname split or lname split != 1:\n",
    "       - if its just lname contains van, replace \"Van \" with \"Van-\"\n",
    "       - check and auto remove Estate of, Heirs of (using the fuzzy matching in case of misspellings)\n",
    "2. Combine consecutive rows with the same name into one row with a total amount of debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrections.json file format:\n",
    "# [\n",
    "#     {\n",
    "#         \"name_original\": \"\",\n",
    "#         \"title_new\": \"\",\n",
    "#         \"first_new\": \"\",\n",
    "#         \"last_new\": \"\",\n",
    "#         \"drop\": False\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "#Ask running user if they want to enable manual corrections\n",
    "enable_manual_corrections = input(\"Enable manual correction system (yes, no)? (DO NOT ENABLE IF YOU ARE NOT READY TO MAKE MANUAL CORRECTIONS) > \")\n",
    "enable_manual_corrections = True if enable_manual_corrections == \"yes\" else False\n",
    "\n",
    "def retrieve_manual_correction(original_name):\n",
    "    '''\n",
    "    Looks for a correction in the corrections.json file\n",
    "    '''\n",
    "    if not os.path.exists(\"corrections.json\"):\n",
    "        f = open(\"corrections.json\", \"w\")\n",
    "        f.write(\"[]\")\n",
    "        f.close()\n",
    "    file = json.load(open(\"corrections.json\", \"r\"))\n",
    "    for obj in file:\n",
    "        if obj[\"name_original\"] == original_name:\n",
    "            return (obj[\"title_new\"], obj[\"first_new\"], obj[\"last_new\"], obj[\"drop\"])\n",
    "    return None\n",
    "\n",
    "def save_manual_correction(name_original, name_correct, drop: bool):\n",
    "    \"\"\"\n",
    "    Saves a correction to corrections.json\n",
    "    \"\"\"\n",
    "    if not enable_manual_corrections: return\n",
    "    if not os.path.exists(\"corrections.json\"):\n",
    "        f = open(\"corrections.json\", \"w\")\n",
    "        f.write(\"[]\")\n",
    "        f.close()\n",
    "    file = json.load(open(\"corrections.json\", \"r\"))\n",
    "    print(\"SMC: \" + str(drop))\n",
    "    if len(name_correct.split()) == 2:\n",
    "        file.append({\n",
    "            \"name_original\": name_original,\n",
    "            \"title_new\": \"\",\n",
    "            \"first_new\": name_correct.split()[0],\n",
    "            \"last_new\": name_correct.split()[1],\n",
    "            \"drop\": drop\n",
    "        })\n",
    "    if len(name_correct.split()) == 3:\n",
    "        file.append({\n",
    "            \"name_original\": name_original,\n",
    "            \"title_new\": name_correct.split()[0],\n",
    "            \"first_new\": name_correct.split()[1],\n",
    "            \"last_new\": name_correct.split()[2],\n",
    "            \"drop\": drop\n",
    "        })\n",
    "    f = open(\"corrections.json\", \"w\")\n",
    "    json.dump(file, f)\n",
    "    f.close()\n",
    "\n",
    "def process_date(yr, mon, day, is_issued_date: bool, state_code, index):\n",
    "    \"\"\" Dates in the files can sometimes be invalid, specifically:\\n\n",
    "     - month and year are swapped\\n\n",
    "     - Typos in the year column (ex. 17780)\\n\n",
    "     - Dates that are impossible (Feburary 31, there are only 28 days in feburary)\\n\n",
    "    Args:\n",
    "        yr (int): Year\n",
    "        mon (int): Month\n",
    "        day (int): Day\n",
    "        is_issued_date (bool): specifies whether this date is the date a certificate is issued or the date is the maturity.\n",
    "        state_code (str): state code\n",
    "        index (int): index of row\n",
    "\n",
    "    Returns:\n",
    "        (int: ordinal of the date (datetime.toordinal(s)), bool: did a manual correction need to be made?)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        d = datetime.date(int(yr), int(mon), int(day))\n",
    "        return (d.toordinal(), False)\n",
    "    except Exception as e:\n",
    "        if \"10: ''\" in str(e): #ie. the \"Invalid literal for base 10: ''\" error, which means blank, which means just make it 0\n",
    "            return (0, False)\n",
    "        manual = retrieve_manual_correction(state_code, index)\n",
    "        if manual == None:\n",
    "            if 'month must' in str(e): #ie. month must be in range 1..12 - just swap month and day\n",
    "                d = datetime.date(yr, day, mon)\n",
    "                return (d.toordinal(), False)\n",
    "            new = input(f\"{state_code}: {'RE, ' if ('range' in str(e)) else ''}{'Issued: ' if is_issued_date else 'Expiries: '} {yr} {mon} {day} (yr-mon-day):\")\n",
    "            if new == \"\" and is_issued_date == False:\n",
    "                return (0, False)\n",
    "            d = datetime.date(int(new.split()[0]), int(new.split()[1]), int(new.split()[2]))\n",
    "            return (d.toordinal(), True)\n",
    "        else:\n",
    "            return (int(manual[1].split('-')[0]) if is_issued_date else int(manual[1].split('-')[1]), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: Arch William Yard, Last: , Title: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_3156/2124374665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"to whom due | title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"to whom due | first name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"to whom due | last name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0magg_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m#agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2018\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2019\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2020\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2021\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   9064\u001b[0m             \u001b[0;31m# infer_objects is needed for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9065\u001b[0m             \u001b[0;31m#  test_append_empty_frame_to_series_with_dateutil_tz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9066\u001b[0;31m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9067\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9068\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mrename_axis\u001b[0;34m(self, mapper, **kwargs)\u001b[0m\n\u001b[1;32m   1311\u001b[0m             )\n\u001b[1;32m   1312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnon_mapper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use `.rename` to alter labels with a mapper.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis_name\u001b[0;34m(self, name, axis, inplace)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m         \u001b[0mrenamed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m         \u001b[0mrenamed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6030\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6031\u001b[0m         \"\"\"\n\u001b[0;32m-> 6032\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6033\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6034\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def check_note_present(note):\n",
    "    \"\"\"Checks if a transcriber note is just a number or actually useful\n",
    "\n",
    "    Args:\n",
    "        note (str): the note\n",
    "\n",
    "    Returns:\n",
    "        bool: if the transcriber note is useful\n",
    "    \"\"\"\n",
    "    if note != \"\":\n",
    "        if \"Lo\" in note or \"Ro\" in note:\n",
    "            return False\n",
    "        try:\n",
    "            float(note.strip())\n",
    "            return False\n",
    "        except:\n",
    "            pass\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def add_dash_to_prefix(name, prefix):\n",
    "    name = name.replace(prefix + \" \", prefix + \"-\")\n",
    "    name = name.replace(\" \" + prefix, \"-\" + prefix)\n",
    "    return name\n",
    "\n",
    "i = 0\n",
    "agg_cols = list(og_df.columns)\n",
    "agg_cols.append(\"deceased?\")\n",
    "agg_df = pd.DataFrame(columns=agg_cols)\n",
    "\n",
    "for index, row in og_df.iterrows():\n",
    "    row = row.replace(np.nan,'',regex=True)\n",
    "    row[\"deceased?\"] = False\n",
    "    title, fname, lname = row[\"to whom due | title\"].strip(), row[\"to whom due | first name\"].strip(), row[\"to whom due | last name\"].strip()\n",
    "    if len(fname.split()) == 1 and len(lname.split()) == 1:\n",
    "        agg_df.loc[len(agg_df.index)] = row\n",
    "        #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "        continue\n",
    "    #\"Van <something>\" and Zee last name and first name replacements\n",
    "    lname = add_dash_to_prefix(lname, \"Van\")\n",
    "    fname = add_dash_to_prefix(fname, \"Van\")\n",
    "    lname = add_dash_to_prefix(lname, \"Zee\")\n",
    "    fname = add_dash_to_prefix(fname, \"Zee\")\n",
    "    lname = add_dash_to_prefix(lname, \"Zie\")\n",
    "    fname = add_dash_to_prefix(fname, \"Zie\")\n",
    "    #Le, Mc, De name prefixes/suffixes\n",
    "    lname = add_dash_to_prefix(lname, \"Le\")\n",
    "    fname = add_dash_to_prefix(fname, \"Le\")\n",
    "    lname = add_dash_to_prefix(lname, \"De\")\n",
    "    fname = add_dash_to_prefix(fname, \"De\")\n",
    "    lname = add_dash_to_prefix(lname, \"Mc\")\n",
    "    fname = add_dash_to_prefix(fname, \"Mc\")\n",
    "\n",
    "    #Get rid of \"the\" prefixes\n",
    "    fname = fname.replace(\"The \", \"\", 1)\n",
    "    fname = fname.replace(\"the \", \"\", 1)\n",
    "    \n",
    "    #Jr, Sr, 1st, 2nd\n",
    "    lname = add_dash_to_prefix(lname, \"Jr\")\n",
    "    fname = add_dash_to_prefix(fname, \"Jr\")\n",
    "    lname = add_dash_to_prefix(lname, \"Sr\")\n",
    "    fname = add_dash_to_prefix(fname, \"Sr\")\n",
    "    lname = add_dash_to_prefix(lname, \"1st\")\n",
    "    fname = add_dash_to_prefix(fname, \"1st\")\n",
    "    lname = add_dash_to_prefix(lname, \"2nd\")\n",
    "    fname = add_dash_to_prefix(fname, \"2nd\")\n",
    "    lname = add_dash_to_prefix(lname, \"2d\")\n",
    "    fname = add_dash_to_prefix(fname, \"2d\")\n",
    "    #And co handling\n",
    "    fname = fname.replace(\" & Co\", \"\").replace(\" & co\", \"\").replace(\" and Co\", \"\").replace(\" and co\", \"\")\n",
    "    lname = lname.replace(\" & Co\", \"\").replace(\" & co\", \"\").replace(\" and Co\", \"\").replace(\" and co\", \"\")\n",
    "    \n",
    "    #Deceased handling\n",
    "    fullname = fname + \" \" + lname\n",
    "    for word in fullname.split():\n",
    "        if \"dead\" or \"decease\" or \"passed\" in word:\n",
    "            row[\"deceased?\"] = True\n",
    "            fname.replace(word, \"\")\n",
    "            lname.replace(word, \"\")\n",
    "    \n",
    "    #State of/Hiers of/Estate of/Town of handling - makes first name \"<thing>\", last name: \"<name>\"\n",
    "    #use fuzz because there are misspellings of Estate of and Heirs of\n",
    "    if len(fname.split()) > 2:\n",
    "        #State of/town of - \"<thing>\" \n",
    "        prefix = fname.split()[0] + fname.split()[1]\n",
    "        prefix = prefix.lower()\n",
    "        if fuzz.ratio(prefix, \"state of\") >= 88:\n",
    "            lname =  \"-\".join(fname.split()[2:])\n",
    "            fname = \"State\"\n",
    "        elif fuzz.ratio(prefix, \"town of\") >= 88:\n",
    "            lname =  \"-\".join(fname.split()[2:])\n",
    "            fname = \"Town\"\n",
    "        elif fuzz.ratio(prefix, \"estate of\") >= 85:\n",
    "            name = fname.replace(fname.split()[0] + fname.split()[1], \"\")\n",
    "            lname =  name.split()[0]\n",
    "            fname = name.split()[1]\n",
    "        elif fuzz.ratio(prefix, \"heir of\") >= 85:\n",
    "            name = fname.replace(fname.split()[0] + fname.split()[1], \"\")\n",
    "            lname =  name.split()[0]\n",
    "            fname = name.split()[1]\n",
    "    \n",
    "    if \" or \" in row[\"to whom due | last name\"]: continue\n",
    "    \n",
    "    if len(fname.split()) == 1 and lname == \"\": lname = \"undefined\" # if there is no last name, make it undefined\n",
    "    \n",
    "    #if len(fname.split()) > 5 or len(lname.split()) > 5: continue # do not even try with ones that are crazy long\n",
    "    \n",
    "    if len(fname.split()) == 2:\n",
    "        #drop the dot - for example: \"James F.\" -> \"James F\"\n",
    "        if len(fname.replace(\".\", \"\").split()[1]) == 1: fname = fname.split()[0] # if middle initial in fname, drop it\n",
    "        elif len(fname.split()[1]) >= 3: # usually means 2 names\n",
    "            fname = fname.replace(\" \", \"-\")\n",
    "            if len(lname.split()) == 0: #usually means that first and last names are put into just first name column\n",
    "                lname = fname.split(\"-\")[1]\n",
    "                fname = fname.split(\"-\")[0]\n",
    "    #Do the same above for the last name\n",
    "    if len(lname.split()) == 2:\n",
    "        if len(lname.replace(\".\", \"\").split()[1]) == 1: lname = lname.split()[0] # if initial in lname, drop it\n",
    "        elif len(lname.split()[1]) >= 3: lname = lname.replace(\" \", \"-\") # usually means 2 names\n",
    "    if fname == \"\" and lname == \"\": continue # Drop ones with no name data\n",
    "    \n",
    "    if ('&' in fname) or (' and' in fname) or ('|' in fname):\n",
    "        #Means there is co-ownership\n",
    "        to_add = []\n",
    "        sepr = \"\"\n",
    "        if (\"&\" in fname): sepr = \"&\"\n",
    "        if (\" and\" in fname): sepr = \"and\"\n",
    "        if (\"|\" in fname): sepr = \"|\"\n",
    "        for i in range(len(fname.split(sepr))):\n",
    "            row[\"to whom due | first name\"] = fname.split(sepr)[i].strip()\n",
    "            row[\"to whom due | last name\"] = \"undefined\"\n",
    "            agg_df.loc[len(agg_df.index)] = row\n",
    "            #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "        continue\n",
    "    if len(fname.split()) != 1 or len(lname.split()) != 1:\n",
    "        i += 1\n",
    "        print(f\"First: {fname}, Last: {lname}, Title: {title}\")\n",
    "        correction = retrieve_manual_correction(title + \" \" + fname + \" \" + lname)\n",
    "        if correction != None:\n",
    "            title_new, first_new, last_new, drop = correction\n",
    "            if drop: continue\n",
    "            row[\"to whom due | title\"] = title_new\n",
    "            row[\"to whom due | first name\"] = first_new\n",
    "            row[\"to whom due | last name\"] = last_new\n",
    "            agg_df.loc[len(agg_df.index)] = row\n",
    "            #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "        else:\n",
    "            new = input(f\"In {row['org_file']}, First: {fname}, Last: {lname}, Title: {title} >>> \")\n",
    "            if new == \"s\":\n",
    "                break\n",
    "            elif new == \"k\":\n",
    "                fullname = title + \" \" + fname + \" \" + lname\n",
    "                save_manual_correction(fullname, fullname.replace(\" \", \"-\"), False)\n",
    "            elif new == \"\":\n",
    "                print(\"dropping\")\n",
    "                save_manual_correction(title + \" \" + fname + \" \" + lname, \" \", True)\n",
    "            else:\n",
    "                split = new.split()\n",
    "                nt, nf, nl = \"\", \"\", \"\"\n",
    "                if len(split) == 2:\n",
    "                    nf, nl = new.split()\n",
    "                if len(split) == 3:\n",
    "                    nt, nf, nl = new.split()\n",
    "                save_manual_correction(title + \" \" + fname + \" \" + lname, nt + \" \" + nf + \" \" + nl, False)\n",
    "    else:\n",
    "        agg_df.loc[len(agg_df.index)] = row\n",
    "        #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'croak', 'go', 'pop_off', 'kick_the_bucket', 'choke', 'asleep', 'conk', 'decease', \"cash_in_one's_chips\", 'snuff_it', 'departed', 'give-up_the_ghost', 'buy_the_farm', 'exit', 'die', 'at_peace', 'perish', 'expire', 'pass_away', 'deceased_person', 'at_rest', 'gone', 'pass', 'decedent', 'drop_dead', 'dead_soul', 'deceased', 'dead_person'}\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "for syn in wordnet.synsets(\"deceased\"):\n",
    "    for lm in syn.lemmas():\n",
    "        synonyms.append(lm.name())#adding into synonyms\n",
    "print (set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop that covers Objective 1 (aggregate data files)\n",
    "#save the name\n",
    "def element_to_int(ele):\n",
    "    if type(ele) == np.float64:\n",
    "        ele = round(ele)\n",
    "    if ele == np.nan: return 0\n",
    "    if str(ele) == \"nan\": return 0\n",
    "    return round(np.float64(ele))\n",
    "\n",
    "def get_dollar(row):\n",
    "    dollar = 0\n",
    "    ninety = 0\n",
    "    #if dollar (90th) is a decimal, then split it\n",
    "    if '.' in str(element_to_int(row[\"amount | dollars\"])):\n",
    "        split = str(element_to_int(row[\"amount | dollars\"])).split(\".\")\n",
    "        dollar, ninety = element_to_int(split[0]), element_to_int(split[1])\n",
    "    elif str(row[\"amount | dollars\"]) == \"\":\n",
    "        if '.' in str(element_to_int(row[\"amount in specie | dollars\"])):\n",
    "            split = str(element_to_int(row[\"amount in specie | dollars\"])).split()\n",
    "            dollar, ninety = element_to_int(split[0]), element_to_int(split[1])\n",
    "    else:\n",
    "        dollar = element_to_int(row[\"amount | dollars\"])\n",
    "        ninety = element_to_int(row[\"amount | 90th\"])\n",
    "    return float(str(dollar) + \".\" + str(ninety))\n",
    "\n",
    "agg_df = pd.DataFrame(columns=og_df.columns)\n",
    "last_f, last_l, last_t = \"\", \"\", \"\"\n",
    "last_row = None\n",
    "#save the sum of money\n",
    "current_sum = 0\n",
    "for index, row in og_df.iterrows():\n",
    "    fname, lname = str(row[\"to whom due | first name\"]).strip(), str(row[\"to whom due | last name\"]).strip()\n",
    "    last_t = last_t if str(row[\"to whom due | title\"]).strip().lower() == \"nan\" else str(row[\"to whom due | title\"]).strip()\n",
    "    if fname == last_f and lname == last_l:\n",
    "        dol = get_dollar(row)\n",
    "        print(f\"adding {dol} to {fname} {lname}'s total\")\n",
    "        current_sum += dol\n",
    "    else:\n",
    "        if current_sum > 0:\n",
    "            print(f\"{last_row['to whom due | first name']} {last_row['to whom due | last name']} is consecutively owed {current_sum}\")\n",
    "            #consecutive has ended\n",
    "            split = str(current_sum).split(\".\")\n",
    "            last_row[\"amount | dollars\"] = int(split[0])\n",
    "            last_row[\"amount | 90th\"] = int(split[1])\n",
    "            last_row[\"to whom due | title\"] = last_t if last_t != \"\" else \"\"\n",
    "            agg_df.loc[len(agg_df.index)] = last_row\n",
    "            #agg_df = pd.concat([agg_df, last_row.to_frame().T], ignore_index=True)\n",
    "            current_sum = 0\n",
    "        else:\n",
    "            #Normal\n",
    "            agg_df.loc[len(agg_df.index)] = last_row\n",
    "            #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "    last_f, last_l = fname, lname\n",
    "    last_row = row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "01843e40f215bf95274bc2c8c3e35c535d55c23ad112577253f312d1e860a459"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
