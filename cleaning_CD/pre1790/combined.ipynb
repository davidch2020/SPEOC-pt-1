{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cells order\n",
    " - imports\n",
    " - load/create dataframes\n",
    " - helper functions\n",
    " - any manual corrections / manually dropping invalid rows\n",
    " - Standardizing Town/State/Estate/Heir of (obj. 4 & 8)\n",
    " - Standardizing names containing 'of' entirely in the first name column\n",
    " - Companies (obj 2)\n",
    " - Entries with 2 names (obj 3)\n",
    " - Names that are entirely in the first or last name column (obj 9)\n",
    " - Filling in blank columns (obj 7)\n",
    " - Deceased individuals (obj 12)\n",
    " - abbreviations (obj 5)\n",
    " - Group consecutive names (obj 1)\n",
    " - Ancestry code\n",
    "# Objectives\n",
    "\n",
    "[here](https://docs.google.com/document/d/1pcSQfWNll6K9tl-_rB4lztN0TsZsclU9vOnbyQob-Zs/edit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import ssl\n",
    "\n",
    "from nameparser import HumanName\n",
    "#---\n",
    "import re\n",
    "import csv\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes\n",
    "agg_debt = pd.read_csv('data/final_agg_debt.csv')\n",
    "\n",
    "name_changes = pd.DataFrame({'title_org': pd.Series(dtype='str'),\n",
    "                       'title_new': pd.Series(dtype='str'),\n",
    "                       'first_name_org': pd.Series(dtype='str'),\n",
    "                       'last_name_org': pd.Series(dtype='str'),\n",
    "                       'first_name_new': pd.Series(dtype='str'),\n",
    "                       'last_name_new': pd.Series(dtype='str'),\n",
    "                       'cleaning case': pd.Series(dtype='int'),\n",
    "                       'file_loc': pd.Series(dtype='str'),\n",
    "                       'org_index': pd.Series(dtype='int')})\n",
    "\n",
    "# retrieve manual corrections from csv file if they exist \n",
    "manual_corrects_df = pd.read_csv('data/manual_corrections.csv')\n",
    "manual_corrects_dict = manual_corrects_df.to_dict(orient='index')\n",
    "manual_corrects = {}\n",
    "# add manual corrections to manual_corrects dictionary \n",
    "for correction in manual_corrects_dict.keys():\n",
    "    manual_corrects[manual_corrects_dict[correction]['Unnamed: 0']] = [manual_corrects_dict[correction]['new first name'], manual_corrects_dict[correction]['new last name']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documenting Changes\n",
    "\n",
    "<b>Goal: </b> We need to document changes we make to ```agg_debt.csv``` in a separate dataframe: ```name_changes```. This way, we can double-check whether those changes were appropriate. \n",
    "\n",
    "<b>Steps</b>\n",
    "1. Create an empty dataframe. Here are the column names:\n",
    "    - ```title_org```: The original title of the individual (Mr., Ms., etc.)\n",
    "    - ```title_new```: The new title of the individual (Mr., Ms., etc.) \n",
    "    - ```first_name_org```: The original first name of the individual from the unchanged ```agg_debt.csv```\n",
    "    - ```last_name_org```: The original last name of the individual from the unchanged ```agg_debt.csv``` \n",
    "    - ```first_name_new``` : If first name changed, record it here. Otherwise, this entry will still be the old name. \n",
    "    - ```last_name_new```: If last name changed, record it here. Otherwise, this entry will still be the old name. \n",
    "    - ```cleaning case```: This corresponds with the task number in the objectives document linked above. \n",
    "    - ```file_loc```: The individual state filename in which the row came from \n",
    "    - ```org_index```: The original index/row that the debt entry can be found in ```file_loc``` \n",
    "2. Create a function that adds a new row to the dataframe. This function will be called while we are cleaning. \n",
    "\n",
    "**Cleaning case = Objective number** \n",
    "- Combine multiple consective debt entries (optional) = 1,\n",
    "- Clean company names = 2,\n",
    "- Handle two names = 3,\n",
    "- Remove \"Estate of\" = 4,\n",
    "- Handle abbreviations = 5,\n",
    "- Standardize names (Ancestry) = 6\n",
    "- Fill in blank name columns = 7,\n",
    "- remove \"Heirs of\" prefixes = 8,\n",
    "- Names that are entierly in first or last name column = 9,\n",
    "- Occupations in the name = 10,\n",
    "- Entry on behalf of someone else = 11,\n",
    "- Mark deceased people = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def add_changes(title_org, title_new, fn_org, ln_org, fn_new, ln_new, case, file, index):\n",
    "    name_changes.loc[len(name_changes.index)] = [title_org, title_new, fn_org, ln_org, fn_new, ln_new, case, file, index]\n",
    "\n",
    "#Download the necessary NLTK models for the below function\n",
    "#Change the below to True to use the workaround in case downloads don't work\n",
    "if True:\n",
    "    try:\n",
    "        _unverified = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        ssl._create_default_https_context = _unverified\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "def get_tags(text):\n",
    "    nltk_results = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    tags = {}\n",
    "    for nltk_result in nltk_results:\n",
    "        if type(nltk_result) == Tree:\n",
    "            name = ''\n",
    "            for nltk_result_leaf in nltk_result.leaves():\n",
    "                name += nltk_result_leaf[0] + ' '\n",
    "            tags[name] = nltk_result.label()\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove long strings\n",
    "#Super fast method - instead of going through it and adding to a new dataset,\n",
    "#use apply with a simple function that doesn't include long strings in a new dataset\n",
    "agg_debt = agg_debt[agg_debt['to whom due | first name'].apply(lambda name: len(str(name).split()) > 10) == False]\n",
    "agg_debt = agg_debt[agg_debt['to whom due | last name'].apply(lambda name: len(str(name).split()) > 10) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heirs of & Estate of\n",
    "\n",
    "<b>Goal:</b> Remove \"Estate of\", \"Heirs of\", \"State of\" prefixes in an entry, and marks \"State of\" entries as organizations\n",
    "\n",
    "<b>Steps:</b>\n",
    "\n",
    "1. Check if a first name entry is longer than 2 words. If it is, run fuzzy checks to see if it begins with State of/Town of/Estate of/Heirs of (Use fuzzy checks to account for typos, which are quite frequent)\n",
    "2. For State of and Town of matches, make the first name \"State\" or \"Town\" respectively, make the last name the name of the state/town, and mark it as an organization\n",
    "3. For Estate of and Heirs of, make the first word the first name, and everything beyond it the last name\n",
    "4. Record any changes in ```name_changes```\n",
    "\n",
    "<b>Notes:</b>\n",
    "\n",
    "1. Sometimes \"Estate of\" is abbreviated to \"State of\", which confuses it (an example is the first manual correction)\n",
    "2. The \"State of\" fuzzy ratio threshold is higher than the \"Estate of\" and runs before it to catch \"State of\" as reliably as possible, just because they are 1 letter off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agg_debt[\"organization?\"] = False\n",
    "\n",
    "manual_corrections = [\n",
    "    {\"og_fname\": \"State of William Sweet\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"William\", \n",
    "     \"new_lname\": \"Sweet\"},\n",
    "    {\"og_fname\": \"Estateof Doct James Front\",\n",
    "     \"new_title\": \"Doct\",\n",
    "     \"new_fname\": \"James\",\n",
    "     \"new_lname\": \"Front\"},\n",
    "    {\"og_fname\": \"Estate of Capt John Williams\",\n",
    "     \"new_title\": \"Capt\",\n",
    "     \"new_fname\": \"John\",\n",
    "     \"new_lname\": \"Williams\"},\n",
    "    {\"og_fname\": \"Estate ofJon Bowman\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"Jon\",\n",
    "     \"new_lname\": \"Bowman\"},\n",
    "    {\"og_fname\": \"Esatate of Matthew Fentom\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"Matthew\",\n",
    "     \"new_lname\": \"Fentom\"}\n",
    "]\n",
    "\n",
    "def handle_ofs(row):\n",
    "    og_fname = str(row[\"to whom due | first name\"])\n",
    "    og_lname = str(row[\"to whom due | last name\"])\n",
    "    title = str(row[\"to whom due | title\"])\n",
    "    \n",
    "    for c in manual_corrections:\n",
    "        if c[\"og_fname\"] == og_fname:\n",
    "            row[\"to whom due | first name\"] = c[\"new_fname\"]\n",
    "            row[\"to whom due | last name\"] = c[\"new_lname\"]\n",
    "            row[\"to whom due | title\"] = c[\"new_title\"]\n",
    "            return row\n",
    "    \n",
    "    og_fname = og_fname.replace(\"the \", \"\").replace(\"The \", \"\")\n",
    "    og_lname = og_lname.replace(\"the \", \"\").replace(\"The \", \"\")\n",
    "    \n",
    "    if len(og_fname.split()) > 2:\n",
    "        prefix = og_fname.split()[0] + og_fname.split()[1]\n",
    "        prefix = prefix.lower()\n",
    "        if fuzz.ratio(prefix, \"state of\") >= 88 and \"est\" not in prefix: #\"not in\" so that this one won't pick up \"Estate of\"\n",
    "            lname =  \" \".join(og_fname.split()[2:])\n",
    "            fname = \"State\"\n",
    "            add_changes(title, title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], fname, lname, 8, row[\"org_file\"], row[\"org_index\"])\n",
    "            #save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 8, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "            row[\"organization?\"] = True\n",
    "        elif fuzz.ratio(prefix, \"town of\") >= 88:\n",
    "            lname =  \" \".join(og_fname.split()[2:])\n",
    "            fname = \"Town\"\n",
    "            add_changes(title, title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], fname, lname, 8, row[\"org_file\"], row[\"org_index\"])\n",
    "            #save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 8, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "            row[\"organization?\"] = True\n",
    "        elif (fuzz.ratio(prefix, \"estate of\") >= 85 or fuzz.ratio(prefix, \"Est of\") >= 85) and \"est\" in prefix: #\"in prefix\" so that this one won't pick up \"State of\"\n",
    "            #print(og_fname.split()[2:])\n",
    "            name = \" \".join(og_fname.split()[2:])\n",
    "            fname =  name.split()[0]\n",
    "            lname = name.split()[1:] if len(name.split()) > 1 else \"\"\n",
    "            if len(lname) == 0 and row[\"to whom due | last name\"] != \"\": lname = row[\"to whom due | last name\"]\n",
    "            if type(lname) == list: lname = \" \".join(lname)\n",
    "            add_changes(title, title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], fname, lname, 4, row[\"org_file\"], row[\"org_index\"])\n",
    "            #save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 4, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "        elif fuzz.ratio(prefix, \"heir of\") >= 85 or fuzz.ratio(prefix, \"heirs of\") >= 85:\n",
    "            name = \" \".join(og_fname.split()[2:])\n",
    "            fname =  name.split()[0]\n",
    "            lname = name.split()[1:] if len(name.split()) > 1 else \"\"\n",
    "            add_changes(title, title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], fname, lname, 4, row[\"org_file\"], row[\"org_index\"])\n",
    "            #save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 4, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_ofs(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing names containing 'of' entirely in the first name column\n",
    "manual_corrections = {\n",
    "    \"School Committee of Derbey\": [\"School Committee\", \"Derbey\"],\n",
    "    \"Trusts of Wilmington Academy\": [\"Trusts\", \"Wilmington Academy\"],\n",
    "    \"Trusts of Wilmington\": [\"Trusts\", \"Wilmington\"],\n",
    "    \"Ruten of Chais\": [\"Ruten\", \"\"]\n",
    "}\n",
    "\n",
    "def handle_all_orgs(row):\n",
    "    og_fname = str(row[\"to whom due | first name\"])\n",
    "    og_lname = str(row[\"to whom due | last name\"])\n",
    "    title = row[\"to whom due | title\"]\n",
    "    \n",
    "    for og, correction in manual_corrections.items():\n",
    "        if og == og_fname:\n",
    "            row[\"organization?\"] = True\n",
    "            row[\"to whom due | first name\"] = correction[0]\n",
    "            row[\"to whom due | last name\"] = correction[1]\n",
    "            return row\n",
    "    \n",
    "    fname, lname = \"\", \"\"\n",
    "    if len(og_fname.split()) > 2 and ((\"of \" in og_fname) or (\" of\" in og_fname)):\n",
    "        tags = get_tags(og_fname)\n",
    "        is_org = True\n",
    "        for token, tag in tags.items():\n",
    "            if tag == \"PERSON\": #Geo political entity\n",
    "                is_org = False\n",
    "        print(f\"{og_fname} {tags}: {is_org}\")\n",
    "        if not is_org: return row\n",
    "        row[\"organization?\"] = True\n",
    "        before_of, after_of = og_fname.split(\"of\")\n",
    "        fname = before_of.strip().replace(\"-\", \"\")\n",
    "        lname = after_of.strip().replace(\"-\", \"\")\n",
    "        add_changes(title, title, og_fname, og_lname, fname, lname, 14, row[\"org_file\"], row[\"org_index\"])\n",
    "        #save_manual_correction(title, og_fname, og_lname, title, fname, lname, 14, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        row[\"to whom due | first name\"] = fname\n",
    "        row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_all_orgs(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company names\n",
    "# retrieve manual corrections from csv file if they exist \n",
    "manual_corrects_df = pd.read_csv('data/manual_corrections.csv')\n",
    "manual_corrects_dict = manual_corrects_df.to_dict(orient='index')\n",
    "manual_corrects = {}\n",
    "# add manual corrections to manual_corrects dictionary \n",
    "for correction in manual_corrects_dict.keys():\n",
    "    manual_corrects[manual_corrects_dict[correction]['Unnamed: 0']] = [manual_corrects_dict[correction]['new first name'], manual_corrects_dict[correction]['new last name']]\n",
    "\n",
    "# dictionary of manual changes i have to make \n",
    "changes = {\n",
    "    'Henry Mc Clellen & Henry & co' : 'Henry Mc Clellen & Co'\n",
    "}\n",
    "\n",
    "conn_words = [' for ', ' of ', ' and '] # these are connector key words\n",
    "corp_key_words = ('corporation', ' and co', ' and coy', ' and others', ' and several others', ' and heirs', ' and comp', ' and other trustees') # these are corporation key words\n",
    "\n",
    "def handle_comp_name(row):        \n",
    "    org_fname = str(row['to whom due | first name'])\n",
    "    org_lname = str(row['to whom due | last name'])\n",
    "    \n",
    "    fname = str(row['to whom due | first name'])\n",
    "    fname = fname.replace('&', 'and')\n",
    "    fname = fname.replace('.', '')\n",
    "    \n",
    "    if fname in changes:\n",
    "        fname = changes[fname]\n",
    "    \n",
    "    fname_l = str(fname).lower().strip()\n",
    "    \n",
    "    # check if string ends with co, coy, or others; if so, delete \n",
    "    for key_word in corp_key_words:\n",
    "        if fname_l.endswith(key_word):\n",
    "            print('index=' + str(row['Unnamed: 0']))\n",
    "            print('old name=' + str(fname_l))      \n",
    "            fname_corr = fname_l.split(key_word)\n",
    "            print('corrected name=' + str(fname_corr[0])) \n",
    "            fname_corr = fname_corr[0]\n",
    "            fname_sp = fname_corr.split()\n",
    "            \n",
    "            # only one name; put name into last name column \n",
    "            if len(fname_sp) == 1:\n",
    "                row['to whom due | first name'] = ''\n",
    "                row['to whom due | last name'] = fname_sp[0].capitalize()\n",
    "                print('corrected name=' + str(fname_sp[0])) \n",
    "                print('new last name=' + str(fname_sp[0].capitalize()))\n",
    "                \n",
    "            # if there are is only a first name and a last name, put into respective columns\n",
    "            elif len(fname_sp) == 2:\n",
    "                row['to whom due | first name'] = fname_sp[0].capitalize()\n",
    "                row['to whom due | last name'] = fname_sp[1].capitalize()\n",
    "                print('new first name=' + str(fname_sp[0].capitalize()))\n",
    "                print('new last name=' + str(fname_sp[1].capitalize()))\n",
    "                \n",
    "            # handles middle names; put middle names in last name column \n",
    "            elif len(fname_sp) == 3:\n",
    "                row['to whom due | first name'] = fname_sp[0].capitalize() \n",
    "                row['to whom due | last name'] = fname_sp[1].capitalize() + ' ' + fname_sp[2].capitalize()\n",
    "                print('new first name=' + str(fname_sp[0].capitalize()))\n",
    "                print('new last name=' + str(fname_sp[1].capitalize() + ' ' + fname_sp[2].capitalize()))  \n",
    "            # manually clean debt entries that have long names \n",
    "            else: \n",
    "                # check if name has already been manually cleaned\n",
    "                if fname_corr in manual_corrects:\n",
    "                    new_fname = manual_corrects[fname_corr][0]\n",
    "                    new_lname = manual_corrects[fname_corr][1]\n",
    "                else:\n",
    "                    new_fname = input('new first name: ')\n",
    "                    new_lname = input('new last name: ') \n",
    "                    manual_corrects[fname_corr] = [new_fname, new_lname]\n",
    "                \n",
    "                row['to whom due | first name'] = new_fname.capitalize()\n",
    "                row['to whom due | last name'] = new_lname.capitalize()\n",
    "                    \n",
    "                print('new first name=' + str(new_fname.capitalize()))\n",
    "                print('new last name=' + str(new_lname.capitalize()))  \n",
    "                \n",
    "            # record change \n",
    "            add_changes(row['to whom due | title'], row['to whom due | title'], org_fname, org_lname, \n",
    "                   row['to whom due | first name'], row['to whom due | last name'], 2, row['org_file'], row['org_index'])\n",
    "            \n",
    "            print('+------------------------------+')\n",
    "        # if the name starts with any keyword: 'corporation for the relief of...'; manually change these names\n",
    "        elif fname_l.startswith(key_word): \n",
    "            print('index=' + str(row['Unnamed: 0']))\n",
    "            print('old name=' + str(fname_l))      \n",
    "            \n",
    "            # check if name has already been manually cleaned\n",
    "            if fname_l in manual_corrects:\n",
    "                new_fname = str(manual_corrects[fname_l][0])\n",
    "                new_lname = str(manual_corrects[fname_l][1])\n",
    "            else:\n",
    "                new_fname = input('new first name: ')\n",
    "                new_lname = input('new last name: ') \n",
    "                manual_corrects[fname_l] = [new_fname, new_lname]\n",
    "\n",
    "            row['to whom due | first name'] = new_fname.capitalize()\n",
    "            row['to whom due | last name'] = new_lname.capitalize()\n",
    "            \n",
    "            # record change \n",
    "            add_changes(row['to whom due | title'], row['to whom due | title'], org_fname, org_lname, \n",
    "                   row['to whom due | first name'], row['to whom due | last name'], 2, row['org_file'], row['org_index'])\n",
    "\n",
    "            print('new first name=' + str(new_fname.capitalize()))\n",
    "            print('new last name=' + str(new_lname.capitalize()))  \n",
    "    \n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_comp_name(row), axis=1)\n",
    "agg_debt['Unnamed: 0'] = agg_debt.index\n",
    "agg_debt.rename(columns={'Unnamed: 0' : 'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entries with 2 names\n",
    "changes = {\n",
    "    'van zandt & kittletas' : ['', 'van zandt | kittletas'],\n",
    "    'trustees of & davids church':['trustees of & davids church', '']\n",
    "}\n",
    "# make sure all names are of type: str\n",
    "agg_debt[['to whom due | first name', 'to whom due | last name']] = agg_debt[['to whom due | first name', 'to whom due | last name']].astype(str)\n",
    "# Function to convert\n",
    "def listToString(s):\n",
    " \n",
    "    # initialize an empty string\n",
    "    str1 = \" \"\n",
    " \n",
    "    # return string\n",
    "    return (str1.join(s))\n",
    "\n",
    "def handle_two_name(row):\n",
    "    org_fn = row['to whom due | first name']\n",
    "    org_ln = row['to whom due | last name']\n",
    "    \n",
    "    org_fn_l = str(org_fn).lower()\n",
    "        \n",
    "    # remove extraneous information like 'for the estates of...'\n",
    "    org_fn_l = org_fn_l.split(' for ')[0]\n",
    "\n",
    "    # remove extraneous information like 'of the heirs of...'\n",
    "    org_fn_l = org_fn_l.split(' of ')[0]\n",
    "\n",
    "    # remove occupations: guardians, etc. \n",
    "    org_fn_l = org_fn_l.replace(' guardian', '')\n",
    "    \n",
    "    # check if there are two individuals, but check if there are more than 7 words (most likely a society)\n",
    "    if ' and ' in org_fn_l and len(org_fn_l.split()) <= 7:   \n",
    "        print('original name= ' + org_fn_l)\n",
    "        \n",
    "        # cleaning extraneous information can reveal there to be only one name\n",
    "        #if ' and ' in org_fn_l:\n",
    "        person1 = org_fn_l.split(' and ')[0]\n",
    "        person2 = org_fn_l.split(' and ')[1]\n",
    "        person1_sp = person1.split() \n",
    "        person2_sp = person2.split()\n",
    "\n",
    "        # recapitalize people's names\n",
    "        person1_sp = [i.title() for i in person1_sp]\n",
    "        person2_sp = [i.title() for i in person2_sp]\n",
    "\n",
    "        # if both individuals only have a last name; put both last names into last name column  ex. edward and joseph\n",
    "        if len(person1_sp) == 1 and len(person2_sp) == 1:\n",
    "            row['to whom due | first name'] = ''\n",
    "            row['to whom due | last name'] = [person1_sp[0], person2_sp[0]] \n",
    "            \n",
    "            print('new last name col (org)=' + listToString(row['to whom due | last name']))\n",
    "        # if there are three separate last names; put all three into last name column: ex. vance caldwell and vance\n",
    "        elif len(person1_sp) == 2 and len(person2_sp) == 1:\n",
    "            row['to whom due | first name'] = ''\n",
    "            row['to whom due | last name'] = [person1_sp[0], person1_sp[1], person2_sp[0]]\n",
    "            print('new last name col=' + listToString(row['to whom due | last name']))\n",
    "        # if both individuals belong to the same family; put names into respective cols: ex. peter and isaac wikoff  \n",
    "        elif len(person1_sp) == 1 and len(person2_sp) == 2:\n",
    "            row['to whom due | first name'] = [person1_sp[0], person2_sp[0]]\n",
    "            row['to whom due | last name'] = person2_sp[1]\n",
    "            print('new first name col=' + listToString(row['to whom due | first name']))\n",
    "            print('new last name col=' + listToString(row['to whom due | last name']))\n",
    "        # if both individuals are two completely different people with full names; ex. john doe and james hill\n",
    "        elif len(person1_sp) == 2 and len(person2_sp) == 2:\n",
    "            row['to whom due | first name'] = [person1_sp[0], person2_sp[0]]\n",
    "            row['to whom due | last name'] = [person1_sp[1], person2_sp[1]]\n",
    "            print('new first name col=' + listToString(row['to whom due | first name']))\n",
    "            print('new last name col=' + listToString(row['to whom due | last name']))\n",
    "        # if either individual has a middle name; group middle names with the last name; ex. john hill doe and james madison hill\n",
    "        elif len(person1_sp) == 3 or len(person2_sp) == 3:\n",
    "            row['to whom due | first name'] = [person1_sp[0], person2_sp[0]]\n",
    "            # determine which individual has the middle name\n",
    "            if len(person1_sp) == 3:\n",
    "                person2_ln = ''\n",
    "                if len(person2_sp) > 1:\n",
    "                    person2_ln = person2_sp[1]\n",
    "                \n",
    "                row['to whom due | last name'] = [person1_sp[1] + ' ' + person1_sp[2], person2_ln]\n",
    "                print('new last name col=' + listToString(row['to whom due | last name']))\n",
    "            elif len(person2_sp) == 3:\n",
    "                person1_ln = ''\n",
    "                if len(person1_sp) > 1:\n",
    "                    person1_ln = person1_sp[1]\n",
    "                \n",
    "                row['to whom due | last name'] = [person1_ln, person2_sp[1] + ' ' + person2_sp[2]]\n",
    "                print('new last name col=' + listToString(row['to whom due | last name']))\n",
    "            # both individuals have a middle name \n",
    "            else:\n",
    "                row['to whom due | last name'] = [person1_sp[1] + ' ' + person1_sp[2], person2_sp[1] + ' ' + person2_sp[2]]\n",
    "                print('new last name col=' + listToString(row['to whom due | last name']))\n",
    "        \n",
    "        # handle all other types of names manually\n",
    "        else:\n",
    "            if org_fn in manual_corrects:\n",
    "                new_fname = str(manual_corrects[org_fn][0])\n",
    "                new_lname = str(manual_corrects[org_fn][1])\n",
    "            else:\n",
    "                new_fname = input('new first name: ')\n",
    "                new_lname = input('new last name: ') \n",
    "                manual_corrects[org_fn] = [new_fname, new_lname]\n",
    "\n",
    "            row['to whom due | first name'] = new_fname.capitalize()\n",
    "            row['to whom due | last name'] = new_lname.capitalize()\n",
    "        \n",
    "        # record change \n",
    "        add_changes(row['to whom due | title'], row['to whom due | title'], org_fn, org_ln, \n",
    "                row['to whom due | first name'], row['to whom due | last name'], 3, row['org_file'], row['org_index'])\n",
    "            \n",
    "        print('+------------------------------+')\n",
    "    # might be a corporation or many names; manually fix\n",
    "    elif ' and ' in org_fn_l and len(org_fn_l.split()) > 7:\n",
    "        print('original name= ' + org_fn_l)\n",
    "         # check if name has already been manually cleaned\n",
    "        if org_fn in manual_corrects:\n",
    "            new_fname = str(manual_corrects[org_fn][0])\n",
    "            new_lname = str(manual_corrects[org_fn][1])\n",
    "        else:\n",
    "            new_fname = input('new first name: ')\n",
    "            new_lname = input('new last name: ') \n",
    "            manual_corrects[org_fn] = [new_fname, new_lname]\n",
    "\n",
    "        row['to whom due | first name'] = new_fname.capitalize()\n",
    "        row['to whom due | last name'] = new_lname.capitalize()\n",
    "        \n",
    "        # record change \n",
    "        add_changes(row['to whom due | title'], row['to whom due | title'], org_fn, org_ln, \n",
    "                row['to whom due | first name'], row['to whom due | last name'], 3, row['org_file'], row['org_index'])\n",
    "\n",
    "        print('new first name col=' + listToString(row['to whom due | first name']))\n",
    "        print('new last name col=' + listToString(row['to whom due | last name']))\n",
    "\n",
    "        print('+------------------------------+')\n",
    "    \n",
    "    # capitalize the names properly \n",
    "    row['to whom due | first name'] = row['to whom due | first name']\n",
    "    row['to whom due | last name'] = row['to whom due | last name']\n",
    "        \n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_two_name(row), axis=1)\n",
    "\n",
    "# save manual corrections \n",
    "manual_corrects_df = pd.DataFrame.from_dict(manual_corrects, orient='index') \n",
    "manual_corrects_df.columns = ['new first name', 'new last name']\n",
    "manual_corrects_df.to_csv('data/manual_corrections.csv')\n",
    "\n",
    "# if there are debt entries with multiple individuals, split them into their own rows\n",
    "agg_debt = agg_debt.explode('to whom due | first name')\n",
    "agg_debt = agg_debt.explode('to whom due | last name')\n",
    "# reindex\n",
    "agg_debt['index'] = agg_debt.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Names that are entirely in the first or last name column\n",
    "\n",
    "def correct_full_names_in_column(row):\n",
    "    if row[\"organization?\"] == True: return row #ignore orgnizations\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    name = None\n",
    "    if (len(lname.split()) == 0 or \"nan\" in lname or \"NaN\" in lname) and len(fname.split()) >= 2:\n",
    "        name = HumanName(fname)\n",
    "    if (len(fname.split()) == 0 or \"nan\" in fname or \"NaN\" in fname) and len(lname.split()) >= 2:\n",
    "        name = HumanName(lname)\n",
    "    if name == None:\n",
    "        return row\n",
    "    else:\n",
    "        #save_manual_correction(row[\"to whom due | title\"], fname, lname, row[\"to whom due | title\"], name.first, name.last, 9, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        add_changes(row[\"to whom due | title\"], row[\"to whom due | title\"], row[\"to whom due | first name\"], fname, row[\"to whom due | last name\"], lname, 9, row[\"org_file\"], row[\"org_index\"])\n",
    "        row[\"to whom due | first name\"] = name.first\n",
    "        row[\"to whom due | last name\"] = name.last\n",
    "        return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: correct_full_names_in_column(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in blank columns\n",
    "\n",
    "def handle_blank_name_cols(row):\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    if fname == \"\": fname = \"UNDEFINED\" # if there is no first name, make it undefined\n",
    "    elif lname == \"\": lname = \"UNDEFINED\" # if there is no last name, make it undefined\n",
    "    else: return row # if both aren't blank, return the row now\n",
    "    #save_manual_correction(row[\"to whom due | title\"], row[\"to whom due | first name\"], row[\"to whom due | last name\"], row[\"to whom due | title\"], fname, lname, 7, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "    add_changes(row[\"to whom due | title\"], row[\"to whom due | title\"], row[\"to whom due | first name\"], fname, row[\"to whom due | last name\"], lname, 7, row[\"org_file\"], row[\"org_index\"])\n",
    "    row[\"to whom due | first name\"] = fname\n",
    "    row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_blank_name_cols(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deceased individuals\n",
    "\n",
    "agg_debt[\"deceased?\"] = False\n",
    "\n",
    "def check_deceased(row):\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    fullname = str(fname) + \" \" + str(lname)\n",
    "    for word in fullname.lower().split():\n",
    "        if \" dead\" or \" decease\" or \" passed\" or \" dec'd\" or \" dec.\" or \" decd\" or \" deceasd\" in word:\n",
    "            row[\"deceased?\"] = True\n",
    "            fname = fname.replace(word, \"\")\n",
    "            lname = lname.replace(word, \"\")\n",
    "            add_changes(row[\"to whom due | title\"], row[\"to whom due | title\"], row[\"to whom due | first name\"], fname, row[\"to whom due | last name\"], lname, 12, row[\"org_file\"], row[\"org_index\"])\n",
    "            #save_manual_correction(row[\"to whom due | title\"], row[\"to whom due | first name\"], row[\"to whom due | last name\"], row[\"to whom due | title\"], fname, lname, 12, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: check_deceased(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abbreviations\n",
    "abbreviations = {\n",
    "    'And':'Andrew', 'Ant':'Anthony', 'Bart':'Bartholomew', 'Cha':'Charles', 'Dor':'Dorothy', 'Dot':'Dorothy', 'Doth':'Dorothy',\n",
    "    'Edw':'Edward', 'Eliz':'Elizabeth', 'Geo':'George', 'H':'Henry', 'Herb':'Herbert', 'Ja':'James', 'Jn':'John', 'Marg':'Margaret', \n",
    "    'Mich':'Michael', 'Pat': 'Patrick', 'Rich':'Richard', 'Tho':'Thomas', 'W':'William', 'Will\\'m':'William'\n",
    "}\n",
    "\n",
    "def handle_abbreviations(row):\n",
    "    fn = str(row['to whom due | first name'])\n",
    "    if fn in abbreviations:\n",
    "        row['to whom due | first name'] = abbreviations[fn]\n",
    "        # record changes\n",
    "        add_changes(row['to whom due | title'], row['to whom due | title'], fn, \n",
    "                    row['to whom due | last name'], row['to whom due | first name'], \n",
    "                    row['to whom due | last name'], 5, row['org_file'], row['org_index'])\n",
    "    \n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_abbreviations(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop that covers Objective 1 (aggregate data files)\n",
    "def element_to_int(ele): # handles all kinds of Nans (returns 0 for nans)\n",
    "    if type(ele) == np.float64:\n",
    "        ele = round(ele)\n",
    "    if ele == np.nan: return 0\n",
    "    if str(ele) == \"nan\": return 0\n",
    "    return round(np.float64(ele))\n",
    "\n",
    "def get_dollar(row): #gets the dollar from a row by checking both dollar columns\n",
    "    dollar = 0\n",
    "    ninety = 0\n",
    "    #if dollar (90th) is a decimal, then split it\n",
    "    if '.' in str(element_to_int(row[11])): # \"amount | dollar\"\n",
    "        split = str(element_to_int(row[11])).split(\".\")\n",
    "        dollar, ninety = element_to_int(split[0]), element_to_int(split[1])\n",
    "    elif str(row[11]) == \"\": # \"amount | dollar\"\n",
    "        if '.' in str(element_to_int(row[24])): # \"amount | specie\"\n",
    "            split = str(element_to_int(row[24])).split() # \"amount | specie\"\n",
    "            dollar, ninety = element_to_int(split[0]), element_to_int(split[1])\n",
    "    else:\n",
    "        dollar = element_to_int(row[11]) # \"amount | dollar\"\n",
    "        ninety = element_to_int(row[12]) # \"amount | 90th\"\n",
    "    return float(str(dollar) + \".\" + str(ninety))\n",
    "\n",
    "def new_tup(old_row, new_dol, new_ninety, new_title): # returns a new tuple, specifically for totaled debt amounts (since you can't assign new values in tuples)\n",
    "    return (old_row[0], old_row[1], old_row[2], old_row[3], old_row[4], old_row[5], old_row[6],\n",
    "            new_title, old_row[8], old_row[9], old_row[10], new_dol, new_ninety, old_row[13],\n",
    "            old_row[14], old_row[15], old_row[16], old_row[17], old_row[18], old_row[19],\n",
    "            old_row[20], old_row[21], old_row[22], old_row[23], old_row[24], old_row[25],\n",
    "            old_row[26], old_row[27], old_row[28], old_row[29], old_row[30], old_row[31])\n",
    "\n",
    "agg_df = pd.DataFrame(columns=agg_debt.columns)\n",
    "last_f, last_l, last_t = \"\", \"\", \"\"\n",
    "last_row = None\n",
    "#save the sum of money\n",
    "current_sum = 0\n",
    "for row in agg_debt.itertuples(name=None, index=False): #main processing function\n",
    "    fname, lname = str(row[5]).strip(), str(row[6]).strip()\n",
    "    last_t = last_t if str(row[7]).strip().lower() == \"nan\" else str(row[7]).strip()\n",
    "    if fname == last_f and lname == last_l: #If the next name is the same as the last one, add onto the amount\n",
    "        dol = get_dollar(row)\n",
    "        print(f\"adding {dol} to {fname} {lname}'s total\")\n",
    "        current_sum += dol\n",
    "    else: #If the next name is not the same as the last one:\n",
    "        if current_sum > 0: #If the sum is more than 0 (ie. this is the end of consecutive same-name entries), then only add this on\n",
    "            print(f\"{last_row[5]} {last_row[6]} is consecutively owed {current_sum}\")\n",
    "            #consecutive has ended\n",
    "            split = str(current_sum).split(\".\")\n",
    "            agg_df.loc[len(agg_df.index)] = new_tup(last_row, int(split[0]), int(split[1]), last_t if last_t != \"\" else \"\")\n",
    "            current_sum = 0\n",
    "        else: #If the sum is not more than 0 (ie. this is one unique entry, add it on now)\n",
    "            #Normal\n",
    "            agg_df.loc[len(agg_df.index)] = last_row\n",
    "    last_f, last_l = fname, lname\n",
    "    last_row = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ancestry\n",
    "\n",
    "# import necessary fuzzy string libraries \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.expected_conditions import element_to_be_clickable, presence_of_element_located\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from phonetics import metaphone\n",
    "from rapidfuzz import fuzz\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from itertools import zip_longest\n",
    "import time \n",
    "import getpass\n",
    "\n",
    "# options\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument(\"--window-size=1000,1000\")\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "options.add_argument('--no-sandbox')  \n",
    "\n",
    "# install driver - uncomment when necessary\n",
    "'''\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager(version='114.0.5735.16').install()), options=options)\n",
    "wait = WebDriverWait(driver, 30)\n",
    "'''\n",
    "\n",
    "# voter records and censuses available for every state \n",
    "records = {\n",
    "    'nh':['https://www.ancestrylibrary.com/search/collections/5058/'],\n",
    "    'nj':['https://www.ancestrylibrary.com/search/collections/2234/', \n",
    "          'https://www.ancestrylibrary.com/search/collections/3562/'],\n",
    "    'ny':['https://www.ancestrylibrary.com/search/collections/5058/'],\n",
    "    'ma':['https://www.ancestrylibrary.com/search/collections/5058/'], \n",
    "    'ct':['https://www.ancestrylibrary.com/search/collections/5058/'], \n",
    "    'va':['https://www.ancestrylibrary.com/search/collections/2234/', \n",
    "         'https://www.ancestrylibrary.com/search/collections/3578/'], \n",
    "    'pa':['https://www.ancestrylibrary.com/search/collections/2702/',\n",
    "         'https://www.ancestrylibrary.com/search/collections/2234/',\n",
    "         'https://www.ancestrylibrary.com/search/collections/3570/'],\n",
    "    'md':['https://www.ancestrylibrary.com/search/collections/3552/'],\n",
    "    'nc':['https://www.ancestrylibrary.com/search/collections/3005/', \n",
    "         'https://www.ancestrylibrary.com/search/collections/2234/'],\n",
    "    'ga':['https://www.ancestrylibrary.com/search/collections/2234/'],\n",
    "    'ri':['https://www.ancestrylibrary.com/search/collections/3571/']\n",
    "}\n",
    "\n",
    "# ancestry has unique urls for each state\n",
    "residence_urls = {\n",
    "    'nh':'_new+hampshire-usa_32',\n",
    "    'nj':'_new+jersey-usa_33', \n",
    "    'ny':'_new+york-usa_35',\n",
    "    'ma':'_massachusetts-usa_24',\n",
    "    'ct':'_connecticut-usa_9',\n",
    "    'va':'_virginia-usa_49', \n",
    "    'pa':'_pennsylvania-usa_41',\n",
    "    'md':'_maryland-usa_23',\n",
    "    'nc':'_north+carolina-usa_36',\n",
    "    'ga':'_georgia-usa_13',\n",
    "    'ri':'_rhode+island-usa_42'\n",
    "}\n",
    "\n",
    "fixes = {} #record name necessary name changes here\n",
    "checked1 = [] #multiple debt entries for the same person: don't search these names again when comparing\n",
    "checked0 = [] #multiple debt entries for the same person: don't search these names again\n",
    "rerun_rows = [] #ancestry crashed trying to find these names\n",
    "\n",
    "# remove 'cs' (congress) and 'f' (foreign officers); these are not state, but specific regiments / types of officers\n",
    "agg_debt_copy = agg_debt[(agg_debt['state'] != 'cs') & (agg_debt['state'] != 'f') & (agg_debt['state'] != 'de')]\n",
    "\n",
    "# split dataframe based on state; makes searching faster\n",
    "agg_debt_sp = agg_debt_copy.groupby('state')\n",
    "agg_debts_st = [agg_debt_sp.get_group(x) for x in agg_debt_sp.groups]\n",
    "\n",
    "\n",
    "for x in agg_debt_sp.groups:\n",
    "    print(x)\n",
    "    \n",
    "# add state to 'fixes' list \n",
    "for st in agg_debt_sp.groups:\n",
    "    fixes[st] = {}\n",
    "    \n",
    "netid_xpath = '/html/body/div[1]/div[2]/section/div[1]/div/form/fieldset/div[1]/input'\n",
    "password_xpath = '/html/body/div[1]/div[2]/section/div[1]/div/form/fieldset/div[2]/input'\n",
    "login_btn0_xpath = '/html/body/main/div/div/div/a'\n",
    "login_btn1_xpath = '/html/body/div[1]/div[2]/section/div[1]/div/form/fieldset/div[3]/button'\n",
    "\n",
    "# ask for password and username \n",
    "username = input('username: ')\n",
    "password = getpass.getpass(prompt='password: ')\n",
    "driver_objs = {}\n",
    "# create a new driver object for each state\n",
    "for st in agg_debt_sp.groups:\n",
    "    driver_objs[st] = [webdriver.Chrome(service=Service(ChromeDriverManager(version='114.0.5735.16').install()), options=options)]\n",
    "# create a new wait object for each state\n",
    "for st in agg_debt_sp.groups:\n",
    "    webdriver_obj = driver_objs[st][0]\n",
    "    driver_objs[st].append(WebDriverWait(webdriver_obj, 30))\n",
    "# for each driver obj: access emory's ancestry's subscription \n",
    "for st in agg_debt_sp.groups:\n",
    "    webdriver_obj = driver_objs[st][0]\n",
    "    wait_obj = driver_objs[st][1]\n",
    "    \n",
    "    # go to emory's library \n",
    "    webdriver_obj.get('https://guides.libraries.emory.edu/ALE')\n",
    "    wait_obj.until(element_to_be_clickable((By.XPATH, login_btn0_xpath))).click()\n",
    "    \n",
    "    # input login information and click 'login'\n",
    "    netid_input = wait_obj.until(element_to_be_clickable((By.XPATH, netid_xpath)))\n",
    "    netid_input.click()\n",
    "    netid_input.send_keys(username)\n",
    "    pass_input = wait_obj.until(element_to_be_clickable((By.XPATH, password_xpath)))\n",
    "    pass_input.click()\n",
    "    pass_input.send_keys(password) \n",
    "    wait_obj.until(element_to_be_clickable((By.XPATH, login_btn1_xpath))).click()\n",
    "    \n",
    "    webdriver_obj.get('https://www.ancestrylibrary.com/search/collections/5058/')\n",
    "    \n",
    "    print(webdriver_obj.current_url)\n",
    "\n",
    "def ancestry_cleaning(agg_debt_st, state):\n",
    "    # retrieve selenium chromedrivers associated with that state\n",
    "    st_driver = driver_objs[state][0]\n",
    "    wait_driver = driver_objs[state][1]\n",
    "    # run ancestry search on agg debt file\n",
    "    # agg_debt_st.swifter.apply(lambda row0: compare_strings(agg_debt_st, row0['to whom due | first name'], row0['to whom due | last name'], state, row0), axis=1) # using apply\n",
    "    agg_debt_clean = compare_strings_vect(agg_debt_st['to whom due | first name'].astype(str), agg_debt_st['to whom due | last name'].astype(str), state, st_driver, wait_driver) # using vectorization\n",
    "    return agg_debt_st\n",
    "\n",
    "# loop through the state agg_debt one more time; compare row0 (original row) with all the other rows (row1)\n",
    "def compare_strings(fn0, ln0, state, st_driver, wait_driver):\n",
    "    # make sure we haven't checked this name before (handles people who share the same fn & ln & live in same state) \n",
    "    # name0 = row0['to whom due | first name'] + ' ' + row0['to whom due | last name'] # uncomment when using apply\n",
    "    agg_debt_st = agg_debt_sp.get_group(state)\n",
    "    \n",
    "    if (fn0, ln0, state) not in checked0:\n",
    "        # compare both strings \n",
    "        # agg_debt_st.swifter.apply(lambda row1: fuzzy_comparison(fn0, ln0, row1['to whom due | first name'], row1['to whom due | last name'], state, row0, row1), axis=1) # using apply\n",
    "        fuzzy_comparison_vect(fn0, ln0, agg_debt_st['to whom due | first name'].astype(str), agg_debt_st['to whom due | last name'].astype(str), state, st_driver, wait_driver) # using vectorization\n",
    "        checked0.append((fn0, ln0, state))\n",
    "\n",
    "# compare two strings using fuzzy string matching \n",
    "def fuzzy_comparison(fn0, ln0, fn1, ln1, state, st_driver, wait_driver):\n",
    "    if (fn1, ln1, state) not in checked1:\n",
    "        \n",
    "        name0 = fn0 + ' ' + ln0\n",
    "        name1 = fn1 + ' ' + ln1\n",
    "\n",
    "        # use phonetic similarity (compares similar sounding names)\n",
    "        meta0 = metaphone(name0.lower()) \n",
    "        meta1 = metaphone(name1.lower())\n",
    "        phonetic_score = fuzz.ratio(meta0, meta1)\n",
    "\n",
    "        # use fuzzy string similarity (compares similar spellings between names)\n",
    "        fuzz_score = fuzz.ratio(name0, name1) \n",
    "\n",
    "        # check if phonetic score and fuzzy string score both meet threshold, both names are not the same  \n",
    "        if phonetic_score > 90 and fuzz_score > 90 and name0 != name1:\n",
    "            search_ancestry(fn0, ln0, fn1, ln1, name0, name1, state, st_driver, wait_driver) \n",
    "            checked1.append((fn1, ln1, state)) # record that we have checked this name\n",
    "\n",
    "# look up both names in ancestry's database\n",
    "def search_ancestry(fn0, ln0, fn1, ln1, name0, name1, state, driver, wait):\n",
    "    # loop through state urls \n",
    "    for url in records[state]:        \n",
    "        try:\n",
    "            # search person-0\n",
    "            url0 = url + '?name=' + fn0 + '_' + ln0 + '&name_x=ps&residence=1780' + residence_urls[state] + '&residence_x=10-0-0_1-0'\n",
    "            driver.get(url0) \n",
    "                        \n",
    "            # results were found for person0\n",
    "            try:\n",
    "                # use xpath to find result text\n",
    "                # result0 = wait.until(presence_of_element_located((By.XPATH, '/html/body/div[3]/div/div/div/section[1]/div[1]/table/tbody/tr[2]/td[2]/span'))).text\n",
    "                # use class_name to find result text\n",
    "                result0 = wait.until(presence_of_element_located((By.CLASS_NAME, 'srchHit'))).text\n",
    "            # no results were found; keep entries separate  \n",
    "            except:\n",
    "                result0 = ''\n",
    "            \n",
    "            # search person-1\n",
    "            url1 = url + '?name=' + fn1 + '_' + ln1 + '&name_x=ps&residence=1780' + residence_urls[state] + '&residence_x=10-0-0_1-0'\n",
    "            driver.get(url1)\n",
    "                        \n",
    "            # results were found for person1\n",
    "            try: \n",
    "                # use xpath to find result text\n",
    "                # result1 = wait.until(presence_of_element_located((By.XPATH, '/html/body/div[3]/div/div/div/section[1]/div[1]/table/tbody/tr[2]/td[2]/span'))).text\n",
    "                # use class_name to find result text\n",
    "                result1 = wait.until(presence_of_element_located((By.CLASS_NAME, 'srchHit'))).text\n",
    "            # no results were found; keep entries separate\n",
    "            except:\n",
    "                result1 = ''\n",
    "                \n",
    "            '''\n",
    "            compare results:\n",
    "            if both results are empty, do not add to fixes dict \n",
    "            if both results are different, do not add to fixes dict\n",
    "            if both results are the same, add to fixes dict\n",
    "                find correct name\n",
    "                if name0 = result0 and result1 : {name1 : name0}\n",
    "                if name1 = result1 and result0 : {name0 : name0} \n",
    "            '''\n",
    "            \n",
    "            if result0 == result1 and result0 != '' and result1 != '':\n",
    "                if name0 == result0 and name0 == result1: # name0 must be the correct version of the name \n",
    "                    fixes[state][(fn1, ln1, name1)] = (fn0, ln0, name0) # convert name1 to name0  \n",
    "                    # record change\n",
    "                    '''\n",
    "                    add_changes(row1['to whom due | title'], row1['to whom due | title'], fn1, ln1, \n",
    "                       fn0, ln0, 6, row1['org_file'], row1['org_index'])\n",
    "                    '''\n",
    "\n",
    "                elif name1 == result0 and name1 == result1: # name1 must be the correct version of the name \n",
    "                    fixes[state][(fn0, ln0, name0)] = (fn1, ln1, name1) # convert name0 to name1\n",
    "                    # record change\n",
    "                    '''\n",
    "                    add_changes(row0['to whom due | title'], row0['to whom due | title'], fn0, ln0, \n",
    "                       fn1, ln1, 6, row0['org_file'], row0['org_index'])\n",
    "                    '''\n",
    "            \n",
    "            print('---------------------------+')\n",
    "            print('Summary')\n",
    "            print('driver=')\n",
    "            print(driver)\n",
    "            print('name0=' + str(name0))\n",
    "            print('name1=' + str(name1))\n",
    "            print('fn0=' + str(fn0))\n",
    "            print('ln0=' + str(ln0))\n",
    "            print('fn1=' + str(fn1))\n",
    "            print('ln1=' + str(ln1))\n",
    "            print('url-0=' + str(url0))\n",
    "            print('url-1=' + str(url1))\n",
    "            print('result0=' + str(result0))\n",
    "            print('result1=' + str(result1))\n",
    "            print('state=' + str(state))\n",
    "            print('fixes length=' + str(len(fixes[state])))\n",
    "            print('rerun rows length=' + str(len(rerun_rows)))\n",
    "            print('---------------------------+')\n",
    "        \n",
    "        # there was error trying to access ancestry's records\n",
    "        except Exception as e:\n",
    "            print('---------------------------+')\n",
    "            print('Error')\n",
    "            print(e)\n",
    "            print('name0=' + str(name0))\n",
    "            print('name1=' + str(name1))\n",
    "            print('---------------------------+')\n",
    "            rerun_rows.append([fn0, ln0, fn1, ln1, name0, name1, state]) \n",
    "\n",
    "# record how long it takes to run ancestry search; useful information to see effectiveness of different methods \n",
    "start = time.time()\n",
    "\n",
    "# vectorize our functions \n",
    "compare_strings_vect = np.vectorize(compare_strings)\n",
    "fuzzy_comparison_vect = np.vectorize(fuzzy_comparison)\n",
    "\n",
    "# initialize a parallelization job; the idea is to have one core work on one state's agg debt file\n",
    "\n",
    "ancestry_calls = [delayed(ancestry_cleaning)(agg_debt_sp.get_group(st), st) for st in agg_debt_sp.groups]\n",
    "results = Parallel(n_jobs=-1, backend=\"threading\")(ancestry_calls) \n",
    "\n",
    "# split nj's agg_debt file to test parallelization\n",
    "# agg_debt_nj = agg_debt_sp.get_group('nj')\n",
    "# agg_debt_nj_sp = np.split(agg_debt_nj, 7)\n",
    "\n",
    "# initialize parallelization (nj)\n",
    "# ancestry_calls = [delayed(ancestry_cleaning)(df, st) for df in agg_debt_nj_sp.groups]\n",
    "# results = Parallel(n_jobs=-1, backend=\"threading\")(ancestry_calls) \n",
    "\n",
    "# try without parallization - try out on [nj] only\n",
    "# agg_debt_nj = ancestry_cleaning(agg_debt_sp.get_group('nj'), 'nj')\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01843e40f215bf95274bc2c8c3e35c535d55c23ad112577253f312d1e860a459"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
