{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239af09c",
   "metadata": {},
   "source": [
    "# Cleaning Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41e041",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to clean the names of individuals. All the problems that we aim to fix in this notebook are listed [here](https://docs.google.com/document/d/1pcSQfWNll6K9tl-_rB4lztN0TsZsclU9vOnbyQob-Zs/edit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140ce0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "from nameparser import HumanName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d7c755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_9876\\4157892421.py:2: DtypeWarning: Columns (1,7,9,10,12,14,15,19,20,21,23,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  agg_debt = pd.read_csv('data/final_agg_debt.csv')\n"
     ]
    }
   ],
   "source": [
    "# import aggregated debt file\n",
    "agg_debt = pd.read_csv('data/final_agg_debt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "677548c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_rows_wrap(row0):\n",
    "    agg_debt.apply(lambda row1: find_duplicate_rows(row0, row1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6b50924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_rows(row0, row1):\n",
    "    if (row0['org_index'] == row1['org_index']) and (row0['org_file'] == row1['org_file']) and row0 != row1:\n",
    "        print(row0['org_index'])\n",
    "        print(row0['org_file'])\n",
    "        print(row0['to whom due | first name'])\n",
    "        print(row0['to whom due | last name'])\n",
    "        print('+-------------------------------+')\n",
    "        print(row1['org_index'])\n",
    "        print(row1['org_file'])\n",
    "        print(row1['to whom due | first name'])\n",
    "        print(row1['to whom due | last name'])\n",
    "        print('+-------------------------------+')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd7aa876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magg_debt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow0\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mduplicate_rows_wrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agg_debt\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row0: \u001b[43mduplicate_rows_wrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow0\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36mduplicate_rows_wrap\u001b[1;34m(row0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mduplicate_rows_wrap\u001b[39m(row0):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43magg_debt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow1\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfind_duplicate_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36mduplicate_rows_wrap.<locals>.<lambda>\u001b[1;34m(row1)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mduplicate_rows_wrap\u001b[39m(row0):\n\u001b[1;32m----> 2\u001b[0m     agg_debt\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row1: \u001b[43mfind_duplicate_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow1\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m, in \u001b[0;36mfind_duplicate_rows\u001b[1;34m(row0, row1)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_duplicate_rows\u001b[39m(row0, row1):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (row0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg_index\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m (row0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg_file\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg_file\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mrow0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow1\u001b[49m:\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(row0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg_index\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(row0[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morg_file\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:1466\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m-> 1466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1467\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1468\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1469\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "agg_debt.apply(lambda row0: duplicate_rows_wrap(row0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4791b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agg_debt.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5ce85",
   "metadata": {},
   "source": [
    "## Documenting Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94686cfe",
   "metadata": {},
   "source": [
    "<b>Goal: </b> We need to document changes we make to ```agg_debt.csv``` in a separate dataframe: ```name_changes```. This way, we can double-check whether those changes were appropriate. \n",
    "\n",
    "<b>Steps</b>\n",
    "1. Create an empty dataframe. Here are the column names:\n",
    "    - ```title_org```: The original title of the individual (Mr., Ms., etc.)\n",
    "    - ```title_new```: The new title of the individual (Mr., Ms., etc.) \n",
    "    - ```first_name_org```: The original first name of the individual from the unchanged ```agg_debt.csv```\n",
    "    - ```last_name_org```: The original last name of the individual from the unchanged ```agg_debt.csv``` \n",
    "    - ```first_name_new``` : If first name changed, record it here. Otherwise, this entry will still be the old name. \n",
    "    - ```last_name_new```: If last name changed, record it here. Otherwise, this entry will still be the old name. \n",
    "    - ```cleaning case```: This corresponds with the task number in the objectives document linked above. \n",
    "    - ```file_loc```: The individual state filename in which the row came from \n",
    "    - ```org_index```: The original index/row that the debt entry can be found in ```file_loc``` \n",
    "2. Create a function that adds a new row to the dataframe. This function will be called while we are cleaning. \n",
    "\n",
    "**Cleaning case = Objective number** \n",
    "- Clean company names = 2,\n",
    "- Handle two names = 3,\n",
    "- Handle abbreviations = 5,\n",
    "- Standardize names (Ancestry) = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record changes in this dataframe\n",
    "name_changes = pd.DataFrame({'title_org': pd.Series(dtype='str'),\n",
    "                       'title_new': pd.Series(dtype='str'),\n",
    "                       'first_name_org': pd.Series(dtype='str'),\n",
    "                       'last_name_org': pd.Series(dtype='str'),\n",
    "                       'first_name_new': pd.Series(dtype='str'),\n",
    "                       'last_name_new': pd.Series(dtype='str'),\n",
    "                       'cleaning case': pd.Series(dtype='int'),\n",
    "                       'file_loc': pd.Series(dtype='str'),\n",
    "                       'org_index': pd.Series(dtype='int')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112012b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_changes(title_org, title_new, fn_org, ln_org, fn_new, ln_new, case, file, index):\n",
    "    name_changes.loc[len(name_changes.index)] = [title_org, title_new, fn_org, ln_org, fn_new, ln_new, case, file, index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c110b87",
   "metadata": {},
   "source": [
    "## Company Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a77aa",
   "metadata": {},
   "source": [
    "There are multiple kinds of companies. \n",
    "\n",
    "<b>Goal: </b> Some debt entries are actually company names or represent a group of people (example: ```James Vernon & Co.```). \n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Use string parsing to find if a debt entry has '& co' or '& others' in it's name. Note: I noticed these company names appear in the first name column. I do <b>not</b> run this program on the last name column.\n",
    "2. I remove the '& co' or '& others' from the name. I use a human name parser library. This library can find out what parts of the name are the first name versus last name. \n",
    "3. I put the first name and last name in their own respective columns. \n",
    "4. Record name change in ``name_changes``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ee241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of manual changes i have to make \n",
    "changes = {\n",
    "    'Henry Mc Clellen & Henry & co' : 'Henry Mc Clellen & Co'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5800aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_comp_name(row):    \n",
    "    org_fname = row['to whom due | first name']\n",
    "    org_lname = row['to whom due | last name']\n",
    "    fname = row['to whom due | first name']\n",
    "    \n",
    "    if fname in changes:\n",
    "        fname = changes[fname]\n",
    "    \n",
    "    fname_c = str(fname).lower()\n",
    "    if ('& co' in fname_c) or ('& others' in fname_c) or ('& several others' in fname_c):        \n",
    "        fname_c = fname_c.replace('& co', '').replace('& others', '')\n",
    "        name = HumanName(fname_c)\n",
    "        row['to whom due | first name'] = name.first\n",
    "        row['to whom due | last name'] = name.last\n",
    "        \n",
    "        # record change\n",
    "        add_changes(row['to whom due | title'], row['to whom due | title'], org_fname, org_lname, \n",
    "                   row['to whom due | first name'], row['to whom due | last name'], 2, row['org_file'], row['org_index'])\n",
    "                \n",
    "        return row\n",
    "    \n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_comp_name(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38847c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checkup on name_changes\n",
    "name_changes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66551839",
   "metadata": {},
   "source": [
    "## Cleaning Entries with Two Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df92c8",
   "metadata": {},
   "source": [
    "<b>Goal: </b>There are debt entries that have two names in a single cell: ```NY_2422: Messes Williamson & Beckman```. The plan is to split the name across the first name and last name columns. Note: I have to check naming conventions during thre 1700s. \n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Use string parsing to check if the name contains '&' or 'and' and split the string accordingly. \n",
    "2. Use the human name parser library to determine the first name and last names. \n",
    "3. Put each person's first name and last name in the respective columns, split by ```|``` to separate both individuals' names. \n",
    "4. Record change in ```name_changes```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9945d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = {\n",
    "    'van zandt & kittletas' : ['', 'van zandt | kittletas'],\n",
    "    'trustees of & davids church':['trustees of & davids church', '']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd4040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def handle_two_name(row):\n",
    "    org_fn = row['to whom due | first name']\n",
    "    org_ln = row['to whom due | last name']\n",
    "    name = str(row['to whom due | first name']).lower()\n",
    "    if (' & ' in name) or (' and ' in name):\n",
    "        person1 = re.split('&|and', name)[0].strip()\n",
    "        person2 = re.split('&|and', name)[1].strip()\n",
    "        human_name_1 = HumanName(person1)\n",
    "        human_name_2 = HumanName(person2)\n",
    "        \n",
    "        if name not in changes:\n",
    "            if human_name_1.first != '' and human_name_2.first != '':\n",
    "                row['to whom due | first name'] = human_name_1.first + \" | \" + human_name_2.first\n",
    "            else: \n",
    "                row['to whom due | first name'] = human_name_1.first + human_name_2.first\n",
    "\n",
    "            if human_name_1.last != '' and human_name_2.last != '':\n",
    "                row['to whom due | last name'] = human_name_1.last + \" | \" + human_name_2.last\n",
    "            else:\n",
    "                row['to whom due | last name'] = human_name_1.last + human_name_2.last\n",
    "        else:\n",
    "            row['to whom due | first name'] = changes[name][0]\n",
    "            row['to whom due | last name'] = changes[name][1]\n",
    "                \n",
    "        # record change\n",
    "        add_changes(row['to whom due | title'], row['to whom due | title'], org_fn, org_ln, \n",
    "                   row['to whom due | first name'], row['to whom due | last name'], 3, row['org_file'], row['org_index'])\n",
    "        \n",
    "    return row\n",
    "\n",
    "agg_debt.apply(lambda row: handle_two_name(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa674ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkup on name_changes\n",
    "name_changes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552b9ae",
   "metadata": {},
   "source": [
    "## Handle Abbreviations of a Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa3adf",
   "metadata": {},
   "source": [
    "<b>Goal: </b>There are individuals who have a handwritten abbreviation of a name in their debt entry. Thanks to Chris, he found a website with all these [abbreviations](https://hull-awe.org.uk/index.php/Conventional_abbreviations_for_forenames). \n",
    "\n",
    "<b>Step: </b>\n",
    "1. Copy and past the name abbreviations from the website into a dictionary. \n",
    "2. Iterate through each row in the dataframe.\n",
    "3. Check if the name is an abbreviation and change accordingly. \n",
    "4. Record changes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07208b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    'And':'Andrew', 'Ant':'Anthony', 'Bart':'Bartholomew', 'Cha':'Charles', 'Dor':'Dorothy', 'Dot':'Dorothy', 'Doth':'Dorothy',\n",
    "    'Edw':'Edward', 'Eliz':'Elizabeth', 'Geo':'George', 'H':'Henry', 'Herb':'Herbert', 'Ja':'James', 'Jn':'John', 'Marg':'Margaret', \n",
    "    'Mich':'Michael', 'Pat': 'Patrick', 'Rich':'Richard', 'Tho':'Thomas', 'W':'William'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_abbreviations(row):\n",
    "    fn = str(row['to whom due | first name'])\n",
    "    if fn in abbreviations:\n",
    "        row['to whom due | first name'] = abbreviations[fn]\n",
    "        # record changes\n",
    "        add_changes(row['to whom due | title'], row['to whom due | title'], fn, \n",
    "                    row['to whom due | last name'], row['to whom due | first name'], \n",
    "                    row['to whom due | last name'], 5, row['org_file'], row['org_index'])\n",
    "    \n",
    "    return row\n",
    "\n",
    "agg_debt.apply(lambda row: handle_abbreviations(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fe74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkup on name_changes\n",
    "name_changes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cf75b",
   "metadata": {},
   "source": [
    "## Standardizing Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d95d6",
   "metadata": {},
   "source": [
    "<b>Goal: </b>Multiple different spellings of a name can be referring to the same identity. We will use a phonetics library and Ancestry to fix this. \n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Login to Emory's Ancestry subscription \n",
    "2. Iterate through ```agg_debt```, through each debt entry. \n",
    "3. Use a combination of phonetics fuzzy string matching and normal fuzzy string matching to determine if two names from a state are similar.  \n",
    "4. Search each name in Ancestry: Edit URL (state and person's name). \n",
    "5. Check if there are any results for both person's name:\n",
    "    - Yes: Check if one spelling of the name appears for both individuals (that's most likely the correct spelling of that name) \n",
    "    - No: Leave entries as two separate entries. \n",
    "6. Record name change in ```fixes``` list (save ```fixes``` as ```out.csv``` too). \n",
    "7. Run ```agg_debt``` through ```fixes```, making changes as necessary. \n",
    "8. Save ```agg_debt``` as a new .csv file.\n",
    "\n",
    "<b style=\"color: red;\">Note: Runtime is long. This is due to the fact there are over 200,000 debt entries and accessing Ancestry takes time too. </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary fuzzy string libraries \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.expected_conditions import element_to_be_clickable, presence_of_element_located\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from phonetics import metaphone\n",
    "from fuzzywuzzy import fuzz\n",
    "import getpass\n",
    "import csv\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec36019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument(\"--window-size=1000,1000\")\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "options.add_argument('--no-sandbox')   \n",
    "options.add_argument(r'--user-data-dir=C:/Users/david/AppData/Local/Google/Chrome/User Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bfa1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "wait = WebDriverWait(driver, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to emory ancestry \n",
    "driver.get('https://guides.libraries.emory.edu/ALE')\n",
    "login_btn_xpath = '/html/body/main/div/div/div/a'\n",
    "wait.until(element_to_be_clickable((By.XPATH, login_btn_xpath))).click()\n",
    "\n",
    "# input login information and click 'login'\n",
    "netid_xpath = '/html/body/div[1]/div[2]/section/div[1]/div/form/fieldset/div[1]/input'\n",
    "password_xpath = '/html/body/div[1]/div[2]/section/div[1]/div/form/fieldset/div[2]/input'\n",
    "username = input('username: ')\n",
    "password = getpass.getpass(prompt='password: ')\n",
    "netid_input = wait.until(element_to_be_clickable((By.XPATH, netid_xpath)))\n",
    "netid_input.click()\n",
    "netid_input.send_keys(username)\n",
    "pass_input = wait.until(element_to_be_clickable((By.XPATH, password_xpath)))\n",
    "pass_input.click()\n",
    "pass_input.send_keys(password)\n",
    "\n",
    "login_btn_xpath = '/html/body/div[1]/div[2]/section/div[1]/div/form/fieldset/div[3]/button'\n",
    "wait.until(element_to_be_clickable((By.XPATH, login_btn_xpath))).click()\n",
    "\n",
    "driver.get('https://www.ancestrylibrary.com/search/collections/5058/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3116d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Find out what states are in the agg_debt dataframe - Helps with finding Ancestry urls \n",
    "Note:\n",
    "- CS most likely stands for congress: Hazen's regiment \n",
    "- F probably stands for 'foreign' officers: most likely France\n",
    "'''\n",
    "agg_debt.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ancestry has unique urls for each state\n",
    "ancestry_state_urls = {\n",
    "    'nh':'_new+hampshire-usa_32',\n",
    "    'ny':'_new+york-usa_35',\n",
    "    'ma':'_massachusetts-usa_24',\n",
    "    'ct':'_connecticut-usa_9',\n",
    "    'pa':'_pennsylvania-usa_41',\n",
    "    'md':'_maryland-usa_23',\n",
    "    'nc':'_north+carolina-usa_36',\n",
    "    'ri':'_rhode+island-usa_42'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5daefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixes = [] #record name necessary name changes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_checked = [] #multiple debt entries for the same person: don't search these names again when comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked0 = [] #multiple debt entries for the same person: don't search these names again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_rows = [] #ancestry crashed trying to find these names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5b8fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def access_ancestry(fn0, ln0, c_fn, c_ln, state, row0, c_row):\n",
    "    name0 = fn0 + ' ' + ln0 # static\n",
    "    c_name = c_fn + ' ' + c_ln # changing\n",
    "    \n",
    "    driver.get('https://www.ancestrylibrary.com/search/collections/5058/?name=' + fn0 + '_' + ln0 + '&residence=' + ancestry_state_urls[state] + '&residence_x=_1-0')\n",
    "    print(driver.current_url)\n",
    "    \n",
    "    try:\n",
    "        try:\n",
    "            check_exists = driver.find_element(By.XPATH, '/html/body/div[3]/div/div/div/section[1]/div[1]/div/div')\n",
    "            result1 = name0\n",
    "            result2 = c_name\n",
    "        except NoSuchElementException:  \n",
    "            result = wait.until(presence_of_element_located((By.XPATH, '/html/body/div[3]/div/div/div/section[1]/div[1]/table/tbody/tr[2]/td[2]/span'))).text\n",
    "            result_name = HumanName(result)\n",
    "\n",
    "            if result_name.middle != '':\n",
    "                result1 = result_name.first + ' ' + result_name.middle + ' ' + result_name.last\n",
    "            else:\n",
    "                result1 = result_name.first + ' ' + result_name.last\n",
    "        \n",
    "        print('index: ' + str(row0['index1']))\n",
    "        print('first ancestry result: ' + result1)\n",
    "\n",
    "        driver.get('https://www.ancestrylibrary.com/search/collections/5058/?name=' + c_fn + '_' + c_ln + '&residence=' + ancestry_state_urls[state] + '&residence_x=_1-0')\n",
    "        print(driver.current_url)\n",
    "\n",
    "        try:\n",
    "            check_exists = driver.find_element(By.XPATH, '/html/body/div[3]/div/div/div/section[1]/div[1]/div/div')\n",
    "            result1 = name0\n",
    "            result2 = c_name\n",
    "        except NoSuchElementException:\n",
    "            result = wait.until(presence_of_element_located((By.XPATH, '/html/body/div[3]/div/div/div/section[1]/div[1]/table/tbody/tr[2]/td[2]/span'))).text\n",
    "            result_name = HumanName(result)\n",
    "\n",
    "            if result_name.middle != '':\n",
    "                result2 = result_name.first + ' ' + result_name.middle + ' ' + result_name.last\n",
    "            else:\n",
    "                result2 = result_name.first + ' ' + result_name.last\n",
    "\n",
    "        print('second ancestry result: ' + result2) \n",
    "\n",
    "        if result1 == name0 and result2 == name0: # name0 is the correct spelling of the name\n",
    "            fixes.append([state, {c_name:name0}])\n",
    "            \n",
    "            # record changes\n",
    "            add_changes(c_row['to whom due | title'], c_row['to whom due | title'], c_row['to whom due | first name'],\n",
    "                        c_row['to whom due | last name'], fn0, ln0, 6, c_row['org_file'], c_row['org_index'])\n",
    "        elif result1 == c_name and result2 == c_name: # c_name is the correct spelling of the name\n",
    "            fixes.append([state, {name0:c_name}])\n",
    "            \n",
    "            # record changes\n",
    "            add_changes(row0['to whom due | title'], row0['to whom due | title'], row0['to whom due | first name'],\n",
    "                        row0['to whom due | last name'], c_fn, c_ln, 6, row0['org_file'], row0['org_index'])\n",
    "    except:\n",
    "        rerun_rows.append([row0, c_row])\n",
    "\n",
    "def only_f(row0, row):\n",
    "    try:\n",
    "        if row['to whom due | first name'][0] == row0['to whom due | first name'][0] and row['to whom due | last name'][0] == row0['to whom due | last name'][0] and row['state'] == row0['state']:\n",
    "            return row\n",
    "    except:\n",
    "        return \n",
    "\n",
    "def fuzzy_similarity(c_row, row0):\n",
    "    name = row0['to whom due | first name'] + ' ' + row0['to whom due | last name']\n",
    "    cname = c_row['to whom due | first name'] + ' ' + c_row['to whom due | last name']\n",
    "    \n",
    "    # check fuzzy string ratio and metaphone ratio\n",
    "    code1 = metaphone(name)\n",
    "    code2 = metaphone(cname)\n",
    "    ratio = fuzz.ratio(name, cname)\n",
    "    score = fuzz.ratio(code1, code2)\n",
    "\n",
    "    # only search ancestry when the two names have a ratio greater than 90, the names don't equal each other, \n",
    "    # and we haven't checled current name already\n",
    "    if score > 90 and ratio > 90 and name != cname and (cname not in c_checked):\n",
    "        print('name: ' + name)\n",
    "        print('comparing to name: ' + cname)\n",
    "        \n",
    "        correct_name = access_ancestry(row0['to whom due | first name'], row0['to whom due | last name'],\n",
    "                                       c_row['to whom due | first name'], c_row['to whom due | last name'], row0['state'], row0, c_row)\n",
    "            \n",
    "        print('--------------------------------------------------')\n",
    "        c_checked.append(cname)\n",
    "    \n",
    "def determine_similarities(row0):\n",
    "    current_name = row0['to whom due | first name'] + ' ' + row0['to whom due | last name']\n",
    "    \n",
    "    # only search ancestry when ancestry has records and if we have not checked name already\n",
    "    if (row0['state'] in ancestry_state_urls) and ([row0['state'], current_name] not in checked0):\n",
    "        \n",
    "        # shorten table to only include names that share first letter of first name and last name and come from the same state\n",
    "        short_table = agg_debt.apply(lambda row: only_f(row0, row), axis=1).dropna()\n",
    "\n",
    "        if len(short_table) > 0:\n",
    "            c_checked.clear()\n",
    "            short_table.apply(lambda row: fuzzy_similarity(row, row0))\n",
    "            \n",
    "        checked0.append([row0['state'], current_name])\n",
    "                        \n",
    "    if len(fixes) % 5 == 0 and len(fixes) > 0:\n",
    "        print(fixes[len(fixes) - 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5209288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay_call(agg_debt):\n",
    "    agg_debt['to whom due | first name'] = agg_debt['to whom due | first name'].astype(str)\n",
    "    agg_debt['to whom due | last name'] = agg_debt['to whom due | last name'].astype(str)\n",
    "    agg_debt.sort_values('to whom due | last name', inplace=True)\n",
    "    #agg_debt.reset_index(inplace=True)\n",
    "    #agg_debt['index1'] = agg_debt.index\n",
    "    agg_debt.apply(lambda row: determine_similarities(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save agg_debt as csv file: 'out.csv'\n",
    "agg_debt.to_csv('data/out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out.csv', 'r') as read_obj:\n",
    "\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "  \n",
    "    # convert string to list\n",
    "    entries = list(csv_reader)\n",
    "    \n",
    "    # remove empty lists\n",
    "    entries = [entry for entry in entries if entry != []]\n",
    "  \n",
    "    print(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a89b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize entries and group by state\n",
    "entries_dict = {}\n",
    "for entry in entries:\n",
    "    if entry[0] not in entries_dict:\n",
    "        entries_dict[entry[0]] = [entry]\n",
    "    else:\n",
    "        entries_dict[entry[0]] += [entry]\n",
    "\n",
    "print(entries_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1139a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# implement changes to agg_debt\n",
    "def implement_name_changes(row):  \n",
    "    if str(row['state']) not in entries_dict:\n",
    "        return row \n",
    "    \n",
    "    # only select part of the list that belongs to one person \n",
    "    entries_red = entries_dict[row['state']]\n",
    "    \n",
    "    # loop through list\n",
    "    # check if name matches \n",
    "    full_name = str(row['to whom due | first name']) + ' ' + str(row['to whom due | last name'])\n",
    "    \n",
    "    for entry in entries_red:\n",
    "        name_dict = ast.literal_eval(entry[1])\n",
    "        \n",
    "        if full_name in name_dict:\n",
    "            new_name = name_dict[full_name]\n",
    "            new_name_l = new_name.split()\n",
    "            new_fn = ''\n",
    "            new_ln = ''\n",
    "            \n",
    "            # account for middle initials and middle names\n",
    "            if len(new_name_l) >= 3:\n",
    "                name = HumanName(new_name)\n",
    "                \n",
    "                if len(name.middle) == 1: # middle initial\n",
    "                    new_fn = name.first + ' ' + name.middle \n",
    "                    new_ln = name.last\n",
    "                elif len(name.middle) > 1: # middle name\n",
    "                    new_fn = name.first\n",
    "                    new_ln = name.middle + ' ' + name.last\n",
    "                else: # no middle name \n",
    "                    new_fn = name.first\n",
    "                    new_ln = name.last\n",
    "                    \n",
    "            # if there is only a first name and a last name \n",
    "            else:\n",
    "                new_fn = new_name_l[0]\n",
    "                new_ln = new_name_l[1] \n",
    "            \n",
    "            # record changes\n",
    "            add_changes(row['to whom due | title'], row['to whom due | title'], row['to whom due | first name'], row['to whom due | last name'], \n",
    "                   new_fn, new_ln, 6, row['org_file'], row['org_index'])\n",
    "            \n",
    "            # remove unncessary spaces at the end of the string \n",
    "            new_fn.strip()\n",
    "            new_ln.strip()\n",
    "            \n",
    "            row['to whom due | first name'] = new_fn \n",
    "            row['to whom due | last name'] = new_ln\n",
    "            \n",
    "            print('old name=' + full_name)\n",
    "            print('new first name=' + new_fn)\n",
    "            print('new last name=' + new_ln)\n",
    "            print('name_changes status=' + str(len(name_changes)))\n",
    "            print('------------------')\n",
    "            \n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: implement_name_changes(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad133e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_debt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_debt.to_csv('data/agg_debt_clean_david.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_changes.to_csv('data/name_changes_david.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad6fbb",
   "metadata": {},
   "source": [
    "## Test Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a096d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed, cpu_count\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042742dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_debt_split = np.array_split(agg_debt, 7)\n",
    "print(len(agg_debt_split[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5fad6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ancestry_calls = [delayed(delay_call)(split) for split in agg_debt_split]\n",
    "results = Parallel(n_jobs=-1, backend=\"threading\")(ancestry_calls) \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/rerun.csv', 'r') as read_obj:\n",
    "\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "  \n",
    "    # convert string to list\n",
    "    entries = list(csv_reader)\n",
    "    \n",
    "    # remove empty lists\n",
    "    entries = [entry for entry in rerun_rows if entry != []]\n",
    "  \n",
    "    print(entries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
