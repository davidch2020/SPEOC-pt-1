{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Organization\n",
    " - Imports\n",
    " - Load & create dataframes\n",
    " - Declare Helper functions\n",
    " - Manual corrections & dropping invalid rows\n",
    " - Standardizing Town/State/Estate/Heir of (4 & 8)\n",
    " - Standardizing names containing 'of' that are entirely in the first name column (14)\n",
    " - Companies (2)\n",
    " - Entries with 2 names (3)\n",
    " - Names that are entirely in the first or last name column (9)\n",
    " - Filling in blank columns (7)\n",
    " - Deceased individuals (12)\n",
    " - abbreviations (5)\n",
    " - Group consecutive names (1)\n",
    " - Ancestry code (6)\n",
    "\n",
    "Refer to the 3rd cell (underneath imports) for information on each cleaning case (the numbers in parentheses above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamloughead/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import ssl\n",
    "\n",
    "from nameparser import HumanName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_29871/2089390861.py:2: DtypeWarning: Columns (1,7,9,10,12,14,15,19,20,21,23,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  og_df = pd.read_csv(\"../../cleaning_CD/pre1790/data/final_agg_debt.csv\")\n"
     ]
    }
   ],
   "source": [
    "#Load the aggregated file\n",
    "#og_df = original dataframe\n",
    "og_df = pd.read_csv(\"../../cleaning_CD/pre1790/data/final_agg_debt.csv\")\n",
    "\n",
    "#Load the changes dataframe\n",
    "corrections_df = None\n",
    "if not os.path.exists(\"../../cleaning_CD/pre1790/name_changes_liam.csv\"):\n",
    "    corrections_df = pd.DataFrame({'og_title': pd.Series(dtype='str'),\n",
    "                       'og_fname': pd.Series(dtype='str'),\n",
    "                       'og_lname': pd.Series(dtype='str'),\n",
    "                       'new_title': pd.Series(dtype='str'),\n",
    "                       'new_fname': pd.Series(dtype='str'),\n",
    "                       'new_lname': pd.Series(dtype='str'),\n",
    "                       'cleaning_case': pd.Series(dtype='int'),\n",
    "                       'file_loc': pd.Series(dtype='str'),\n",
    "                       'org_index': pd.Series(dtype='int')})\n",
    "else:\n",
    "    corrections_df = pd.read_csv(\"../../cleaning_CD/pre1790/name_changes_liam.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    " - retrieve_correction: Get the correction for the title, fname and lname in the dataframe\n",
    " - save_correction: Save the correction, given the original and new names\n",
    " - process_date: (Unused) Correct dates by prompting the user\n",
    " - text_contains_human_name: Returns an array of human names in the supplied text, empty array if no human names. More information from [this blog post](https://unbiased-coder.com/extract-names-python-nltk/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Ask running user if they want to enable manual corrections\n",
    "enable_manual_corrections = input(\"Enable manual correction system (yes, no)? (DO NOT ENABLE IF YOU ARE NOT READY TO MAKE MANUAL CORRECTIONS) > \")\n",
    "enable_manual_corrections = True if enable_manual_corrections == \"yes\" else False\n",
    "\n",
    "def retrieve_correction(og_title, og_fname, og_lname):\n",
    "    '''\n",
    "    Looks for a correction in the corrections dataframe\n",
    "    '''\n",
    "    for index, row in corrections_df.iterrows():\n",
    "        if row[\"og_title\"] == og_title and row[\"og_fname\"] == og_fname and row[\"og_lname\"] == og_lname:\n",
    "            return (row[\"new_title\"], row[\"new_fname\"], row[\"new_lname\"])\n",
    "    return None\n",
    "\n",
    "def save_manual_correction(og_title, og_fname, og_lname, new_title, new_fname, new_lname, clean_case, file, org_i, is_manual):\n",
    "    \"\"\"\n",
    "    Saves a correction to the correction df\n",
    "    \"\"\"\n",
    "    if is_manual and not enable_manual_corrections: return\n",
    "    corrections_df.loc[len(corrections_df.index)] = [\n",
    "        og_title, og_fname, og_lname,\n",
    "        new_title, new_fname, new_lname,\n",
    "        clean_case, file, org_i]\n",
    "\n",
    "#Download the necessary NLTK models for the below function\n",
    "#Change the below to True to use the workaround in case downloads don't work\n",
    "if True:\n",
    "    try:\n",
    "        _unverified = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        ssl._create_default_https_context = _unverified\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "def get_tags(text):\n",
    "    nltk_results = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    tags = {}\n",
    "    for nltk_result in nltk_results:\n",
    "        if type(nltk_result) == Tree:\n",
    "            name = ''\n",
    "            for nltk_result_leaf in nltk_result.leaves():\n",
    "                name += nltk_result_leaf[0] + ' '\n",
    "            tags[name] = nltk_result.label()\n",
    "    return tags\n",
    "\n",
    "def process_date(yr, mon, day, is_issued_date: bool, state_code, index):\n",
    "    \"\"\" Dates in the files can sometimes be invalid, specifically:\\n\n",
    "     - month and year are swapped\\n\n",
    "     - Typos in the year column (ex. 17780)\\n\n",
    "     - Dates that are impossible (Feburary 31, there are only 28 days in feburary)\\n\n",
    "    Args:\n",
    "        yr (int): Year\n",
    "        mon (int): Month\n",
    "        day (int): Day\n",
    "        is_issued_date (bool): specifies whether this date is the date a certificate is issued or the date is the maturity.\n",
    "        state_code (str): state code\n",
    "        index (int): index of row\n",
    "\n",
    "    Returns:\n",
    "        (int: ordinal of the date (datetime.toordinal(s)), bool: did a manual correction need to be made?)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        d = datetime.date(int(yr), int(mon), int(day))\n",
    "        return (d.toordinal(), False)\n",
    "    except Exception as e:\n",
    "        if \"10: ''\" in str(e): #ie. the \"Invalid literal for base 10: ''\" error, which means blank, which means just make it 0\n",
    "            return (0, False)\n",
    "        manual = retrieve_manual_correction(state_code, index)\n",
    "        if manual == None:\n",
    "            if 'month must' in str(e): #ie. month must be in range 1..12 - just swap month and day\n",
    "                d = datetime.date(yr, day, mon)\n",
    "                return (d.toordinal(), False)\n",
    "            new = input(f\"{state_code}: {'RE, ' if ('range' in str(e)) else ''}{'Issued: ' if is_issued_date else 'Expiries: '} {yr} {mon} {day} (yr-mon-day):\")\n",
    "            if new == \"\" and is_issued_date == False:\n",
    "                return (0, False)\n",
    "            d = datetime.date(int(new.split()[0]), int(new.split()[1]), int(new.split()[2]))\n",
    "            return (d.toordinal(), True)\n",
    "        else:\n",
    "            return (int(manual[1].split('-')[0]) if is_issued_date else int(manual[1].split('-')[1]), False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Corrections\n",
    "\n",
    "<b>Goal: </b>Remove very long names\n",
    "\n",
    "<b>Step: </b> Remove rows that contain names longer than 10 words (in either the first name or last name category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Super fast method - instead of going through it and adding to a new dataset,\n",
    "#use apply with a simple function that doesn't include long strings in a new dataset\n",
    "og_df = og_df[og_df['to whom due | first name'].apply(lambda name: len(str(name).split()) > 5) == False]\n",
    "og_df = og_df[og_df['to whom due | last name'].apply(lambda name: len(str(name).split()) > 5) == False]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heirs of & Estate of\n",
    "\n",
    "<b>Goal:</b> Remove \"Estate of\", \"Heirs of\", \"State of\" prefixes in an entry, and marks \"State of\" entries as organizations\n",
    "\n",
    "<b>Steps:</b>\n",
    "\n",
    "1. Check if a first name entry is longer than 2 words. If it is, run fuzzy checks to see if it begins with State of/Town of/Estate of/Heirs of (Use fuzzy checks to account for typos, which are quite frequent)\n",
    "2. For State of and Town of matches, make the first name \"State\" or \"Town\" respectively, make the last name the name of the state/town, and mark it as an organization\n",
    "3. For Estate of and Heirs of, make the first word the first name, and everything beyond it the last name\n",
    "4. Record any changes in ```name_changes```\n",
    "\n",
    "<b>Notes:</b>\n",
    "\n",
    "1. Sometimes \"Estate of\" is abbreviated to \"State of\", which confuses it (an example is the first manual correction)\n",
    "2. The \"State of\" fuzzy ratio threshold is higher than the \"Estate of\" and runs before it to catch \"State of\" as reliably as possible, just because they are 1 letter off.\n",
    "3. Example: First name: \"State of New York\", Last name: \"\" -> First name: \"State\", Last name: \"New York\"\n",
    "4. Example: First name: \"Estate of William Garrett\", Last name: \"\" -> First name: \"William\", Last name: \"Garrett\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_debt = pd.DataFrame(columns=og_df.columns)\n",
    "agg_debt[\"organization?\"] = False\n",
    "\n",
    "manual_corrections = [\n",
    "    {\"og_fname\": \"State of William Sweet\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"William\", \n",
    "     \"new_lname\": \"Sweet\"},\n",
    "    {\"og_fname\": \"Estateof Doct James Front\",\n",
    "     \"new_title\": \"Doct\",\n",
    "     \"new_fname\": \"James\",\n",
    "     \"new_lname\": \"Front\"},\n",
    "    {\"og_fname\": \"Estate of Capt John Williams\",\n",
    "     \"new_title\": \"Capt\",\n",
    "     \"new_fname\": \"John\",\n",
    "     \"new_lname\": \"Williams\"},\n",
    "    {\"og_fname\": \"Estate ofJon Bowman\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"Jon\",\n",
    "     \"new_lname\": \"Bowman\"},\n",
    "    {\"og_fname\": \"Esatate of Matthew Fentom\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"Matthew\",\n",
    "     \"new_lname\": \"Fentom\"},\n",
    "    {\"og_fname\": \"Estate ofJon Bowman\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"Thomas\",\n",
    "     \"new_lname\": \"Meredith\"}\n",
    "]\n",
    "\n",
    "def handle_ofs(row):\n",
    "    og_fname = str(row[\"to whom due | first name\"])\n",
    "    og_lname = str(row[\"to whom due | last name\"])\n",
    "    title = str(row[\"to whom due | title\"])\n",
    "    \n",
    "    for c in manual_corrections:\n",
    "        if c[\"og_fname\"] == og_fname:\n",
    "            row[\"to whom due | first name\"] = c[\"new_fname\"]\n",
    "            row[\"to whom due | last name\"] = c[\"new_lname\"]\n",
    "            row[\"to whom due | title\"] = c[\"new_title\"]\n",
    "            return row\n",
    "    \n",
    "    og_fname = og_fname.replace(\"the \", \"\").replace(\"The \", \"\")\n",
    "    og_lname = og_lname.replace(\"the \", \"\").replace(\"The \", \"\")\n",
    "    \n",
    "    if len(og_fname.split()) > 2:\n",
    "        prefix = og_fname.split()[0] + og_fname.split()[1]\n",
    "        prefix = prefix.lower()\n",
    "        if fuzz.ratio(prefix, \"state of\") >= 88 and \"est\" not in prefix: #\"not in\" so that this one won't pick up \"Estate of\"\n",
    "            lname =  \"-\".join(og_fname.split()[2:])\n",
    "            fname = \"State\"\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 8, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "            row[\"organization?\"] = True\n",
    "        elif fuzz.ratio(prefix, \"town of\") >= 88:\n",
    "            lname =  \"-\".join(og_fname.split()[2:])\n",
    "            fname = \"Town\"\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 8, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "            row[\"organization?\"] = True\n",
    "        elif (fuzz.ratio(prefix, \"estate of\") >= 85 or fuzz.ratio(prefix, \"Est of\") >= 85) and \"est\" in prefix: #\"in prefix\" so that this one won't pick up \"State of\"\n",
    "            #print(og_fname.split()[2:])\n",
    "            name = \" \".join(og_fname.split()[2:])\n",
    "            fname =  name.split()[0]\n",
    "            lname = name.split()[1:] if len(name.split()) > 1 else \"\"\n",
    "            if len(lname) == 0 and row[\"to whom due | last name\"] != \"\": lname = row[\"to whom due | last name\"]\n",
    "            if type(lname) == list: lname = \" \".join(lname)\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 4, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "        elif fuzz.ratio(prefix, \"heir of\") >= 85 or fuzz.ratio(prefix, \"heirs of\") >= 85:\n",
    "            name = \" \".join(og_fname.split()[2:])\n",
    "            fname =  name.split()[0]\n",
    "            lname = name.split()[1:] if len(name.split()) > 1 else \"\"\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 4, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = og_df.apply(lambda row: handle_ofs(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizations\n",
    "\n",
    "<b>Goal: </b> Catch and mark any organizations that were not caught in the above cell\n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Handle any manual corrections\n",
    "2. Use NLTK to check if a name is an organization\n",
    "\n",
    "<b>Notes: </b>\n",
    "1. NLTK is much more accurate when detecting if an entry is a person versus an organization, so anything not marked as a person is assumed to be an organization (that has the keyword \"of\" in the first name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trusts of Wilmington {'Wilmington ': 'PERSON'}: False\n",
      "Trusts of Wilmington {'Wilmington ': 'PERSON'}: False\n",
      "Trusts of Wilmington {'Wilmington ': 'PERSON'}: False\n",
      "Trusts of Wilmington {'Wilmington ': 'PERSON'}: False\n",
      "Esatate of Matthew {'Matthew ': 'GPE'}: True\n",
      "Esatate of Thomas {'Thomas ': 'GPE'}: True\n",
      "Administrator of Jacob {'Jacob ': 'PERSON'}: False\n",
      "Ecr of Jn {}: True\n",
      "Ecr of Jn {}: True\n",
      "Ex of Jacob {'Jacob ': 'PERSON'}: False\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of William {'Est ': 'GPE', 'William ': 'PERSON'}: False\n",
      "Est of William {'Est ': 'GPE', 'William ': 'PERSON'}: False\n",
      "Est of William {'Est ': 'GPE', 'William ': 'PERSON'}: False\n",
      "Ests of Randolph {'Randolph ': 'GPE'}: True\n",
      "Ests of Randolph {'Randolph ': 'GPE'}: True\n",
      "Ests of Randolph {'Randolph ': 'GPE'}: True\n"
     ]
    }
   ],
   "source": [
    "manual_corrections = {\n",
    "    \"School Committee of Derbey\": [\"School Committee\", \"Derbey\"],\n",
    "    \"Trusts of Wilmington Academy\": [\"Trusts\", \"Wilmington Academy\"],\n",
    "    \"Trusts of Wilmington\": [\"Trusts\", \"Wilmington\"],\n",
    "    \"Ruten of Chais\": [\"Ruten\", \"\"]\n",
    "}\n",
    "\n",
    "def handle_all_orgs(row):\n",
    "    og_fname = str(row[\"to whom due | first name\"])\n",
    "    og_lname = str(row[\"to whom due | last name\"])\n",
    "    title = row[\"to whom due | title\"]\n",
    "    \n",
    "    for og, correction in manual_corrections.items():\n",
    "        if og == og_fname:\n",
    "            row[\"organization?\"] = True\n",
    "            row[\"to whom due | first name\"] = correction[0]\n",
    "            row[\"to whom due | last name\"] = correction[1]\n",
    "            return row\n",
    "    \n",
    "    fname, lname = \"\", \"\"\n",
    "    if len(og_fname.split()) > 2 and ((\"of \" in og_fname) or (\" of\" in og_fname)):\n",
    "        tags = get_tags(og_fname)\n",
    "        is_org = True\n",
    "        for token, tag in tags.items():\n",
    "            if tag == \"PERSON\": #Geo political entity\n",
    "                is_org = False\n",
    "        print(f\"{og_fname} {tags}: {is_org}\")\n",
    "        if not is_org: return row\n",
    "        row[\"organization?\"] = True\n",
    "        before_of, after_of = og_fname.split(\"of\")\n",
    "        fname = before_of.strip().replace(\"-\", \"\")\n",
    "        lname = after_of.strip().replace(\"-\", \"\")\n",
    "        save_manual_correction(title, og_fname, og_lname, title, fname, lname, 14, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        row[\"to whom due | first name\"] = fname\n",
    "        row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_all_orgs(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name in only first or last name column\n",
    "\n",
    "<b>Goal: </b>Some names are entirely in the first name column or last name column, so split the name into their respective categories\n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Check if one column has a name and the other is blank\n",
    "2. Use the human name parser library to determine the first name and last names. \n",
    "3. Put each person's first name and last name in the respective columns\n",
    "4. Record change in ```name_changes```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_full_names_in_column(row):\n",
    "    if row[\"organization?\"] == True: return row #ignore orgnizations\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    name = None\n",
    "    if (len(lname.split()) == 0 or \"nan\" in lname or \"NaN\" in lname) and len(fname.split()) >= 2:\n",
    "        name = HumanName(fname)\n",
    "    if (len(fname.split()) == 0 or \"nan\" in fname or \"NaN\" in fname) and len(lname.split()) >= 2:\n",
    "        name = HumanName(lname)\n",
    "    if name == None:\n",
    "        return row\n",
    "    else:\n",
    "        save_manual_correction(row[\"to whom due | title\"], fname, lname, row[\"to whom due | title\"], name.first, name.last, 9, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        row[\"to whom due | first name\"] = name.first\n",
    "        row[\"to whom due | last name\"] = name.last\n",
    "        return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: correct_full_names_in_column(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark blank name columns with UNDEFINED\n",
    "\n",
    "<b>Goal: </b>Mark name columns (first name, last name) that are blank with UNDEFINED.\n",
    "\n",
    "<b>Steps: </b>\n",
    "1. If ```to whom due | first name``` is blank, fill it in with the word UNDEFINED\n",
    "2. If ```to whom due | last name``` is blank, fill it in with the word UNDEFINED\n",
    "3. Record change in ```name_changes```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_blank_name_cols(row):\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    if fname == \"\": fname = \"UNDEFINED\" # if there is no first name, make it undefined\n",
    "    elif lname == \"\": lname = \"UNDEFINED\" # if there is no last name, make it undefined\n",
    "    else: return row # if both aren't blank, return the row now\n",
    "    save_manual_correction(row[\"to whom due | title\"], row[\"to whom due | first name\"], row[\"to whom due | last name\"], row[\"to whom due | title\"], fname, lname, 7, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "    row[\"to whom due | first name\"] = fname\n",
    "    row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = og_df.apply(lambda row: handle_blank_name_cols(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deceased Individuals\n",
    "\n",
    "<b>Goal: </b>Add a column and mark each row if the individual is deceased\n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Check if a keyword is present in either name column\n",
    "2. If so, mark the row as deceased and remove the keyword from whatever column it was found in\n",
    "3. Record changes in ```name_changes```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a deceased column to get ready to mark all deceased owners\n",
    "agg_debt[\"deceased?\"] = False\n",
    "\n",
    "# Define the keywords to search for in the name\n",
    "keywords = [\" dead\", \"deceased\", \" dec'd\", \" dec'\", \" decd\", \" deceasd\"]\n",
    "\n",
    "# List of names that should not be marked\n",
    "manual_no_mark_list = [\"Slaughter Deadloff\"]\n",
    "\n",
    "# A quick helper function to take a string and check if any keyword is in the string, if so return the keyword found\n",
    "def check_keyword_in_string(word):\n",
    "    for keyword in keywords:\n",
    "        if keyword in word:\n",
    "            return keyword\n",
    "    return False\n",
    "\n",
    "def check_deceased(row):\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    fullname = fname + \" \" + lname #Create a full name to search for keywords\n",
    "    if fullname in manual_no_mark_list: return row #If the fullname should not be marked, don't mark it\n",
    "    k = check_keyword_in_string(fullname.lower()) #Use fullname.lower() to make sure string matching works correctly (ie. case-insensitive)\n",
    "    if k != False: #Meaning a keyword was found\n",
    "        row[\"deceased?\"] = True #Mark the row\n",
    "        fname = fname.replace(k, \"\") #Remove the keyword from the name\n",
    "        lname = lname.replace(k, \"\")\n",
    "        save_manual_correction(row[\"to whom due | title\"], row[\"to whom due | first name\"], row[\"to whom due | last name\"], row[\"to whom due | title\"], fname, lname, 12, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        row[\"to whom due | first name\"] = fname\n",
    "        row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = og_df.apply(lambda row: check_deceased(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not run cells below this line - these are kept here for referral purposes and are not functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consecutive names\n",
    "\n",
    "<b>Goal: </b>Consolidate the dataset by aggregating consecutive entries\n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Create a new dataframe called ```agg_df```\n",
    "2. If the current row has the same name as the last, then keep track of the current dollar amount for this person\n",
    "3. If the current row does not have the name as the last, and there have been consecutive entries, then add one one single entry of all of the aggregated entries to ```agg_df```\n",
    "3. If there were not consecutive entries, then the row is a one-off and added on to ```agg_df``` normally\n",
    "\n",
    "<b>Note: </b> This is a different, less efficient and more error-prone method of the \"Grouping consecutive names\" cell found in ```combined.ipynb```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop that covers Objective 1 (aggregate data files)\n",
    "def element_to_int(ele): # handles all kinds of Nans (returns 0 for nans)\n",
    "    if type(ele) == np.float64:\n",
    "        ele = round(ele)\n",
    "    if ele == np.nan: return 0\n",
    "    if str(ele) == \"nan\": return 0\n",
    "    return round(np.float64(ele))\n",
    "\n",
    "def get_dollar(row): #gets the dollar from a row by checking both dollar columns\n",
    "    dollar = 0\n",
    "    ninety = 0\n",
    "    #if dollar (90th) is a decimal, then split it\n",
    "    if '.' in str(element_to_int(row[11])): # \"amount | dollar\"\n",
    "        split = str(element_to_int(row[11])).split(\".\")\n",
    "        dollar, ninety = element_to_int(split[0]), element_to_int(split[1])\n",
    "    elif str(row[11]) == \"\": # \"amount | dollar\"\n",
    "        if '.' in str(element_to_int(row[24])): # \"amount | specie\"\n",
    "            split = str(element_to_int(row[24])).split() # \"amount | specie\"\n",
    "            dollar, ninety = element_to_int(split[0]), element_to_int(split[1])\n",
    "    else:\n",
    "        dollar = element_to_int(row[11]) # \"amount | dollar\"\n",
    "        ninety = element_to_int(row[12]) # \"amount | 90th\"\n",
    "    return float(str(dollar) + \".\" + str(ninety))\n",
    "\n",
    "def new_tup(old_row, new_dol, new_ninety, new_title): # returns a new tuple, specifically for totaled debt amounts (since you can't assign new values in tuples)\n",
    "    return (old_row[0], old_row[1], old_row[2], old_row[3], old_row[4], old_row[5], old_row[6],\n",
    "            new_title, old_row[8], old_row[9], old_row[10], new_dol, new_ninety, old_row[13],\n",
    "            old_row[14], old_row[15], old_row[16], old_row[17], old_row[18], old_row[19],\n",
    "            old_row[20], old_row[21], old_row[22], old_row[23], old_row[24], old_row[25],\n",
    "            old_row[26], old_row[27], old_row[28], old_row[29], old_row[30], old_row[31])\n",
    "\n",
    "agg_df = pd.DataFrame(columns=og_df.columns)\n",
    "last_f, last_l, last_t = \"\", \"\", \"\"\n",
    "last_row = None\n",
    "#save the sum of money\n",
    "current_sum = 0\n",
    "for row in og_df.itertuples(name=None, index=False): #main processing function\n",
    "    fname, lname = str(row[5]).strip(), str(row[6]).strip()\n",
    "    last_t = last_t if str(row[7]).strip().lower() == \"nan\" else str(row[7]).strip()\n",
    "    if fname == last_f and lname == last_l: #If the next name is the same as the last one, add onto the amount\n",
    "        dol = get_dollar(row)\n",
    "        print(f\"adding {dol} to {fname} {lname}'s total\")\n",
    "        current_sum += dol\n",
    "    else: #If the next name is not the same as the last one:\n",
    "        if current_sum > 0: #If the sum is more than 0 (ie. this is the end of consecutive same-name entries), then only add this on\n",
    "            print(f\"{last_row[5]} {last_row[6]} is consecutively owed {current_sum}\")\n",
    "            #consecutive has ended\n",
    "            split = str(current_sum).split(\".\")\n",
    "            agg_df.loc[len(agg_df.index)] = new_tup(last_row, int(split[0]), int(split[1]), last_t if last_t != \"\" else \"\")\n",
    "            current_sum = 0\n",
    "        else: #If the sum is not more than 0 (ie. this is one unique entry, add it on now)\n",
    "            #Normal\n",
    "            agg_df.loc[len(agg_df.index)] = last_row\n",
    "    last_f, last_l = fname, lname\n",
    "    last_row = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One cell cleaning\n",
    "\n",
    "The following cell was originally intended to clean everything, however it was slower and less readable then splitting each cleaning case into its own cell. Some functionality present here is not present in the above cells, so this is used as a reference in case its functionality becomes necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: Arch William Yard, Last: UNDEFINED, Title: \n"
     ]
    }
   ],
   "source": [
    "def check_note_present(note):\n",
    "    \"\"\"Checks if a transcriber note is just a number or actually useful\n",
    "\n",
    "    Args:\n",
    "        note (str): the note\n",
    "\n",
    "    Returns:\n",
    "        bool: if the transcriber note is useful\n",
    "    \"\"\"\n",
    "    if note != \"\":\n",
    "        if \"Lo\" in note or \"Ro\" in note:\n",
    "            return False\n",
    "        try:\n",
    "            float(note.strip())\n",
    "            return False\n",
    "        except:\n",
    "            pass\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def add_dash_to_prefix(name, prefix):\n",
    "    name = name.replace(prefix + \" \", prefix + \"-\")\n",
    "    name = name.replace(\" \" + prefix, \"-\" + prefix)\n",
    "    return name\n",
    "\n",
    "agg_cols = list(og_df.columns)\n",
    "agg_cols.append(\"deceased?\")\n",
    "agg_df = pd.DataFrame(columns=agg_cols)\n",
    "\n",
    "for index, row in og_df.iterrows():\n",
    "    row = row.replace(np.nan,'',regex=True)\n",
    "    row[\"deceased?\"] = False\n",
    "    title, fname, lname = row[\"to whom due | title\"].strip(), row[\"to whom due | first name\"].strip(), row[\"to whom due | last name\"].strip()\n",
    "    if len(fname.split()) == 1 and len(lname.split()) == 1:\n",
    "        agg_df.loc[len(agg_df.index)] = row\n",
    "        #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "        continue\n",
    "    #\"Van <something>\" and Zee last name and first name replacements\n",
    "    lname = add_dash_to_prefix(lname, \"Van\")\n",
    "    fname = add_dash_to_prefix(fname, \"Van\")\n",
    "    lname = add_dash_to_prefix(lname, \"Zee\")\n",
    "    fname = add_dash_to_prefix(fname, \"Zee\")\n",
    "    lname = add_dash_to_prefix(lname, \"Zie\")\n",
    "    fname = add_dash_to_prefix(fname, \"Zie\")\n",
    "    #Le, Mc, De name prefixes/suffixes\n",
    "    lname = add_dash_to_prefix(lname, \"Le\")\n",
    "    fname = add_dash_to_prefix(fname, \"Le\")\n",
    "    lname = add_dash_to_prefix(lname, \"De\")\n",
    "    fname = add_dash_to_prefix(fname, \"De\")\n",
    "    lname = add_dash_to_prefix(lname, \"Mc\")\n",
    "    fname = add_dash_to_prefix(fname, \"Mc\")\n",
    "\n",
    "    #Get rid of \"the\" prefixes\n",
    "    fname = fname.replace(\"The \", \"\", 1)\n",
    "    fname = fname.replace(\"the \", \"\", 1)\n",
    "    \n",
    "    #Jr, Sr, 1st, 2nd\n",
    "    lname = add_dash_to_prefix(lname, \"Jr\")\n",
    "    fname = add_dash_to_prefix(fname, \"Jr\")\n",
    "    lname = add_dash_to_prefix(lname, \"Sr\")\n",
    "    fname = add_dash_to_prefix(fname, \"Sr\")\n",
    "    lname = add_dash_to_prefix(lname, \"1st\")\n",
    "    fname = add_dash_to_prefix(fname, \"1st\")\n",
    "    lname = add_dash_to_prefix(lname, \"2nd\")\n",
    "    fname = add_dash_to_prefix(fname, \"2nd\")\n",
    "    lname = add_dash_to_prefix(lname, \"2d\")\n",
    "    fname = add_dash_to_prefix(fname, \"2d\")\n",
    "    #And co handling\n",
    "    fname = fname.replace(\" & Co\", \"\").replace(\" & co\", \"\").replace(\" and Co\", \"\").replace(\" and co\", \"\")\n",
    "    lname = lname.replace(\" & Co\", \"\").replace(\" & co\", \"\").replace(\" and Co\", \"\").replace(\" and co\", \"\")\n",
    "    \n",
    "    #Deceased handling\n",
    "    fullname = fname + \" \" + lname\n",
    "    for word in fullname.split():\n",
    "        if \"dead\" or \"decease\" or \"passed\" or \"dec'd\" or \"dec.\" or \"decd\" in word:\n",
    "            row[\"deceased?\"] = True\n",
    "            fname.replace(word, \"\")\n",
    "            lname.replace(word, \"\")\n",
    "    \n",
    "    #State of/Hiers of/Estate of/Town of handling - makes first name \"<thing>\", last name: \"<name>\"\n",
    "    #use fuzz because there are misspellings of Estate of and Heirs of\n",
    "    if len(fname.split()) > 2:\n",
    "        #State of/town of - \"<thing>\" \n",
    "        prefix = fname.split()[0] + fname.split()[1]\n",
    "        prefix = prefix.lower()\n",
    "        if fuzz.ratio(prefix, \"state of\") >= 88:\n",
    "            lname =  \"-\".join(fname.split()[2:])\n",
    "            fname = \"State\"\n",
    "        elif fuzz.ratio(prefix, \"town of\") >= 88:\n",
    "            lname =  \"-\".join(fname.split()[2:])\n",
    "            fname = \"Town\"\n",
    "        elif fuzz.ratio(prefix, \"estate of\") >= 85:\n",
    "            name = fname.replace(fname.split()[0] + fname.split()[1], \"\")\n",
    "            lname =  name.split()[0]\n",
    "            fname = name.split()[1]\n",
    "        elif fuzz.ratio(prefix, \"heir of\") >= 85:\n",
    "            name = fname.replace(fname.split()[0] + fname.split()[1], \"\")\n",
    "            lname =  name.split()[0]\n",
    "            fname = name.split()[1]\n",
    "    \n",
    "    if \" or \" in row[\"to whom due | last name\"]: continue\n",
    "    \n",
    "    if fname == \"\": fname = \"UNDEFINED\" # if there is no first name, make it undefined\n",
    "    if lname == \"\": lname = \"UNDEFINED\" # if there is no last name, make it undefined\n",
    "    \n",
    "    #if len(fname.split()) > 5 or len(lname.split()) > 5: continue # do not even try with ones that are crazy long\n",
    "    \n",
    "    if len(fname.split()) == 2:\n",
    "        #drop the dot - for example: \"James F.\" -> \"James F\"\n",
    "        if len(fname.replace(\".\", \"\").split()[1]) == 1: fname = fname.split()[0] # if middle initial in fname, drop it\n",
    "        elif len(fname.split()[1]) >= 3: # usually means 2 names\n",
    "            fname = fname.replace(\" \", \"-\")\n",
    "            if len(lname.split()) == 0: #usually means that first and last names are put into just first name column\n",
    "                lname = fname.split(\"-\")[1]\n",
    "                fname = fname.split(\"-\")[0]\n",
    "    #Do the same above for the last name\n",
    "    if len(lname.split()) == 2:\n",
    "        if len(lname.replace(\".\", \"\").split()[1]) == 1: lname = lname.split()[0] # if initial in lname, drop it\n",
    "        elif len(lname.split()[1]) >= 3: lname = lname.replace(\" \", \"-\") # usually means 2 names\n",
    "    if fname == \"\" and lname == \"\": continue # Drop ones with no name data\n",
    "    \n",
    "    if ('&' in fname) or (' and' in fname) or ('|' in fname):\n",
    "        #Means there is co-ownership\n",
    "        to_add = []\n",
    "        sepr = \"\"\n",
    "        if (\"&\" in fname): sepr = \"&\"\n",
    "        if (\" and\" in fname): sepr = \"and\"\n",
    "        if (\"|\" in fname): sepr = \"|\"\n",
    "        for i in range(len(fname.split(sepr))):\n",
    "            row[\"to whom due | first name\"] = fname.split(sepr)[i].strip()\n",
    "            row[\"to whom due | last name\"] = \"undefined\"\n",
    "            agg_df.loc[len(agg_df.index)] = row\n",
    "            #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "        continue\n",
    "    if len(fname.split()) != 1 or len(lname.split()) != 1:\n",
    "        print(f\"First: {fname}, Last: {lname}, Title: {title}\")\n",
    "        correction = retrieve_manual_correction(title + \" \" + fname + \" \" + lname)\n",
    "        if correction != None:\n",
    "            title_new, first_new, last_new, drop = correction\n",
    "            if drop: continue\n",
    "            row[\"to whom due | title\"] = title_new\n",
    "            row[\"to whom due | first name\"] = first_new\n",
    "            row[\"to whom due | last name\"] = last_new\n",
    "            agg_df.loc[len(agg_df.index)] = row\n",
    "            #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)\n",
    "        else:\n",
    "            new = input(f\"In {row['org_file']}, First: {fname}, Last: {lname}, Title: {title} >>> \")\n",
    "            if new == \"s\":\n",
    "                break\n",
    "            elif new == \"k\":\n",
    "                fullname = title + \" \" + fname + \" \" + lname\n",
    "                save_manual_correction(fullname, fullname.replace(\" \", \"-\"), False)\n",
    "            elif new == \"\":\n",
    "                print(\"dropping\")\n",
    "                save_manual_correction(title + \" \" + fname + \" \" + lname, \" \", True)\n",
    "            else:\n",
    "                split = new.split()\n",
    "                nt, nf, nl = \"\", \"\", \"\"\n",
    "                if len(split) == 2:\n",
    "                    nf, nl = new.split()\n",
    "                if len(split) == 3:\n",
    "                    nt, nf, nl = new.split()\n",
    "                save_manual_correction(title + \" \" + fname + \" \" + lname, nt + \" \" + nf + \" \" + nl, False)\n",
    "    else:\n",
    "        agg_df.loc[len(agg_df.index)] = row\n",
    "        #agg_df = pd.concat([agg_df, row.to_frame().T], ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "01843e40f215bf95274bc2c8c3e35c535d55c23ad112577253f312d1e860a459"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
