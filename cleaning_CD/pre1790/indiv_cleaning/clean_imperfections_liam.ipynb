{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Organization\n",
    " - Imports\n",
    " - Load & create dataframes\n",
    " - Declare Helper functions\n",
    " - Manual corrections & dropping invalid rows\n",
    " - Standardizing Town/State/Estate/Heir of (4 & 8)\n",
    " - Standardizing names containing 'of' that are entirely in the first name column (14)\n",
    " - Companies (2)\n",
    " - Entries with 2 names (3)\n",
    " - Names that are entirely in the first or last name column (9)\n",
    " - Filling in blank columns (7)\n",
    " - Deceased individuals (12)\n",
    " - abbreviations (5)\n",
    " - Group consecutive names (1)\n",
    " - Ancestry code (6)\n",
    "\n",
    "Refer to the 3rd cell (underneath imports) for information on each cleaning case (the numbers in parentheses above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamloughead/Code/SPEOC-pt-1/.venv/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import ssl\n",
    "\n",
    "from nameparser import HumanName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/ttydz5l94qz_x6kzy6q6_4_rnvbbsq/T/ipykernel_29871/2089390861.py:2: DtypeWarning: Columns (1,7,9,10,12,14,15,19,20,21,23,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  og_df = pd.read_csv(\"../../cleaning_CD/pre1790/data/final_agg_debt.csv\")\n"
     ]
    }
   ],
   "source": [
    "#Load the aggregated file\n",
    "#og_df = original dataframe\n",
    "og_df = pd.read_csv(\"../../cleaning_CD/pre1790/data/final_agg_debt.csv\")\n",
    "\n",
    "#Load the changes dataframe\n",
    "corrections_df = None\n",
    "if not os.path.exists(\"../../cleaning_CD/pre1790/name_changes_liam.csv\"):\n",
    "    corrections_df = pd.DataFrame({'og_title': pd.Series(dtype='str'),\n",
    "                       'og_fname': pd.Series(dtype='str'),\n",
    "                       'og_lname': pd.Series(dtype='str'),\n",
    "                       'new_title': pd.Series(dtype='str'),\n",
    "                       'new_fname': pd.Series(dtype='str'),\n",
    "                       'new_lname': pd.Series(dtype='str'),\n",
    "                       'cleaning_case': pd.Series(dtype='int'),\n",
    "                       'file_loc': pd.Series(dtype='str'),\n",
    "                       'org_index': pd.Series(dtype='int')})\n",
    "else:\n",
    "    corrections_df = pd.read_csv(\"../../cleaning_CD/pre1790/name_changes_liam.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    " - retrieve_correction: Get the correction for the title, fname and lname in the dataframe\n",
    " - save_correction: Save the correction, given the original and new names\n",
    " - process_date: (Unused) Correct dates by prompting the user\n",
    " - text_contains_human_name: Returns an array of human names in the supplied text, empty array if no human names. More information from [this blog post](https://unbiased-coder.com/extract-names-python-nltk/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/liamloughead/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Ask running user if they want to enable manual corrections\n",
    "enable_manual_corrections = input(\"Enable manual correction system (yes, no)? (DO NOT ENABLE IF YOU ARE NOT READY TO MAKE MANUAL CORRECTIONS) > \")\n",
    "enable_manual_corrections = True if enable_manual_corrections == \"yes\" else False\n",
    "\n",
    "def retrieve_correction(og_title, og_fname, og_lname):\n",
    "    '''\n",
    "    Looks for a correction in the corrections dataframe\n",
    "    '''\n",
    "    for index, row in corrections_df.iterrows():\n",
    "        if row[\"og_title\"] == og_title and row[\"og_fname\"] == og_fname and row[\"og_lname\"] == og_lname:\n",
    "            return (row[\"new_title\"], row[\"new_fname\"], row[\"new_lname\"])\n",
    "    return None\n",
    "\n",
    "def save_manual_correction(og_title, og_fname, og_lname, new_title, new_fname, new_lname, clean_case, file, org_i, is_manual):\n",
    "    \"\"\"\n",
    "    Saves a correction to the correction df\n",
    "    \"\"\"\n",
    "    if is_manual and not enable_manual_corrections: return\n",
    "    corrections_df.loc[len(corrections_df.index)] = [\n",
    "        og_title, og_fname, og_lname,\n",
    "        new_title, new_fname, new_lname,\n",
    "        clean_case, file, org_i]\n",
    "\n",
    "#Download the necessary NLTK models for the below function\n",
    "#Change the below to True to use the workaround in case downloads don't work\n",
    "if True:\n",
    "    try:\n",
    "        _unverified = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        ssl._create_default_https_context = _unverified\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "def get_tags(text):\n",
    "    nltk_results = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    tags = {}\n",
    "    for nltk_result in nltk_results:\n",
    "        if type(nltk_result) == Tree:\n",
    "            name = ''\n",
    "            for nltk_result_leaf in nltk_result.leaves():\n",
    "                name += nltk_result_leaf[0] + ' '\n",
    "            tags[name] = nltk_result.label()\n",
    "    return tags\n",
    "\n",
    "def process_date(yr, mon, day, is_issued_date: bool, state_code, index):\n",
    "    \"\"\" Dates in the files can sometimes be invalid, specifically:\\n\n",
    "     - month and year are swapped\\n\n",
    "     - Typos in the year column (ex. 17780)\\n\n",
    "     - Dates that are impossible (Feburary 31, there are only 28 days in feburary)\\n\n",
    "    Args:\n",
    "        yr (int): Year\n",
    "        mon (int): Month\n",
    "        day (int): Day\n",
    "        is_issued_date (bool): specifies whether this date is the date a certificate is issued or the date is the maturity.\n",
    "        state_code (str): state code\n",
    "        index (int): index of row\n",
    "\n",
    "    Returns:\n",
    "        (int: ordinal of the date (datetime.toordinal(s)), bool: did a manual correction need to be made?)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        d = datetime.date(int(yr), int(mon), int(day))\n",
    "        return (d.toordinal(), False)\n",
    "    except Exception as e:\n",
    "        if \"10: ''\" in str(e): #ie. the \"Invalid literal for base 10: ''\" error, which means blank, which means just make it 0\n",
    "            return (0, False)\n",
    "        manual = retrieve_manual_correction(state_code, index)\n",
    "        if manual == None:\n",
    "            if 'month must' in str(e): #ie. month must be in range 1..12 - just swap month and day\n",
    "                d = datetime.date(yr, day, mon)\n",
    "                return (d.toordinal(), False)\n",
    "            new = input(f\"{state_code}: {'RE, ' if ('range' in str(e)) else ''}{'Issued: ' if is_issued_date else 'Expiries: '} {yr} {mon} {day} (yr-mon-day):\")\n",
    "            if new == \"\" and is_issued_date == False:\n",
    "                return (0, False)\n",
    "            d = datetime.date(int(new.split()[0]), int(new.split()[1]), int(new.split()[2]))\n",
    "            return (d.toordinal(), True)\n",
    "        else:\n",
    "            return (int(manual[1].split('-')[0]) if is_issued_date else int(manual[1].split('-')[1]), False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Corrections\n",
    "\n",
    "<b>Goal: </b>Remove very long names\n",
    "\n",
    "<b>Step: </b> Remove rows that contain names longer than 10 words (in either the first name or last name category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Super fast method - instead of going through it and adding to a new dataset,\n",
    "#use apply with a simple function that doesn't include long strings in a new dataset\n",
    "og_df = og_df[og_df['to whom due | first name'].apply(lambda name: len(str(name).split()) > 5) == False]\n",
    "og_df = og_df[og_df['to whom due | last name'].apply(lambda name: len(str(name).split()) > 5) == False]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heirs of & Estate of\n",
    "\n",
    "<b>Goal:</b> Remove \"Estate of\", \"Heirs of\", \"State of\" prefixes in an entry, and marks \"State of\" entries as organizations\n",
    "\n",
    "<b>Steps:</b>\n",
    "\n",
    "1. Check if a first name entry is longer than 2 words. If it is, run fuzzy checks to see if it begins with State of/Town of/Estate of/Heirs of (Use fuzzy checks to account for typos, which are quite frequent)\n",
    "2. For State of and Town of matches, make the first name \"State\" or \"Town\" respectively, make the last name the name of the state/town, and mark it as an organization\n",
    "3. For Estate of and Heirs of, make the first word the first name, and everything beyond it the last name\n",
    "4. Record any changes in ```name_changes```\n",
    "\n",
    "<b>Notes:</b>\n",
    "\n",
    "1. Sometimes \"Estate of\" is abbreviated to \"State of\", which confuses it (an example is the first manual correction)\n",
    "2. The \"State of\" fuzzy ratio threshold is higher than the \"Estate of\" and runs before it to catch \"State of\" as reliably as possible, just because they are 1 letter off.\n",
    "3. Example: First name: \"State of New York\", Last name: \"\" -> First name: \"State\", Last name: \"New York\"\n",
    "4. Example: First name: \"Estate of William Garrett\", Last name: \"\" -> First name: \"William\", Last name: \"Garrett\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_debt = pd.DataFrame(columns=og_df.columns)\n",
    "agg_debt[\"organization?\"] = False\n",
    "\n",
    "manual_corrections = [\n",
    "    {\"og_fname\": \"State of William Sweet\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"William\", \n",
    "     \"new_lname\": \"Sweet\"},\n",
    "    {\"og_fname\": \"Estateof Doct James Front\",\n",
    "     \"new_title\": \"Doct\",\n",
    "     \"new_fname\": \"James\",\n",
    "     \"new_lname\": \"Front\"},\n",
    "    {\"og_fname\": \"Estate of Capt John Williams\",\n",
    "     \"new_title\": \"Capt\",\n",
    "     \"new_fname\": \"John\",\n",
    "     \"new_lname\": \"Williams\"},\n",
    "    {\"og_fname\": \"Estate ofJon Bowman\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"Jon\",\n",
    "     \"new_lname\": \"Bowman\"},\n",
    "    {\"og_fname\": \"Esatate of Matthew Fentom\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"Matthew\",\n",
    "     \"new_lname\": \"Fentom\"},\n",
    "    {\"og_fname\": \"Estate ofJon Bowman\",\n",
    "     \"new_title\": \"\",\n",
    "     \"new_fname\": \"Thomas\",\n",
    "     \"new_lname\": \"Meredith\"}\n",
    "]\n",
    "\n",
    "def handle_ofs(row):\n",
    "    og_fname = str(row[\"to whom due | first name\"])\n",
    "    og_lname = str(row[\"to whom due | last name\"])\n",
    "    title = str(row[\"to whom due | title\"])\n",
    "    \n",
    "    for c in manual_corrections:\n",
    "        if c[\"og_fname\"] == og_fname:\n",
    "            row[\"to whom due | first name\"] = c[\"new_fname\"]\n",
    "            row[\"to whom due | last name\"] = c[\"new_lname\"]\n",
    "            row[\"to whom due | title\"] = c[\"new_title\"]\n",
    "            return row\n",
    "    \n",
    "    og_fname = og_fname.replace(\"the \", \"\").replace(\"The \", \"\")\n",
    "    og_lname = og_lname.replace(\"the \", \"\").replace(\"The \", \"\")\n",
    "    \n",
    "    if len(og_fname.split()) > 2:\n",
    "        prefix = og_fname.split()[0] + og_fname.split()[1]\n",
    "        prefix = prefix.lower()\n",
    "        if fuzz.ratio(prefix, \"state of\") >= 88 and \"est\" not in prefix: #\"not in\" so that this one won't pick up \"Estate of\"\n",
    "            lname =  \"-\".join(og_fname.split()[2:])\n",
    "            fname = \"State\"\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 8, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "            row[\"organization?\"] = True\n",
    "        elif fuzz.ratio(prefix, \"town of\") >= 88:\n",
    "            lname =  \"-\".join(og_fname.split()[2:])\n",
    "            fname = \"Town\"\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 8, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "            row[\"organization?\"] = True\n",
    "        elif (fuzz.ratio(prefix, \"estate of\") >= 85 or fuzz.ratio(prefix, \"Est of\") >= 85) and \"est\" in prefix: #\"in prefix\" so that this one won't pick up \"State of\"\n",
    "            #print(og_fname.split()[2:])\n",
    "            name = \" \".join(og_fname.split()[2:])\n",
    "            fname =  name.split()[0]\n",
    "            lname = name.split()[1:] if len(name.split()) > 1 else \"\"\n",
    "            if len(lname) == 0 and row[\"to whom due | last name\"] != \"\": lname = row[\"to whom due | last name\"]\n",
    "            if type(lname) == list: lname = \" \".join(lname)\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 4, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "        elif fuzz.ratio(prefix, \"heir of\") >= 85 or fuzz.ratio(prefix, \"heirs of\") >= 85:\n",
    "            name = \" \".join(og_fname.split()[2:])\n",
    "            fname =  name.split()[0]\n",
    "            lname = name.split()[1:] if len(name.split()) > 1 else \"\"\n",
    "            save_manual_correction(title, row[\"to whom due | first name\"], row[\"to whom due | last name\"], title, fname, lname, 4, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "            row[\"to whom due | first name\"] = fname\n",
    "            row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = og_df.apply(lambda row: handle_ofs(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizations\n",
    "\n",
    "<b>Goal: </b> Catch and mark any organizations that were not caught in the above cell\n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Handle any manual corrections\n",
    "2. Use NLTK to check if a name is an organization\n",
    "\n",
    "<b>Notes: </b>\n",
    "1. NLTK is much more accurate when detecting if an entry is a person versus an organization, so anything not marked as a person is assumed to be an organization (that has the keyword \"of\" in the first name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trusts of Wilmington {'Wilmington ': 'PERSON'}: False\n",
      "Trusts of Wilmington {'Wilmington ': 'PERSON'}: False\n",
      "Trusts of Wilmington {'Wilmington ': 'PERSON'}: False\n",
      "Trusts of Wilmington {'Wilmington ': 'PERSON'}: False\n",
      "Esatate of Matthew {'Matthew ': 'GPE'}: True\n",
      "Esatate of Thomas {'Thomas ': 'GPE'}: True\n",
      "Administrator of Jacob {'Jacob ': 'PERSON'}: False\n",
      "Ecr of Jn {}: True\n",
      "Ecr of Jn {}: True\n",
      "Ex of Jacob {'Jacob ': 'PERSON'}: False\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of Presley {}: True\n",
      "Est of William {'Est ': 'GPE', 'William ': 'PERSON'}: False\n",
      "Est of William {'Est ': 'GPE', 'William ': 'PERSON'}: False\n",
      "Est of William {'Est ': 'GPE', 'William ': 'PERSON'}: False\n",
      "Ests of Randolph {'Randolph ': 'GPE'}: True\n",
      "Ests of Randolph {'Randolph ': 'GPE'}: True\n",
      "Ests of Randolph {'Randolph ': 'GPE'}: True\n"
     ]
    }
   ],
   "source": [
    "manual_corrections = {\n",
    "    \"School Committee of Derbey\": [\"School Committee\", \"Derbey\"],\n",
    "    \"Trusts of Wilmington Academy\": [\"Trusts\", \"Wilmington Academy\"],\n",
    "    \"Trusts of Wilmington\": [\"Trusts\", \"Wilmington\"],\n",
    "    \"Ruten of Chais\": [\"Ruten\", \"\"]\n",
    "}\n",
    "\n",
    "def handle_all_orgs(row):\n",
    "    og_fname = str(row[\"to whom due | first name\"])\n",
    "    og_lname = str(row[\"to whom due | last name\"])\n",
    "    title = row[\"to whom due | title\"]\n",
    "    \n",
    "    for og, correction in manual_corrections.items():\n",
    "        if og == og_fname:\n",
    "            row[\"organization?\"] = True\n",
    "            row[\"to whom due | first name\"] = correction[0]\n",
    "            row[\"to whom due | last name\"] = correction[1]\n",
    "            return row\n",
    "    \n",
    "    fname, lname = \"\", \"\"\n",
    "    if len(og_fname.split()) > 2 and ((\"of \" in og_fname) or (\" of\" in og_fname)):\n",
    "        tags = get_tags(og_fname)\n",
    "        is_org = True\n",
    "        for token, tag in tags.items():\n",
    "            if tag == \"PERSON\": #Geo political entity\n",
    "                is_org = False\n",
    "        print(f\"{og_fname} {tags}: {is_org}\")\n",
    "        if not is_org: return row\n",
    "        row[\"organization?\"] = True\n",
    "        before_of, after_of = og_fname.split(\"of\")\n",
    "        fname = before_of.strip().replace(\"-\", \"\")\n",
    "        lname = after_of.strip().replace(\"-\", \"\")\n",
    "        save_manual_correction(title, og_fname, og_lname, title, fname, lname, 14, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        row[\"to whom due | first name\"] = fname\n",
    "        row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: handle_all_orgs(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name in only first or last name column\n",
    "\n",
    "<b>Goal: </b>Some names are entirely in the first name column or last name column, so split the name into their respective categories\n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Check if one column has a name and the other is blank\n",
    "2. Use the human name parser library to determine the first name and last names. \n",
    "3. Put each person's first name and last name in the respective columns\n",
    "4. Record change in ```name_changes```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_full_names_in_column(row):\n",
    "    if row[\"organization?\"] == True: return row #ignore orgnizations\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    name = None\n",
    "    if (len(lname.split()) == 0 or \"nan\" in lname or \"NaN\" in lname) and len(fname.split()) >= 2:\n",
    "        name = HumanName(fname)\n",
    "    if (len(fname.split()) == 0 or \"nan\" in fname or \"NaN\" in fname) and len(lname.split()) >= 2:\n",
    "        name = HumanName(lname)\n",
    "    if name == None:\n",
    "        return row\n",
    "    else:\n",
    "        save_manual_correction(row[\"to whom due | title\"], fname, lname, row[\"to whom due | title\"], name.first, name.last, 9, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        row[\"to whom due | first name\"] = name.first\n",
    "        row[\"to whom due | last name\"] = name.last\n",
    "        return row\n",
    "\n",
    "agg_debt = agg_debt.apply(lambda row: correct_full_names_in_column(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark blank name columns with UNDEFINED\n",
    "\n",
    "<b>Goal: </b>Mark name columns (first name, last name) that are blank with UNDEFINED.\n",
    "\n",
    "<b>Steps: </b>\n",
    "1. If ```to whom due | first name``` is blank, fill it in with the word UNDEFINED\n",
    "2. If ```to whom due | last name``` is blank, fill it in with the word UNDEFINED\n",
    "3. Record change in ```name_changes```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_blank_name_cols(row):\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    if fname == \"\": fname = \"UNDEFINED\" # if there is no first name, make it undefined\n",
    "    elif lname == \"\": lname = \"UNDEFINED\" # if there is no last name, make it undefined\n",
    "    else: return row # if both aren't blank, return the row now\n",
    "    save_manual_correction(row[\"to whom due | title\"], row[\"to whom due | first name\"], row[\"to whom due | last name\"], row[\"to whom due | title\"], fname, lname, 7, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "    row[\"to whom due | first name\"] = fname\n",
    "    row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = og_df.apply(lambda row: handle_blank_name_cols(row), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deceased Individuals\n",
    "\n",
    "<b>Goal: </b>Add a column and mark each row if the individual is deceased\n",
    "\n",
    "<b>Steps: </b>\n",
    "1. Check if a keyword is present in either name column\n",
    "2. If so, mark the row as deceased and remove the keyword from whatever column it was found in\n",
    "3. Record changes in ```name_changes```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a deceased column to get ready to mark all deceased owners\n",
    "agg_debt[\"deceased?\"] = False\n",
    "\n",
    "# Define the keywords to search for in the name\n",
    "keywords = [\" dead\", \"deceased\", \" dec'd\", \" dec'\", \" decd\", \" deceasd\"]\n",
    "\n",
    "# List of names that should not be marked\n",
    "manual_no_mark_list = [\"Slaughter Deadloff\"]\n",
    "\n",
    "# A quick helper function to take a string and check if any keyword is in the string, if so return the keyword found\n",
    "def check_keyword_in_string(word):\n",
    "    for keyword in keywords:\n",
    "        if keyword in word:\n",
    "            return keyword\n",
    "    return False\n",
    "\n",
    "def check_deceased(row):\n",
    "    fname = str(row[\"to whom due | first name\"])\n",
    "    lname = str(row[\"to whom due | last name\"])\n",
    "    fullname = fname + \" \" + lname #Create a full name to search for keywords\n",
    "    if fullname in manual_no_mark_list: return row #If the fullname should not be marked, don't mark it\n",
    "    k = check_keyword_in_string(fullname.lower()) #Use fullname.lower() to make sure string matching works correctly (ie. case-insensitive)\n",
    "    if k != False: #Meaning a keyword was found\n",
    "        row[\"deceased?\"] = True #Mark the row\n",
    "        fname = fname.replace(k, \"\") #Remove the keyword from the name\n",
    "        lname = lname.replace(k, \"\")\n",
    "        save_manual_correction(row[\"to whom due | title\"], row[\"to whom due | first name\"], row[\"to whom due | last name\"], row[\"to whom due | title\"], fname, lname, 12, row[\"org_file\"], row[\"org_index\"], is_manual=False)\n",
    "        row[\"to whom due | first name\"] = fname\n",
    "        row[\"to whom due | last name\"] = lname\n",
    "    return row\n",
    "\n",
    "agg_debt = og_df.apply(lambda row: check_deceased(row), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "01843e40f215bf95274bc2c8c3e35c535d55c23ad112577253f312d1e860a459"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
