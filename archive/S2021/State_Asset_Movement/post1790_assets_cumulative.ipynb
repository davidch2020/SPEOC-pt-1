{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Data Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "from os.path import exists\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def stringConvert(x):\n",
    "    return x.replace(\"  \", \" \") if type(x) == str else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def combineLists(lst):\n",
    "    returnlst = []\n",
    "    for sublist in lst:\n",
    "        if type(sublist) == list:\n",
    "            returnlst.extend([item for item in sublist])\n",
    "        else:\n",
    "            returnlst.append(sublist)\n",
    "    return returnlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#function that makes dictionary that combines 3 full name columns into 1\n",
    "def genFullNameList(namelst): \n",
    "    #remove duplicates and nulls\n",
    "    namelst = list(set([name for name in namelst if not pd.isnull(name)]))\n",
    "    namelst = sorted(namelst, key=len)\n",
    "    #remove names that are really similar\n",
    "    namelstnew = namelst\n",
    "    if len(namelst) > 1:\n",
    "        namelstnew = []\n",
    "        name1 = namelst[0]\n",
    "        namelstnew.append(name1)\n",
    "        for name in namelst[1:]:\n",
    "            score1  = process.extract(name1, [name])[0][1]\n",
    "            #only add names if they are dissimilar - fuzzy score 70 or less\n",
    "            if score1 <= 70:\n",
    "                namelstnew.append(name)\n",
    "    return namelstnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def genFuzzyDict(df):\n",
    "    namelst = list(set([name for namelist in df['full name prelim'] for name in namelist]))\n",
    "    #create dictionary that matches similar names together\n",
    "    fn_fuzzy_pre = dict()\n",
    "    for name in namelst:\n",
    "        marker = False\n",
    "        if not pd.isnull(name):\n",
    "            #find matches for name\n",
    "            match = process.extract(name, [x for x in namelst if x != name and not \n",
    "                                           pd.isnull(x)], limit = 1, score_cutoff = 90)\n",
    "            if len(match)> 0:\n",
    "                match = match[0]\n",
    "                if match[1]>95:\n",
    "                    #add suitable matches to dictionary\n",
    "                    for nm in [match[0], name]:\n",
    "                        if nm in fn_fuzzy_pre.keys() and not marker:\n",
    "                            fn_fuzzy_pre[nm].extend([n for n in [match[0], name] if \n",
    "                                                     n != nm and n not in fn_fuzzy_pre[nm]])\n",
    "                            marker = True\n",
    "                    if not marker:\n",
    "                        if len(name) < len(match[0]):\n",
    "                            fn_fuzzy_pre[name] = [match[0]]\n",
    "                        else:\n",
    "                            fn_fuzzy_pre[match[0]] = [name]\n",
    "    #invert dictionary\n",
    "    fn_fuzzy = dict()\n",
    "    for key in fn_fuzzy_pre.keys():\n",
    "        vals = fn_fuzzy_pre[key]\n",
    "        for val in vals:\n",
    "            fn_fuzzy[val] = key\n",
    "    \n",
    "    return fn_fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#separate a string that contains two names into a list of two names\n",
    "def parseNames(x):\n",
    "    #replace words that don't have meaning\n",
    "    x = x.replace(\"and Co\", \"\").replace(\"and co\", \"\").replace(\"and Others\" ,\"\")\n",
    "    x = x.replace(\"and others\", \"\").replace(\"and Son\", \"\").replace(\"and Sons\", \"\")\n",
    "    x = x.replace(\"and Brothers\", \"\").strip()\n",
    "    #string preprocessing\n",
    "    namelst = x.split(\" and \")\n",
    "    namelst = [x.strip() for x in namelst if x.strip() != \"\"]\n",
    "    if len(namelst) > 1:\n",
    "        wd1len = len(namelst[0].split(\" \"))\n",
    "        wd2len = len(namelst[1].split(\" \"))\n",
    "        #add last name\n",
    "        if wd1len == 1 and wd2len != 1:\n",
    "            namelst[0] = namelst[0] + \" \" + namelst[1].split(\" \")[-1]\n",
    "    return namelst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transformdf(df, state):\n",
    "    #add full name columns\n",
    "    df['full name 1'] = (df['First Name'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 1'] = df['full name 1'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['full name 2'] = (df['First Name.1'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name.1'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 2'] = df['full name 2'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['full name 3'] = (df['First Name.2'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name.2'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 3'] = df['full name 3'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['debt state'] = state\n",
    "    #add dicionary to merge different full name columns into one\n",
    "    df['full name prelim'] = [ ([fname1, fname2, fname3])\n",
    "                              for fname1, fname2, fname3 in zip(df['full name 1'],\n",
    "                                                                df['full name 2'],\n",
    "                                                                df['full name 3'])]\n",
    "    df['full name'] = df['full name prelim']\n",
    "    #do some additional preprocessing\n",
    "    df = df[df['full name'].apply(lambda x: x != [])]\n",
    "    #separate names that are combined with \"and\", or otherwise treatde as one when they should be two\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [parseNames(x) if len(x.strip().split(\" \")) > 2 and \" and \" in x \n",
    "                                                                 else x for x in lst])\n",
    "    df['full name'] = df['full name'].apply(lambda namelist: combineLists(namelist))\n",
    "    \n",
    "    #fuzzy matching for different names in the full name column\n",
    "    fn_fuzzy = genFuzzyDict(df)\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [x if x not in fn_fuzzy.keys() \n",
    "                                                         else fn_fuzzy[x] for x in lst])\n",
    "    #simplify state into just one column\n",
    "    if 'state1' in list(df.columns):\n",
    "        state_list = [[s for s in list(set([s1, s2, s3])) if not pd.isnull(s)]\n",
    "                      for s1, s2, s3 in zip(df['state1'], df['state2'], df['state3'])]\n",
    "        df['state']  = [state[0] if state != [] else np.nan for state in state_list]\n",
    "   \n",
    "    #fill in potentially missing states\n",
    "    missing_fullname = list(df[df['state'].apply(lambda x: pd.isnull(x))]['full name'])\n",
    "    missing_ind = list(df[df['state'].apply(lambda x: pd.isnull(x))].index)\n",
    "    replacement_states = []\n",
    "    for name in missing_fullname:\n",
    "        df_filt = df[df['full name'].apply(lambda x: x == name)] \n",
    "        if df_filt.shape[1] != 0:\n",
    "            state = list(df_filt['state'])[0]\n",
    "            replacement_states.append(state)\n",
    "        else:\n",
    "            replacement_states.append(np.nan)\n",
    "    df.loc[missing_ind, 'state'] = replacement_states\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transformonecoldf(df, state):\n",
    "    #do transformdf but for when you only have one full name oclumn\n",
    "    df['full name prelim'] =  (df['First Name'].apply(lambda x: stringConvert(x)) + \" \" + \n",
    "                               df['Last Name'].apply(lambda x: stringConvert(x))).apply(lambda x: x.strip())\n",
    "    \n",
    "    df['full name prelim'] = df['full name prelim'].apply(lambda x: [x] if x != \"\" else [])\n",
    "    df['debt state'] = state\n",
    "    \n",
    "    df['full name'] = df['full name prelim']\n",
    "    #some preprocessing\n",
    "    df = df[df['full name'].apply(lambda x: x != [])]\n",
    "    #separate names that are combined with \"and\", or otherwise treated as one when they should be two\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [parseNames(x) if len(x.strip().split(\" \")) > 2 and \" and \" in x \n",
    "                                                                 else x for x in lst])\n",
    "    df['full name'] = df['full name'].apply(lambda namelist: combineLists(namelist))\n",
    "    \n",
    "    #fuzzy matching for different names in the full name column\n",
    "    fn_fuzzy = genFuzzyDict(df)\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [x if x not in fn_fuzzy.keys() \n",
    "                                                         else fn_fuzzy[x] for x in lst]) \n",
    "    \n",
    "    #fill in potentially missing states\n",
    "    if list(set(df['state'])) != [np.nan]:\n",
    "        missing_fullname = list(df[df['state'].apply(lambda x: pd.isnull(x))]['full name'])\n",
    "        missing_ind = list(df[df['state'].apply(lambda x: pd.isnull(x))].index)\n",
    "        replacement_states = []\n",
    "        for name in missing_fullname:\n",
    "            df_filt = df[df['full name'].apply(lambda x: x == name)] \n",
    "            if df_filt.shape[1] != 0:\n",
    "                state = list(df_filt['state'])[0]\n",
    "                replacement_states.append(state)\n",
    "            else:\n",
    "                replacement_states.append(np.nan)\n",
    "        df.loc[missing_ind, 'state'] = replacement_states\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Connecticut Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "CT_CD = pd.read_excel(\"../Data/Post1790/CT/CT_post1790_CD_ledger.xlsx\", \n",
    "                      header = 13, usecols = 'H, I, K, N, O, X, Y, AA, AD, AE, AN, AO, AQ, AT, AU')\n",
    "CT_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                  'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents', ]\n",
    "CT_CD_agg_pre = transformdf(CT_CD, 'CT')\n",
    "CT_CD_agg = CT_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "CT_ASD = pd.read_excel(\"../Data/Post1790/CT/CT_post1790_ASD_ledger.xlsx\", \n",
    "                      header = 13, usecols = 'H, I, K, N, O, X, Y, AA, AD, AE, AN, AO, AQ, AT, AU')\n",
    "CT_ASD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                  'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents', ]\n",
    "CT_ASD_agg_pre = transformdf(CT_ASD, 'CT')\n",
    "CT_ASD_agg = CT_ASD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Maryland Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "MD_CD = pd.read_excel(\"../Data/Post1790/MD/MD_post1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, X, Z, AA, AI, AJ, AL, AN, AO')\n",
    "MD_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "MD_CD_agg_pre = transformdf(MD_CD, 'MD')\n",
    "MD_CD_agg = MD_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "MD_ASD = pd.read_excel(\"../Data/Post1790/MD/MD_post1790_ASD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, X, Z, AA, AI, AJ, AL, AN, AO')\n",
    "MD_ASD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "MD_ASD_agg_pre = transformdf(MD_ASD, 'MD')\n",
    "MD_ASD_agg = MD_ASD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([CT_CD_agg, MD_CD_agg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_ASD = pd.concat([CT_ASD_agg, MD_ASD_agg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# North Carolina Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NC_CD = pd.read_excel(\"../Data/Post1790/NC/T695_R4_NC_CD.xlsx\", \n",
    "                      header = 11, usecols = 'J, K, M, W, X, Z, AA, AC, AD ')\n",
    "NC_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NC_CD_agg_pre = transformonecoldf(NC_CD, 'NC')\n",
    "NC_CD_agg = NC_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NC_ASD = pd.read_excel(\"../Data/Post1790/NC/T695_R3_NC_ASD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, K, P, Q, R, S, T, U ')\n",
    "NC_ASD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NC_ASD_agg_pre = transformonecoldf(NC_ASD, 'NC')\n",
    "NC_ASD_agg = NC_ASD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NC_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_ASD = pd.concat([NC_ASD_agg, cumulative_ASD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# New Hampshire Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NH_CD = pd.read_excel(\"../Data/Post1790/NH/T652_R6_New_Hampshire_CD.xlsx\", \n",
    "                      header = 10, usecols = 'I, J, L, N, O, P, Q, R, S')\n",
    "NH_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents',  \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NH_CD_agg_pre = transformonecoldf(NH_CD, 'NH')\n",
    "NH_CD_agg = NH_CD_agg_pre[['full name', 'state', 'debt state',  '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NH_ASD = pd.read_excel(\"../Data/Post1790/NH/T652_New_Hampshire_ASD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, M, N, V, W, AB, AC, AK, AL, AM, AN')\n",
    "NH_ASD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "NH_ASD_agg_pre = transformdf(NH_ASD, 'NH')\n",
    "NH_ASD_agg = NH_ASD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                             '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NH_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_ASD = pd.concat([NC_ASD_agg, cumulative_ASD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# New York Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#new york data doesn't tell us what state people are from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NY_CD = pd.read_excel(\"../Data/Post1790/NY/NY_1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, M, N, X, Y, AC, AD, AM, AN, AR, AS')\n",
    "NY_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "NY_CD['state'] = 'NY loan office'\n",
    "NY_CD_agg_pre = transformdf(NY_CD, 'NY')\n",
    "NY_CD_agg = NY_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NY_ASD = pd.read_excel(\"../Data/Post1790/NY/NY_1790_ASD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, M, N, X, Y, AC, AD, AM, AN, AR, AS')\n",
    "NY_ASD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "NY_ASD['state'] = 'NY loan office'\n",
    "NY_ASD_agg_pre = transformdf(NY_ASD, 'NY')\n",
    "NY_ASD_agg = NY_ASD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NY_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_ASD = pd.concat([NY_ASD_agg, cumulative_ASD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# South Carolina Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "SC_CD = pd.read_excel(\"../Data/Post1790/SC/Post_1790_South_Carolina_CD.xlsx\", \n",
    "                      header = 11, usecols = 'D, E, G, M, N, S, T, V, AB, AC, AH, AI, AK, AQ, AR')\n",
    "SC_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2',  '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "SC_CD_agg_pre = transformdf(SC_CD, 'SC')\n",
    "SC_CD_agg = SC_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "SC_ASD = pd.read_excel(\"../Data/Post1790/SC/Post_1790_South_Carolina_ASD_transfers_removed.xlsx\", \n",
    "                      header = 11, usecols = 'D, E, G, M, N, O')\n",
    "SC_ASD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_def_Dollar', '3p_Dollar']\n",
    "SC_ASD_agg_pre = transformonecoldf(SC_ASD, 'SC')\n",
    "SC_ASD_agg = SC_ASD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_def_Dollar', '3p_Dollar', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([SC_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_ASD = pd.concat([SC_ASD_agg, cumulative_ASD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pennsylvania Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "PA_CD = pd.read_excel(\"../Data/Post1790/PA/PA_post1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, X, Z, AA, AI, AJ, AM, AO, AP')\n",
    "PA_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "PA_CD_agg_pre = transformdf(PA_CD, 'PA')\n",
    "PA_CD_agg = PA_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([PA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Rhode Island Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "RI_CD = pd.read_excel(\"../Data/Post1790/RI/T653_Rhode_Island_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, X, Z, AA, AI, AJ, AL, AN, AO')\n",
    "RI_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "RI_CD_agg_pre = transformdf(RI_CD, 'RI')\n",
    "RI_CD_agg = RI_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "RI_ASD = pd.read_excel(\"../Data/Post1790/RI/T653_Rhode_Island_ASD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, K, N, O, X, Y, AA, AD, AE, AO, AP, AQ, AT, AU')\n",
    "RI_ASD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                  'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                  'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "RI_ASD_agg_pre = transformdf(RI_ASD, 'RI')\n",
    "RI_ASD_agg = RI_ASD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([RI_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_ASD = pd.concat([RI_ASD_agg, cumulative_ASD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Virginia Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#virginia data doesn't tell us what state people are from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "VA_CD = pd.read_excel(\"../Data/Post1790/VA/VA_CD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, K, L, U, V, X, Y, AH, AI, AK, AL')\n",
    "VA_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "VA_CD['state'] = np.nan\n",
    "VA_CD_agg_pre = transformdf(VA_CD, 'VA')\n",
    "VA_CD_agg = VA_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "VA_ASD = pd.read_excel(\"../Data/Post1790/VA/VA_ASD.xlsx\", \n",
    "                      header = 11, usecols = 'D, E, N, O, U, V, AE, AF, AL, AM, AW, AX')\n",
    "VA_ASD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                  'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                  'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "VA_ASD['state'] = np.nan\n",
    "VA_ASD_agg_pre = transformdf(VA_ASD, 'VA')\n",
    "VA_ASD_agg = VA_ASD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                             '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([VA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_ASD = pd.concat([VA_ASD_agg, cumulative_ASD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Georgia Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "GA_CD = pd.read_excel(\"../Data/Post1790/GA/T694_GA_Loan_Office_CD.xlsx\", \n",
    "                      header = 10, usecols = 'Q, R, T, Z, AA, AB, AC, AD, AE')\n",
    "GA_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents',  \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "GA_CD_agg_pre = transformonecoldf(GA_CD, 'GA')\n",
    "GA_CD_agg = GA_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([GA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#no new jersey because it only has 3% stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_ASD.reset_index(drop = True, inplace = True)\n",
    "cumulative_CD.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_ASD['Total'] = cumulative_ASD[['6p_Dollar','6p_def_Dollar']].fillna(0).sum(axis = 1) + cumulative_ASD[['6p_Cents','6p_def_Cents']].fillna(0).sum(axis = 1)/100\n",
    "cumulative_ASD.loc[cumulative_ASD[cumulative_ASD['state'].apply(lambda x: pd.isnull(x))].index, 'state'] = 'unspecified'\n",
    "\n",
    "cumulative_CD['Total'] = cumulative_CD[['6p_Dollar','6p_def_Dollar']].fillna(0).sum(axis = 1) + cumulative_CD[['6p_Cents','6p_def_Cents']].fillna(0).sum(axis = 1)/100\n",
    "cumulative_CD.loc[cumulative_CD[cumulative_CD['state'].apply(lambda x: pd.isnull(x))].index, 'state'] = 'unspecified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2168273.1746222223\n",
      "3611474.3704666668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6003844835099973"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ASD Statistics\n",
    "print(cumulative_ASD[cumulative_ASD['state'].apply(lambda x: x in ['unspecified', 'NY loan office'])]['Total'].sum())\n",
    "print(cumulative_ASD['Total'].sum())\n",
    "cumulative_ASD[cumulative_ASD['state'].apply(lambda x: x in ['unspecified', 'NY loan office'])]['Total'].sum()/cumulative_ASD['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3552155.41583\n",
      "11274965.092275001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.315048018930342"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CD Statistics\n",
    "print(cumulative_CD[cumulative_CD['state'].apply(lambda x: x in ['unspecified', 'NY loan office'])]['Total'].sum())\n",
    "print(cumulative_CD['Total'].sum())\n",
    "cumulative_CD[cumulative_CD['state'].apply(lambda x: x in ['unspecified', 'NY loan office'])]['Total'].sum()/cumulative_CD['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#using state\n",
    "agg_table_ASD = cumulative_ASD.fillna(0)[['state', 'Total']].groupby('state').sum().reset_index()\n",
    "agg_table_ASD = agg_table_ASD.round(2)\n",
    "agg_table_CD = cumulative_CD.fillna(0)[['state', 'Total']].groupby('state').sum().reset_index()\n",
    "agg_table_CD = agg_table_CD.round(2)\n",
    "agg_table = pd.merge(agg_table_ASD,agg_table_CD, on = 'state', how = 'outer')\n",
    "agg_table.columns = ['state', 'ASD Total', 'CD Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agg_table.to_csv('prepost_data_aggregations/statewise_debt_aggregation_Post1790.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#using state - replace unspecified with debt state, replace NY loan office with nY\n",
    "cumulative_ASD_rep = cumulative_ASD.copy()\n",
    "cumulative_ASD_rep.loc[cumulative_ASD_rep[cumulative_ASD_rep['state'] == 'unspecified'].index, 'state'] = cumulative_ASD_rep[cumulative_ASD_rep['state'] == 'unspecified']['debt state']\n",
    "cumulative_CD_rep = cumulative_CD.copy()\n",
    "cumulative_CD_rep.loc[cumulative_CD_rep[cumulative_CD_rep['state'] == 'unspecified'].index, 'state'] = cumulative_CD_rep[cumulative_CD_rep['state'] == 'unspecified']['debt state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agg_table_ASD_rep = cumulative_ASD_rep.fillna(0)[['state', 'Total']].groupby('state').sum().reset_index()\n",
    "agg_table_ASD_rep = agg_table_ASD_rep.round(2)\n",
    "agg_table_CD_rep = cumulative_CD_rep.fillna(0)[['state', 'Total']].groupby('state').sum().reset_index()\n",
    "agg_table_CD_rep = agg_table_CD_rep.round(2)\n",
    "agg_table_rep = pd.merge(agg_table_ASD_rep,agg_table_CD_rep, on = 'state', how = 'outer')\n",
    "agg_table_rep.columns = ['state', 'ASD Total', 'CD Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agg_table_rep.to_csv('prepost_data_aggregations/statewise_debt_aggregation_Post1790_rep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#using debt state instead of state\n",
    "agg_table_ASD_debtstate = cumulative_ASD.fillna(0)[['debt state', 'Total']].groupby('debt state').sum().reset_index()\n",
    "agg_table_ASD_debtstate = agg_table_ASD_debtstate.round(2)\n",
    "agg_table_CD_debtstate = cumulative_CD.fillna(0)[['debt state', 'Total']].groupby('debt state').sum().reset_index()\n",
    "agg_table_CD_debtstate = agg_table_CD_debtstate.round(2)\n",
    "agg_table_debtstate = pd.merge(agg_table_ASD_debtstate,agg_table_CD_debtstate, on = 'debt state', how = 'outer')\n",
    "agg_table_debtstate.columns = ['debt state', 'ASD Total', 'CD Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agg_table_debtstate.to_csv('prepost_data_aggregations/statewise_debt_aggregation_Post1790_debtstate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}