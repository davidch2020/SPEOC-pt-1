{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Data Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rapidfuzz import process\n",
    "from os.path import exists\n",
    "import itertools\n",
    "from whoswho import who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def stringConvert(x):\n",
    "    return x.replace(\"  \", \" \") if type(x) == str else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def combineLists(lst):\n",
    "    returnlst = []\n",
    "    for sublist in lst:\n",
    "        if type(sublist) == list:\n",
    "            returnlst.extend([item for item in sublist])\n",
    "        else:\n",
    "            returnlst.append(sublist)\n",
    "    return returnlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#function that makes dictionary that combines 3 full name columns into 1\n",
    "def genFullNameList(namelst): \n",
    "    #remove duplicates and nulls\n",
    "    namelst = list(set([name for name in namelst if not pd.isnull(name)]))\n",
    "    namelst = sorted(namelst, key=len)\n",
    "    #remove names that are really similar\n",
    "    namelstnew = namelst\n",
    "    if len(namelst) > 1:\n",
    "        namelstnew = []\n",
    "        name1 = namelst[0]\n",
    "        namelstnew.append(name1)\n",
    "        for name in namelst[1:]:\n",
    "            score1  = process.extract(name1, [name])[0][1]\n",
    "            score2 = who.match(name1, name)\n",
    "            #only add names if they are dissimilar - fuzzy score 70 or less\n",
    "            if score1 <= 70:\n",
    "                namelstnew.append(name)\n",
    "    return namelstnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def genFuzzyDict(df):\n",
    "    namelst = list(set([name for namelist in df['full name prelim'] for name in namelist]))\n",
    "    #create dictionary that matches similar names together\n",
    "    fn_fuzzy_pre = dict()\n",
    "    for name in namelst:\n",
    "        marker = False\n",
    "        if not pd.isnull(name):\n",
    "            #find matches for name\n",
    "            match = process.extract(name, [x for x in namelst if x != name and not \n",
    "                                           pd.isnull(x)], limit = 1, score_cutoff = 90)\n",
    "            if len(match)> 0:\n",
    "                match = match[0]\n",
    "                if match[1]>95:\n",
    "                    #add suitable matches to dictionary\n",
    "                    for nm in [match[0], name]:\n",
    "                        if nm in fn_fuzzy_pre.keys() and not marker:\n",
    "                            fn_fuzzy_pre[nm].extend([n for n in [match[0], name] if \n",
    "                                                     n != nm and n not in fn_fuzzy_pre[nm]])\n",
    "                            marker = True\n",
    "                    if not marker:\n",
    "                        if len(name) < len(match[0]):\n",
    "                            fn_fuzzy_pre[name] = [match[0]]\n",
    "                        else:\n",
    "                            fn_fuzzy_pre[match[0]] = [name]\n",
    "    #invert dictionary\n",
    "    fn_fuzzy = dict()\n",
    "    for key in fn_fuzzy_pre.keys():\n",
    "        vals = fn_fuzzy_pre[key]\n",
    "        for val in vals:\n",
    "            fn_fuzzy[val] = key\n",
    "    \n",
    "    return fn_fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#separate a string that contains two names into a list of two names\n",
    "def parseNames(x):\n",
    "    #replace words that don't have meaning\n",
    "    x = x.replace(\"and Co\", \"\").replace(\"and co\", \"\").replace(\"and Others\" ,\"\")\n",
    "    x = x.replace(\"and others\", \"\").replace(\"and Son\", \"\").replace(\"and Sons\", \"\")\n",
    "    x = x.replace(\"and Brothers\", \"\").strip()\n",
    "    #string preprocessing\n",
    "    namelst = x.split(\" and \")\n",
    "    namelst = [x.strip() for x in namelst if x.strip() != \"\"]\n",
    "    if len(namelst) > 1:\n",
    "        wd1len = len(namelst[0].split(\" \"))\n",
    "        wd2len = len(namelst[1].split(\" \"))\n",
    "        #add last name\n",
    "        if wd1len == 1 and wd2len != 1:\n",
    "            namelst[0] = namelst[0] + \" \" + namelst[1].split(\" \")[-1]\n",
    "    return namelst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transformdf(df, state):\n",
    "    #add full name columns\n",
    "    df['full name 1'] = (df['First Name'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 1'] = df['full name 1'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['full name 2'] = (df['First Name.1'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name.1'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 2'] = df['full name 2'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['full name 3'] = (df['First Name.2'].apply(lambda x: stringConvert(x))\n",
    "                         + \" \" + \n",
    "                         df['Last Name.2'].apply(lambda x: stringConvert(x)))\n",
    "    df['full name 3'] = df['full name 3'].apply(lambda x: x if len(x.strip().split(\" \")) > 1 else np.nan)\n",
    "    df['debt state'] = state\n",
    "    #add dicionary to merge different full name columns into one\n",
    "    df['full name prelim'] = [genFullNameList([fname1, fname2, fname3]) \n",
    "                              for fname1, fname2, fname3 in zip(df['full name 1'],\n",
    "                                                                df['full name 2'],\n",
    "                                                                df['full name 3'])]\n",
    "    df['full name'] = df['full name prelim']\n",
    "    #do some additional preprocessing\n",
    "    df = df[df['full name'].apply(lambda x: x != [])]\n",
    "    #separate names that are combined with \"and\", or otherwise treatde as one when they should be two\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [parseNames(x) if len(x.strip().split(\" \")) > 2 and \" and \" in x \n",
    "                                                                 else x for x in lst])\n",
    "    df['full name'] = df['full name'].apply(lambda namelist: combineLists(namelist))\n",
    "    \n",
    "    #fuzzy matching for different names in the full name column\n",
    "    fn_fuzzy = genFuzzyDict(df)\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [x if x not in fn_fuzzy.keys() \n",
    "                                                         else fn_fuzzy[x] for x in lst])\n",
    "    #simplify state into just one column\n",
    "    if 'state1' in list(df.columns):\n",
    "        state_list = [[s for s in list(set([s1, s2, s3])) if not pd.isnull(s)]\n",
    "                      for s1, s2, s3 in zip(df['state1'], df['state2'], df['state3'])]\n",
    "        df['state']  = [state[0] if state != [] else np.nan for state in state_list]\n",
    "   \n",
    "    #fill in potentially missing states\n",
    "    missing_fullname = list(df[df['state'].apply(lambda x: pd.isnull(x))]['full name'])\n",
    "    missing_ind = list(df[df['state'].apply(lambda x: pd.isnull(x))].index)\n",
    "    replacement_states = []\n",
    "    for name in missing_fullname:\n",
    "        df_filt = df[df['full name'].apply(lambda x: x == name)] \n",
    "        if df_filt.shape[1] != 0:\n",
    "            state = list(df_filt['state'])[0]\n",
    "            replacement_states.append(state)\n",
    "        else:\n",
    "            replacement_states.append(np.nan)\n",
    "    df.loc[missing_ind, 'state'] = replacement_states\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transformonecoldf(df, state):\n",
    "    #do transformdf but for when you only have one full name oclumn\n",
    "    df['full name prelim'] =  (df['First Name'].apply(lambda x: stringConvert(x)) + \" \" + \n",
    "                               df['Last Name'].apply(lambda x: stringConvert(x))).apply(lambda x: x.strip())\n",
    "    df['full name prelim'] = df['full name prelim'].apply(lambda x: [x] if x != \"\" else [])\n",
    "    \n",
    "    df['debt state'] = state\n",
    "    \n",
    "    df['full name'] = df['full name prelim']\n",
    "    #some preprocessing\n",
    "    df = df[df['full name'].apply(lambda x: x != [])]\n",
    "    #separate names that are combined with \"and\", or otherwise treated as one when they should be two\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [parseNames(x) if len(x.strip().split(\" \")) > 2 and \" and \" in x \n",
    "                                                                 else x for x in lst])\n",
    "    df['full name'] = df['full name'].apply(lambda namelist: combineLists(namelist))\n",
    "    \n",
    "    #fuzzy matching for different names in the full name column\n",
    "    fn_fuzzy = genFuzzyDict(df)\n",
    "    df['full name'] = df['full name'].apply(lambda lst: [x if x not in fn_fuzzy.keys() \n",
    "                                                         else fn_fuzzy[x] for x in lst]) \n",
    "    \n",
    "    #fill in potentially missing states\n",
    "    if list(set(df['state'])) != [np.nan]:\n",
    "        missing_fullname = list(df[df['state'].apply(lambda x: pd.isnull(x))]['full name'])\n",
    "        missing_ind = list(df[df['state'].apply(lambda x: pd.isnull(x))].index)\n",
    "        replacement_states = []\n",
    "        for name in missing_fullname:\n",
    "            df_filt = df[df['full name'].apply(lambda x: x == name)] \n",
    "            if df_filt.shape[1] != 0:\n",
    "                state = list(df_filt['state'])[0]\n",
    "                replacement_states.append(state)\n",
    "            else:\n",
    "                replacement_states.append(np.nan)\n",
    "        df.loc[missing_ind, 'state'] = replacement_states\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Connecticut Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "CT_CD = pd.read_excel(\"../Data/Post1790/CT/CT_post1790_CD_ledger.xlsx\", \n",
    "                      header = 13, usecols = 'H, I, K, N, O, X, Y, AA, AD, AE, AN, AO, AQ, AT, AU')\n",
    "CT_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                  'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents', ]\n",
    "CT_CD_agg_pre = transformdf(CT_CD, 'CT')\n",
    "CT_CD_agg = CT_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>state</th>\n",
       "      <th>debt state</th>\n",
       "      <th>6p_Dollar</th>\n",
       "      <th>6p_Cents</th>\n",
       "      <th>6p_def_Dollar</th>\n",
       "      <th>6p_def_Cents</th>\n",
       "      <th>3p_Dollar</th>\n",
       "      <th>3p_Cents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Samuel W Pomeroy]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Benjamin Trumbull]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>449.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[Richard Green]</td>\n",
       "      <td>RI</td>\n",
       "      <td>CT</td>\n",
       "      <td>154.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Thomas Hopkins]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>196.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[John Morgan]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>53.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1002</td>\n",
       "      <td>[John Morgan]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1003</td>\n",
       "      <td>[Samuel W Pomeroy]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1004</td>\n",
       "      <td>[William H Imlay]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>237.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1005</td>\n",
       "      <td>[Jonathan Palmer]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>196.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1006</td>\n",
       "      <td>[Jonathan Palmer]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>249.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1007 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                full name state debt state  6p_Dollar  6p_Cents  \\\n",
       "0      [Samuel W Pomeroy]    CT         CT     1064.0      75.0   \n",
       "1     [Benjamin Trumbull]    CT         CT      449.0      96.0   \n",
       "2         [Richard Green]    RI         CT      154.0      20.0   \n",
       "3        [Thomas Hopkins]    CT         CT      196.0      75.0   \n",
       "4           [John Morgan]    CT         CT       53.0      58.0   \n",
       "...                   ...   ...        ...        ...       ...   \n",
       "1002        [John Morgan]    CT         CT        NaN       NaN   \n",
       "1003   [Samuel W Pomeroy]    CT         CT        NaN       NaN   \n",
       "1004    [William H Imlay]    CT         CT      237.0      87.0   \n",
       "1005    [Jonathan Palmer]    CT         CT      196.0      63.0   \n",
       "1006    [Jonathan Palmer]    CT         CT      249.0      90.0   \n",
       "\n",
       "      6p_def_Dollar  6p_def_Cents  3p_Dollar  3p_Cents  \n",
       "0             532.0          37.0      508.0      51.0  \n",
       "1             224.0          97.0      232.0      10.0  \n",
       "2              77.0          10.0      192.0       NaN  \n",
       "3              98.0          37.0      172.0      24.0  \n",
       "4              26.0          79.0       67.0       6.0  \n",
       "...             ...           ...        ...       ...  \n",
       "1002            NaN           NaN       46.0      30.0  \n",
       "1003            NaN           NaN        NaN       2.0  \n",
       "1004          277.0          64.0      166.0      54.0  \n",
       "1005           98.0          31.0      223.0      92.0  \n",
       "1006          124.0          95.0      144.0       0.0  \n",
       "\n",
       "[1007 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CT_CD_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Maryland Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "MD_CD = pd.read_excel(\"../Data/Post1790/MD/MD_post1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, Z, AA, AI, AJ, AN, AO')\n",
    "MD_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "MD_CD_agg_pre = transformdf(MD_CD, 'MD')\n",
    "MD_CD_agg = MD_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([CT_CD_agg, MD_CD_agg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# North Carolina Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NC_CD = pd.read_excel(\"../Data/Post1790/NC/T695_R4_NC_CD.xlsx\", \n",
    "                      header = 11, usecols = 'J, K, M, W, X, Z, AA, AC, AD ')\n",
    "NC_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents', \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NC_CD_agg_pre = transformonecoldf(NC_CD, 'NC')\n",
    "NC_CD_agg = NC_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NC_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# New Hampshire Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NH_CD = pd.read_excel(\"../Data/Post1790/NH/T652_R6_New_Hampshire_CD.xlsx\", \n",
    "                      header = 10, usecols = 'I, J, L, N, O, P, Q, R, S')\n",
    "NH_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents',  \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "NH_CD_agg_pre = transformonecoldf(NH_CD, 'NH')\n",
    "NH_CD_agg = NH_CD_agg_pre[['full name', 'state', 'debt state',  '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NH_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# New York Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#new york data doesn't tell us what state people are from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "NY_CD = pd.read_excel(\"../Data/Post1790/NY/NY_1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, M, N, X, Y, AC, AD, AM, AN, AR, AS')\n",
    "NY_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "NY_CD['state'] = np.nan\n",
    "NY_CD_agg_pre = transformdf(NY_CD, 'NY')\n",
    "NY_CD_agg = NY_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([NY_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# South Carolina Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "SC_CD = pd.read_excel(\"../Data/Post1790/SC/Post_1790_South_Carolina_CD.xlsx\", \n",
    "                      header = 11, usecols = 'D, E, G, M, N, S, T, V, AB, AC, AH, AI, AK, AQ, AR')\n",
    "SC_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2',  '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "SC_CD_agg_pre = transformdf(SC_CD, 'SC')\n",
    "SC_CD_agg = SC_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([SC_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pennsylvania Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "PA_CD = pd.read_excel(\"../Data/Post1790/PA/PA_post1790_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, X, Z, AA, AI, AJ, AM, AO, AP')\n",
    "PA_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "PA_CD_agg_pre = transformdf(PA_CD, 'PA')\n",
    "PA_CD_agg = PA_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([PA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Rhode Island Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "RI_CD = pd.read_excel(\"../Data/Post1790/RI/T653_Rhode_Island_CD.xlsx\", \n",
    "                      header = 11, usecols = 'G, H, J, L, M, U, V, X, Z, AA, AI, AJ, AL, AN, AO')\n",
    "RI_CD.columns = ['First Name', 'Last Name', 'state1', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', 'state2', '6p_def_Dollar', '6p_def_Cents',\n",
    "                'First Name.2', 'Last Name.2', 'state3', '3p_Dollar', '3p_Cents']\n",
    "RI_CD_agg_pre = transformdf(RI_CD, 'RI')\n",
    "RI_CD_agg = RI_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([RI_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Virginia Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#virginia data doesn't tell us what state people are from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "VA_CD = pd.read_excel(\"../Data/Post1790/VA/VA_CD.xlsx\", \n",
    "                      header = 11, usecols = 'H, I, K, L, U, V, X, Y, AH, AI, AK, AL')\n",
    "VA_CD.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents', \n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "VA_CD['state'] = np.nan\n",
    "VA_CD_agg_pre = transformdf(VA_CD, 'VA')\n",
    "VA_CD_agg = VA_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([VA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Georgia Continental Debt Dataset Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare loan dataset\n",
    "GA_CD = pd.read_excel(\"../Data/Post1790/GA/T694_GA_Loan_Office_CD.xlsx\", \n",
    "                      header = 10, usecols = 'Q, R, T, Z, AA, AB, AC, AD, AE')\n",
    "GA_CD.columns = ['First Name', 'Last Name', 'state', '6p_Dollar', '6p_Cents',  \n",
    "                 '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']\n",
    "GA_CD_agg_pre = transformonecoldf(GA_CD, 'GA')\n",
    "GA_CD_agg = GA_CD_agg_pre[['full name', 'state', 'debt state', '6p_Dollar', '6p_Cents', \n",
    "                           '6p_def_Dollar', '6p_def_Cents', '3p_Dollar', '3p_Cents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD = pd.concat([GA_CD_agg, cumulative_CD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#no new jersey because it only has 3% stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD['full name'] = cumulative_CD['full name'].apply(lambda lst: [x for x in lst if len(x.split(\" \")) > 1])\n",
    "cumulative_CD = cumulative_CD[cumulative_CD['full name'].apply(lambda x: x != [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#turn full name column from list into strings\n",
    "fname = cumulative_CD['full name'].apply(pd.Series)\n",
    "nnames = len(fname.columns)\n",
    "colnames = ['full name ' + str(i) for i in np.arange(1, nnames+1, 1)]\n",
    "fname.columns = colnames\n",
    "cumulative_CD = pd.concat([cumulative_CD, fname], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How many unique individuals were issued 6 percent stocks or deferred 6 percent stocks in 1790 and after?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table of number of unique individuals issued 6% stocks (normal or deferred) by state\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "state\n",
       "BM       2\n",
       "BVI      4\n",
       "CT     689\n",
       "DE       8\n",
       "FR       2\n",
       "GA      14\n",
       "GB       2\n",
       "MA     108\n",
       "MD     278\n",
       "NC      41\n",
       "NH     132\n",
       "NJ      32\n",
       "NY      40\n",
       "PA     618\n",
       "RI     344\n",
       "SC     208\n",
       "US       1\n",
       "VA      31\n",
       "VI       4\n",
       "VT       7\n",
       "Name: full name, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_6 = cumulative_CD[['6p_Dollar', '6p_Cents', \n",
    "                          '6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index\n",
    "print('table of number of unique individuals issued 6% stocks (normal or deferred) by state')\n",
    "cumulative_CD.groupby('state')['full name'].agg(sum).apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# How many of these individuals\n",
    "- were original purchasers of loan office certicates of the same state as the 6 percent stock?\n",
    "- were original purchasers of loan office certicates issued from another state?\n",
    "- were original recipients of liquidated debtcerti cates issued by the same-state loan office? other state loan offices?\n",
    "- were original recipients of the Pierce Certicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fuzzy_merge(lst1, lst2, threshold=85, limit = 100):\n",
    "    delegates = pd.Series([x for x in lst1.unique() if not pd.isnull(x)])\n",
    "    possible =  [x for x in lst2.unique().tolist() if type(x) == str]\n",
    " \n",
    "    #get matches\n",
    "    #process.extract uses a combination of all four fuzzywuzzy scores\n",
    "    matches = delegates.apply(lambda x: \n",
    "                              process.extract(x, possible, limit=limit, score_cutoff = threshold))\n",
    "    \n",
    "    match_df = pd.DataFrame(columns = ['Delegates', 'Loan Matches'])\n",
    "    #make each match a row in the dataframe\n",
    "    for delegate, matchset in zip(delegates, matches):\n",
    "        matchset_thres = [name for name in matchset if name[1] >= threshold]\n",
    "        if len(matchset_thres) == 0:\n",
    "            add_df = pd.DataFrame(data = {'Delegates': [delegate], 'Loan Matches': [\"\"], 'Scores': [0]})\n",
    "            match_df = pd.concat([match_df, add_df])\n",
    "        else:\n",
    "            delegate_lst = [delegate] * len(matchset_thres)\n",
    "            add_df = pd.DataFrame(data = {'Delegates': delegate_lst, \n",
    "                                          'Loan Matches': [x[0] for x in matchset_thres],\n",
    "                                          'Scores': [x[1] for x in matchset_thres]})\n",
    "            match_df = pd.concat([match_df, add_df])\n",
    "\n",
    "    return match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#function for performing the second step of the match\n",
    "def matchFunction(lst1, lst2, score = 90):\n",
    "    #check if our matches are actually min 2 words each\n",
    "    #make sure our match is because the individual are similar, not because the phrase or one word in the phrase is similar\n",
    "    #lst1 = list(pd.Series(lst1).unique())\n",
    "    #lst2 = list(pd.Series(lst2).unique())\n",
    "    threshold = min(len(lst1), len(lst2))\n",
    "    matches = 0\n",
    "    nomatch = []\n",
    "    i = 0\n",
    "    for wd1 in lst1:\n",
    "        #modifying which words we compare - dont want to compare first in lst1 with last in lst2\n",
    "        for wd2 in lst2:\n",
    "            if wd1 not in nomatch and process.extract(wd1, [wd2])[0][1] > score:\n",
    "                matches+=1\n",
    "                nomatch.append(wd1)\n",
    "        i+=1\n",
    "    return matches >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def produceMatches(delegates, debt, delegate_names, debt_names, threshold = 85):\n",
    "    initial = True\n",
    "    join_df = pd.DataFrame()\n",
    "    #run firs step of matching function\n",
    "    for del_name in delegate_names:\n",
    "        for debt_name in debt_names:\n",
    "            if initial:\n",
    "                join_df = fuzzy_merge(delegates[del_name], debt[debt_name], threshold)\n",
    "                initial = False\n",
    "            else:\n",
    "                add_df = fuzzy_merge(delegates[del_name], debt[debt_name], threshold)\n",
    "                join_df = pd.concat([join_df, add_df])\n",
    "    join_df = join_df.drop_duplicates().reset_index(drop = True)\n",
    "    join_df = join_df[join_df['Scores'].apply(lambda x: x != 0)]\n",
    "    join_df = join_df[join_df['Loan Matches'].apply(lambda x: not pd.isnull(x))]    \n",
    "    #cleaning\n",
    "    join_df_p2 = join_df[join_df['Loan Matches'].apply(lambda x: len(list(set(x.replace(\"??\", \"\").strip().split(\" \"))))>=2)]\n",
    "    #run second step of matching function\n",
    "    join_df_p2_final = join_df_p2[[matchFunction(x.split(\" \"), y.split(\" \")) for x, y in zip(join_df_p2['Delegates'], join_df_p2['Loan Matches'])]]\n",
    "    #select only the highest scoring loan match name pairing \n",
    "    join_df_p2_final.sort_values(by = 'Scores', ascending = False, inplace = True)\n",
    "    join_df_p2_final_ind = join_df_p2_final[['Delegates','Loan Matches']].drop_duplicates().index\n",
    "    join_df_p2_final = join_df_p2_final.loc[join_df_p2_final_ind]\n",
    "    \n",
    "    return join_df_p2_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import and preprocess loan office data\n",
    "loan_office = pd.read_csv('../Data/Pre1790/cleaned/loan_office_certificates_9_states_cleaned.csv', index_col = 0)\n",
    "states = ['NH', 'MA', 'CT', 'NY', 'NJ', 'PA', 'DE', 'MD', 'VA']\n",
    "num_names = [1, 2, 2, 3, 2, None, 2, None, None]\n",
    "state_names = dict(zip(np.arange(1, 10, 1), states))\n",
    "loan_office['State Name'] = loan_office['State'].apply(lambda x: state_names[x])\n",
    "loan_office['Full Name 1'] = (loan_office['First Name 1 '].apply(lambda x: stringConvert(x)) + \" \" + loan_office['Last Name 1 '].apply(lambda x: stringConvert(x)))\n",
    "loan_office['Full Name 2'] = (loan_office['First Name 2'].apply(lambda x: stringConvert(x)) + \" \" + loan_office['Last Name 2'].apply(lambda x: stringConvert(x)))\n",
    "loan_office['Full Name 3'] = (loan_office['First Name 3'].apply(lambda x: stringConvert(x)) + \" \" + loan_office['Last Name 3'].apply(lambda x: stringConvert(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### How many individuals were original purchasers of loan office certicates of the same state as the 6 percent stock?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state_select = colnames\n",
    "state_select.extend(['state'])\n",
    "state_cols = ['cd name ' + str(i) for i in np.arange(1, len(state_select))]\n",
    "state_cols.extend(['cd state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#match cd debt data with loan office data from the same state\n",
    "def loanOfficeSameState(state):\n",
    "    #filter for 6% stock\n",
    "    state_ind = cumulative_CD[cumulative_CD['debt state'].apply(lambda x: x == state)][['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index\n",
    "    #skip empty dataframes\n",
    "    if len(state_ind) != 0:\n",
    "        #prepare state and loan office data\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        loan_office_state = loan_office[loan_office['State Name'] == state][['Full Name 1', 'Full Name 2', 'Full Name 3', 'State Name']].drop_duplicates()\n",
    "        loan_office_state.columns = ['loan office name 1', 'loan office name 2', 'loan office name 3', 'loan office state']\n",
    "        #match data\n",
    "        matches = produceMatches(state_cd, loan_office_state, \n",
    "                                 delegate_names = [x for x in state_cols if 'state' not in x],\n",
    "                                 debt_names = ['loan office name 1', 'loan office name 2', 'loan office name 3'], threshold = 85)\n",
    "        matches['state'] = state\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_loanoffice_samestate = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#combine matches from all the states\n",
    "for state in states:\n",
    "    df_loanoffice_samestate = pd.concat([df_loanoffice_samestate, loanOfficeSameState(state)])\n",
    "df_loanoffice_samestate.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_loanoffice_samestate = df_loanoffice_samestate[df_loanoffice_samestate['CD name'].apply(lambda x: len(x.split(\" \")) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_loanoffice_samestate.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals who were original purchasers of loan office certicates of the same state as the 6 percent stock\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    344\n",
       "DE     10\n",
       "MA     84\n",
       "MD    123\n",
       "NH     70\n",
       "NJ     43\n",
       "NY     45\n",
       "PA    394\n",
       "VA     71\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarize results\n",
    "print(\"Number of individuals who were original purchasers of loan office certicates of the same state as the 6 percent stock\")\n",
    "df_loanoffice_samestate.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### How many individuals were original purchasers of loan office certicates issued from another state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#higher match threshold for non-same state loan office certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#match cd debt data with loan office data from a different state\n",
    "def loanOfficeDifState(state):\n",
    "    #filter for 6% stock\n",
    "    state_ind = cumulative_CD[cumulative_CD['debt state'].apply(lambda x: x == state)][['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index\n",
    "    if len(state_ind) != 0:\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        loan_office_nostate = loan_office[loan_office['State Name'] != state][['Full Name 1', 'Full Name 2', 'Full Name 3', 'State Name']].drop_duplicates()\n",
    "        loan_office_nostate.columns = ['loan office name 1', 'loan office name 2', 'loan office name 3', 'loan office state']\n",
    "        #match data\n",
    "        matches = produceMatches(state_cd, loan_office_nostate, \n",
    "                                 delegate_names = [x for x in state_cols if 'state' not in x],\n",
    "                                 debt_names = ['loan office name 1', 'loan office name 2', 'loan office name 3'], threshold = 95)\n",
    "        matches['state'] = state\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_loanoffice_difstate = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#combine matches from all the states\n",
    "for state in states:\n",
    "    df_loanoffice_difstate = pd.concat([df_loanoffice_difstate, loanOfficeDifState(state)])\n",
    "df_loanoffice_difstate.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_loanoffice_difstate = df_loanoffice_difstate[df_loanoffice_difstate['CD name'].apply(lambda x: len(x.split(\" \")) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_loanoffice_difstate.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    372\n",
       "DE    302\n",
       "MA    313\n",
       "MD    326\n",
       "NH    317\n",
       "NJ    300\n",
       "NY    288\n",
       "PA    264\n",
       "VA    261\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loanoffice_difstate.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### How many individuals were original recipients of liquidated debt certificates issued by the same-state loan office? other state loan offices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Same State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#match CD state data with liquidated debt from the same state\n",
    "def liquidatedSameStateDebt(state, file, num_names):\n",
    "    #filter for 6% stock   \n",
    "    state_ind = cumulative_CD[cumulative_CD['debt state'].apply(lambda x: x == state)][['6p_Dollar', '6p_Cents']].dropna(thresh = 1).index\n",
    "    if len(state_ind) != 0:\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        #import liquidated state debt files\n",
    "        datafile = '../Data/Pre1790/cleaned/'+file\n",
    "        if exists(datafile):\n",
    "            state_cert = pd.read_csv(datafile, index_col = 0)\n",
    "            namelst = []\n",
    "            #figure out how many full name columns there are in the state liquidated debt file\n",
    "            state_cert['Full Name'] = state_cert['First name'] + \" \" + state_cert['Last name'] \n",
    "            namelst.append('Full Name')\n",
    "            if num_names > 1:\n",
    "                for i in np.arange(2, num_names+1, 1):\n",
    "                    fullname_str = 'Full Name ' + str(i)\n",
    "                    state_cert[fullname_str] = state_cert['First name ' + str(i)] + \" \" + state_cert['Last name ' + str(i)] \n",
    "                    namelst.append(fullname_str)\n",
    "            state_cert_names = state_cert[namelst].drop_duplicates()\n",
    "            #produce matches\n",
    "            matches = produceMatches(state_cd, state_cert_names, \n",
    "                                     delegate_names = state_cols, debt_names = namelst, \n",
    "                                     threshold = 85)\n",
    "            matches['state'] = state\n",
    "            return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_samestateliquid = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state_name = dict(zip(states, num_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#combine matches from all the states\n",
    "for state, num_name in state_name.items():\n",
    "    if state != \"PA\":\n",
    "        file = 'liquidated_debt_certificates_'+state+'_cleaned.csv'\n",
    "        df_samestateliquid = pd.concat([df_samestateliquid, liquidatedSameStateDebt(state, file, num_name)])\n",
    "    else:\n",
    "        file1 = 'liquidated_debt_certificates_PA_story_cleaned.csv'\n",
    "        df1 = liquidatedSameStateDebt('PA', file1, 1)\n",
    "        file2 = 'liquidated_debt_certificates_PA_stelle_cleaned.csv'\n",
    "        df2 = liquidatedSameStateDebt('PA', file2, 2)\n",
    "        df = pd.concat([df1, df2]).drop_duplicates()\n",
    "        df_samestateliquid = pd.concat([df_samestateliquid, df])\n",
    "df_samestateliquid.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_samestateliquid = df_samestateliquid[df_samestateliquid['CD name'].apply(lambda x: len(x.split(\" \")) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_samestateliquid.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    121\n",
       "DE     12\n",
       "MA     51\n",
       "NH     32\n",
       "NJ     74\n",
       "NY    106\n",
       "PA    302\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarize results\n",
    "df_samestateliquid.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Different State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def produceLiquidatedMatches(datafile, num_names, state_cd):\n",
    "    if exists(datafile):\n",
    "        state_cert = pd.read_csv(datafile, index_col = 0)\n",
    "        namelst = []\n",
    "        #figure out how many full name columns there are in the state liquidated debt file\n",
    "        state_cert['Full Name'] = state_cert['First name'] + \" \" + state_cert['Last name'] \n",
    "        namelst.append('Full Name')\n",
    "        if num_names > 1:\n",
    "            for i in np.arange(2, num_names+1, 1):\n",
    "                fullname_str = 'Full Name ' + str(i)\n",
    "                state_cert[fullname_str] = state_cert['First name ' + str(i)] + \" \" + state_cert['Last name ' + str(i)] \n",
    "                namelst.append(fullname_str)\n",
    "        state_cert_names = state_cert[namelst].drop_duplicates()\n",
    "        state_names = [x for x in state_cd.columns if x != 'cd state']\n",
    "        #produce matches\n",
    "        matches = produceMatches(state_cd, state_cert_names, \n",
    "                                 delegate_names = state_names, debt_names = namelst, \n",
    "                                 threshold = 95)\n",
    "        matches['state'] = state\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#match CD state data with liquidated debt from a dif state\n",
    "def liquidatedDifStateDebt(state):\n",
    "    #filter for 6% stock   \n",
    "    state_ind = cumulative_CD[cumulative_CD['debt state'].apply(lambda x: x == state)][['6p_Dollar', '6p_Cents']].dropna(thresh = 1).index\n",
    "    if len(state_ind) != 0:\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        #import liquidated state debt files\n",
    "        match_df = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores'])\n",
    "        for statename, num_names in state_name.items():\n",
    "            if not pd.isnull(num_names):\n",
    "                datafile = '../Data/Pre1790/cleaned/liquidated_debt_certificates_'+statename+'_cleaned.csv'\n",
    "                matches = produceLiquidatedMatches(datafile, num_names, state_cd)\n",
    "                match_df = pd.concat([match_df, matches])\n",
    "            elif state == 'PA':    \n",
    "                datafile1 = '../Data/Pre1790/cleaned/liquidated_debt_certificates_PA_story_cleaned.csv'\n",
    "                matches1 = produceLiquidatedMatches(datafile, 1, state_cd)\n",
    "                datafile2 = '../Data/Pre1790/cleaned/liquidated_debt_certificates_PA_stelle_cleaned.csv'\n",
    "                matches2 = produceLiquidatedMatches(datafile, 2, state_cd)\n",
    "                match_df = pd.concat([match_df, matches2])\n",
    "        match_df['state'] = state\n",
    "        return match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_difstateliquid = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#combine matches from all the states\n",
    "for state in states:\n",
    "    df_difstateliquid = pd.concat([df_difstateliquid, liquidatedDifStateDebt(state)])\n",
    "df_difstateliquid.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_difstateliquid.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    307\n",
       "DE    144\n",
       "MA    175\n",
       "MD    174\n",
       "NH    186\n",
       "NJ    152\n",
       "NY    148\n",
       "PA    223\n",
       "VA    143\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_difstateliquid.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### How many individuals were original recipients of the Pierce Certicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pierce = pd.read_csv('../Data/Pre1790/cleaned/'+\"Pierce_Certs_cleaned_2021.csv\", index_col = 0)\n",
    "pierce['Full Name'] = pierce['First'].apply(lambda x: stringConvert(x)) + \" \" + pierce['Last'].apply(lambda x: stringConvert(x))\n",
    "pierce['Full Name 2'] = pierce['First 2'].apply(lambda x: stringConvert(x)) + \" \" + pierce['Last 2'].apply(lambda x: stringConvert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#match cd debt data with loan office data from the Pierce certificate data\n",
    "def pierceCertificates(state):\n",
    "    #filter for 6% stock\n",
    "    state_ind = cumulative_CD[cumulative_CD['debt state'].apply(lambda x: x == state)][['6p_Dollar', '6p_Cents', '6p_def_Dollar', '6p_def_Cents']].dropna(thresh = 1).index\n",
    "    if len(state_ind) != 0:\n",
    "        state_cd = cumulative_CD.loc[state_ind][state_select].drop_duplicates()\n",
    "        state_cd.columns = state_cols\n",
    "        #match data\n",
    "        pierce_names = pierce[pierce['State'].apply(lambda x: pd.isnull(x) or x == state)][['Full Name', 'Full Name 2']].drop_duplicates()\n",
    "        matches = produceMatches(state_cd, pierce_names, \n",
    "                                 delegate_names = ['cd name 1'], \n",
    "                                 debt_names = ['Full Name', 'Full Name 2'], \n",
    "                                 threshold = 95)\n",
    "        matches['state'] = state\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_pierce = pd.DataFrame({}, columns = ['Delegates', 'Loan Matches', 'Scores', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    df_pierce = pd.concat([df_pierce, pierceCertificates(state)])\n",
    "df_pierce.columns = ['CD name', 'Loan Office name', 'Scores', 'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_pierce = df_pierce[df_pierce['CD name'].apply(lambda x: len(x.split(\" \")) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "CT    331\n",
       "DE    168\n",
       "MA    224\n",
       "MD    242\n",
       "NH    197\n",
       "NJ    171\n",
       "NY    202\n",
       "PA    308\n",
       "VA    204\n",
       "Name: CD name, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pierce.groupby('state')['CD name'].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_pierce.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Organizing all our name matchg pairs into one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#column to add the matching names into a total table containing cd loan names\n",
    "#and corresopnding match names for each pre1790 loan times\n",
    "def mergeNames(colname, df):\n",
    "    colnames = [colname + ' 1', colname + ' 2', colname + ' 3', colname + ' 4', colname + ' 5']\n",
    "    loss_dict = dict(df.groupby('CD name')['Loan Office name'].apply(lambda x: list(x)))\n",
    "    cumulative_CD[colname + ' 1'] = cumulative_CD['full name 1'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname + ' 2'] = cumulative_CD['full name 2'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname + ' 3'] = cumulative_CD['full name 3'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname + ' 4'] = cumulative_CD['full name 4'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname + ' 5'] = cumulative_CD['full name 5'].apply(lambda name: \n",
    "                                                                       loss_dict.get(name, np.nan))\n",
    "    cumulative_CD[colname] = cumulative_CD[colnames].values.tolist()\n",
    "    cumulative_CD[colname] = cumulative_CD[colname].apply(lambda lst: list(set(combineLists([x for x in lst if type(x) != float]))))\n",
    "    cumulative_CD[colname] = cumulative_CD[colname].apply(lambda x: x if x != [] else np.nan)\n",
    "    cumulative_CD.drop(colnames, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#run process on all four pre1790 loan types\n",
    "mergeNames('Same State Loan Office', df_loanoffice_samestate)\n",
    "mergeNames('Different State Loan Office', df_loanoffice_difstate)\n",
    "mergeNames('Same State Liquidated Debt', df_samestateliquid)\n",
    "mergeNames('Different State Liquidated Debt', df_difstateliquid)\n",
    "mergeNames('Pierce Certificates', df_pierce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#number of loan types one person had\n",
    "cumulative_CD['tot_count'] = 5 - cumulative_CD[['Same State Loan Office',\n",
    "                                                'Different State Loan Office',\n",
    "                                                'Same State Liquidated Debt',\n",
    "                                                'Different State Liquidated Debt',\n",
    "                                                'Pierce Certificates']].isna().sum(axis = 1)\n",
    "cumulative_CD.drop(['3p_Cents','3p_Dollar', 'full name 1', \n",
    "                    'full name 2','full name 3', 'full name 4',\n",
    "                    'full name 5'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#some preprocesing - creating dictionaries to add back in data, after I turned the list of names into a string to remove duplicates\n",
    "#the original data we imported above was lost so we readd it by creating dictionaries\n",
    "cumulative_CD['str name'] = cumulative_CD['full name'].apply(lambda x: str(x)) + \"____\" + cumulative_CD['state']\n",
    "fullnamedict = dict(zip(cumulative_CD['str name'], cumulative_CD['full name']))\n",
    "statenamedict = dict(zip(cumulative_CD['str name'], cumulative_CD['state']))\n",
    "statedebtnamedict = dict(zip(cumulative_CD['str name'], cumulative_CD['debt state']))\n",
    "sslodict = dict(zip(cumulative_CD['str name'], cumulative_CD['Same State Loan Office']))\n",
    "dslodict = dict(zip(cumulative_CD['str name'], cumulative_CD['Different State Loan Office']))\n",
    "sslddict = dict(zip(cumulative_CD['str name'], cumulative_CD['Same State Liquidated Debt']))\n",
    "dslddict = dict(zip(cumulative_CD['str name'], cumulative_CD['Different State Liquidated Debt']))\n",
    "pcdict = dict(zip(cumulative_CD['str name'], cumulative_CD['Pierce Certificates']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#use dictionaries to link data to matched values for each loan type\n",
    "cumulative_CD_assets = cumulative_CD.groupby('str name')['6p_Cents','6p_Dollar',\n",
    "                                                         '6p_def_Cents','6p_def_Dollar'].sum()\n",
    "cumulative_CD_assets.reset_index(inplace = True)\n",
    "cumulative_CD_assets['full name'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                           fullnamedict[x])\n",
    "cumulative_CD_assets['state'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                       statenamedict[x])\n",
    "cumulative_CD_assets['state debt'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                       statedebtnamedict[x])\n",
    "cumulative_CD_assets['Same State Loan Office'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                        sslodict[x])\n",
    "cumulative_CD_assets['Different State Loan Office'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                             dslodict[x])\n",
    "cumulative_CD_assets['Same State Liquidated Debt'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                            sslddict[x])\n",
    "cumulative_CD_assets['Different State Liquidated Debt'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                                 dslddict[x])\n",
    "cumulative_CD_assets['Pierce Certificates'] = cumulative_CD_assets['str name'].apply(lambda x: \n",
    "                                                                                     pcdict[x])\n",
    "cumulative_CD_assets['Total'] = (cumulative_CD_assets['6p_def_Cents'] + \n",
    "                                 cumulative_CD_assets['6p_Cents'])/100 + (cumulative_CD_assets['6p_Dollar'] + \n",
    "                                                                          cumulative_CD_assets['6p_def_Dollar'])\n",
    "cumulative_CD_assets.drop(['6p_def_Cents', '6p_Cents', \n",
    "                           '6p_Dollar', '6p_def_Dollar', 'str name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full name</th>\n",
       "      <th>state</th>\n",
       "      <th>state debt</th>\n",
       "      <th>Same State Loan Office</th>\n",
       "      <th>Different State Loan Office</th>\n",
       "      <th>Same State Liquidated Debt</th>\n",
       "      <th>Different State Liquidated Debt</th>\n",
       "      <th>Pierce Certificates</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Bernard O'Neill]</td>\n",
       "      <td>MD</td>\n",
       "      <td>MD</td>\n",
       "      <td>[Bernard O'Neill]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Francis O'Neill]</td>\n",
       "      <td>MD</td>\n",
       "      <td>MD</td>\n",
       "      <td>[Francis O'Neill]</td>\n",
       "      <td>[Francis O Neill]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[Henry O'Neale]</td>\n",
       "      <td>MD</td>\n",
       "      <td>MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Henry O'Neal]</td>\n",
       "      <td>99.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[James O'Hara]</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[ Agness ann]</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>883.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2532</td>\n",
       "      <td>[Zebulon Waterman]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2533</td>\n",
       "      <td>[Zephaniah Andrews]</td>\n",
       "      <td>RI</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1728.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2534</td>\n",
       "      <td>[Zephaniah Brown]</td>\n",
       "      <td>RI</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2415.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2535</td>\n",
       "      <td>[Zephaniah Davis]</td>\n",
       "      <td>CT</td>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2536</td>\n",
       "      <td>[Zuriel Waterman]</td>\n",
       "      <td>RI</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2537 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                full name state state debt Same State Loan Office  \\\n",
       "0       [Bernard O'Neill]    MD         MD      [Bernard O'Neill]   \n",
       "1       [Francis O'Neill]    MD         MD      [Francis O'Neill]   \n",
       "2         [Henry O'Neale]    MD         MD                    NaN   \n",
       "3          [James O'Hara]    PA         PA                    NaN   \n",
       "4           [ Agness ann]    PA         PA                    NaN   \n",
       "...                   ...   ...        ...                    ...   \n",
       "2532   [Zebulon Waterman]    CT         CT                    NaN   \n",
       "2533  [Zephaniah Andrews]    RI         RI                    NaN   \n",
       "2534    [Zephaniah Brown]    RI         RI                    NaN   \n",
       "2535    [Zephaniah Davis]    CT         CT                    NaN   \n",
       "2536    [Zuriel Waterman]    RI         RI                    NaN   \n",
       "\n",
       "     Different State Loan Office Same State Liquidated Debt  \\\n",
       "0                            NaN                        NaN   \n",
       "1              [Francis O Neill]                        NaN   \n",
       "2                            NaN                        NaN   \n",
       "3                            NaN                        NaN   \n",
       "4                            NaN                        NaN   \n",
       "...                          ...                        ...   \n",
       "2532                         NaN                        NaN   \n",
       "2533                         NaN                        NaN   \n",
       "2534                         NaN                        NaN   \n",
       "2535                         NaN                        NaN   \n",
       "2536                         NaN                        NaN   \n",
       "\n",
       "     Different State Liquidated Debt Pierce Certificates    Total  \n",
       "0                                NaN                 NaN   230.31  \n",
       "1                                NaN                 NaN    37.96  \n",
       "2                                NaN      [Henry O'Neal]    99.77  \n",
       "3                                NaN                 NaN    33.44  \n",
       "4                                NaN                 NaN   883.63  \n",
       "...                              ...                 ...      ...  \n",
       "2532                             NaN                 NaN   306.61  \n",
       "2533                             NaN                 NaN  1728.74  \n",
       "2534                             NaN                 NaN  2415.08  \n",
       "2535                             NaN                 NaN    77.20  \n",
       "2536                             NaN                 NaN    10.95  \n",
       "\n",
       "[2537 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_CD_assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Adding the different asset totals from each loan type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Same State Loan Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#add asset counts for each individual on each row to the state loan office table for the same state merging method\n",
    "def ssloTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Same State Loan Office']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state debt']\n",
    "    state_office = loan_office[loan_office['State Name'] == state]\n",
    "    ind1 = state_office[state_office['Full Name 1'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind2 = state_office[state_office['Full Name 2'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind3 = state_office[state_office['Full Name 3'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind1.extend(ind2)\n",
    "    ind1.extend(ind3)\n",
    "    total_val = state_office.loc[ind1]['Specie Value '].sum()\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD_assets['SSLO Total'] = np.nan\n",
    "ssloIndex = cumulative_CD_assets[cumulative_CD_assets['Same State Loan Office'].apply(lambda x: type(x) == list)].index\n",
    "cumulative_CD_assets.loc[ssloIndex, 'SSLO Total'] = [ssloTotal(x) for x in ssloIndex]\n",
    "cumulative_CD_assets['SSLO Total'] = cumulative_CD_assets['SSLO Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Different State Loan Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#add asset counts for each individual on each row to the state loan office table for the dif state merging method\n",
    "def dsloTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Different State Loan Office']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state debt']    \n",
    "    state_office = loan_office[loan_office['State Name'] != state]\n",
    "    ind1 = state_office[state_office['Full Name 1'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind2 = state_office[state_office['Full Name 2'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind3 = state_office[state_office['Full Name 3'].apply(lambda x: x in name_options)].index.tolist()\n",
    "    ind1.extend(ind2)\n",
    "    ind1.extend(ind3)\n",
    "    total_val = state_office.loc[ind1]['Specie Value '].sum()\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD_assets['DSLO Total'] = np.nan\n",
    "dsloIndex = cumulative_CD_assets[cumulative_CD_assets['Different State Loan Office'].apply(lambda x: \n",
    "                                                                                           type(x) == list)].index\n",
    "cumulative_CD_assets.loc[dsloIndex, 'DSLO Total'] = [dsloTotal(x) for x in dsloIndex]\n",
    "cumulative_CD_assets['DSLO Total'] = cumulative_CD_assets['DSLO Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Same State Liquidated Debt Certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#function to add values of liquidated debt certificates\n",
    "def ssldTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Same State Liquidated Debt']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state debt']\n",
    "    \n",
    "    if state != 'PA' and state in state_name.keys():\n",
    "        num_names = state_name[state]\n",
    "        state_certs_file = '../Data/Pre1790/cleaned/liquidated_debt_certificates_'+state+'_cleaned.csv'\n",
    "        if exists(state_certs_file):\n",
    "            total_val = calculateTotalValue(state_certs_file, num_names, name_options)\n",
    "            return total_val\n",
    "    elif state == 'PA':\n",
    "        state_certs_file1 = '../Data/Pre1790/cleaned/liquidated_debt_certificates_PA_story_cleaned.csv'\n",
    "        total_val1 = calculateTotalValue(state_certs_file1, 1, name_options)\n",
    "        state_certs_file2 = '../Data/Pre1790/cleaned/liquidated_debt_certificates_PA_stelle_cleaned.csv'\n",
    "        total_val2 = calculateTotalValue(state_certs_file2, 2, name_options)\n",
    "        return total_val1 + total_val2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#calculate total value held by one person in debt certificates from a particular state\n",
    "def calculateTotalValue(file, num_names, name_options):\n",
    "    #this part is pretty similar to the merging part for liquidated debt certificates\n",
    "    state_cert = pd.read_csv(file, index_col = 0)\n",
    "    state_cert['Full Name'] = state_cert['First name'] + \" \" + state_cert['Last name'] \n",
    "    namelst = []\n",
    "    namelst.append('Full Name')\n",
    "    if num_names > 1:\n",
    "        for i in np.arange(2, num_names+1, 1):\n",
    "            fullname_str = 'Full Name ' + str(i)\n",
    "            state_cert[fullname_str] = state_cert['First name ' + str(i)] + \" \" + state_cert['Last name ' + str(i)] \n",
    "            namelst.append(fullname_str)\n",
    "    ind = []\n",
    "    for name in namelst:\n",
    "        ind.extend(state_cert[state_cert[name].apply(lambda x: x in name_options)].index.tolist())\n",
    "    #create subtable for the data we want, make it into a numeric value and sum it\n",
    "    subtbl = state_cert.loc[ind]\n",
    "    subtbl['Dollars'] = subtbl['Dollars'].apply(lambda x: float(x))\n",
    "    subtbl['90th'] = subtbl['90th'].apply(lambda x: float(x) if x != '22/8' else 22/8)\n",
    "    total_val = subtbl['Dollars'].sum() + subtbl['90th'].sum()/90\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD_assets['SSLD Total'] = np.nan\n",
    "ssldIndex = cumulative_CD_assets[cumulative_CD_assets['Same State Liquidated Debt'].apply(lambda x: \n",
    "                                                                                          type(x) == list)].index\n",
    "cumulative_CD_assets.loc[ssldIndex, 'SSLD Total'] = [ssldTotal(x) for x in ssldIndex]\n",
    "cumulative_CD_assets['SSLD Total'] = cumulative_CD_assets['SSLD Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Different State Liquidated Debt Certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#function to add values of liquidated debt certificates\n",
    "def dsldTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Different State Liquidated Debt']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state debt']\n",
    "    sumval = 0\n",
    "    for statename in states:\n",
    "        if statename != 'PA' and not pd.isnull(state_name[statename]):\n",
    "            num_names = state_name[statename]\n",
    "            state_certs_file = '../Data/Pre1790/cleaned/liquidated_debt_certificates_'+statename+'_cleaned.csv'\n",
    "            if exists(state_certs_file):\n",
    "                total_val = calculateTotalValue(state_certs_file, \n",
    "                                                num_names, name_options)\n",
    "            sumval = sumval + total_val\n",
    "        elif statename == 'PA':\n",
    "            state_certs_file1 = '../Data/Pre1790/cleaned/liquidated_debt_certificates_PA_story_cleaned.csv'\n",
    "            total_val1 = calculateTotalValue(state_certs_file1, \n",
    "                                             1, name_options)\n",
    "            state_certs_file2 = '../Data/Pre1790/cleaned/liquidated_debt_certificates_PA_stelle_cleaned.csv'\n",
    "            total_val2 = calculateTotalValue(state_certs_file2, \n",
    "                                             2, name_options)\n",
    "            sumval = sumval + total_val1 + total_val2\n",
    "    return sumval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#calculate total value held by one person in debt certificates from a particular state\n",
    "def calculateTotalValue(file, num_names, name_options):\n",
    "    #this part is pretty similar to the merging part for liquidated debt certificates\n",
    "    state_cert = pd.read_csv(file, index_col = 0)\n",
    "    state_cert['Full Name'] = state_cert['First name'] + \" \" + state_cert['Last name'] \n",
    "    namelst = []\n",
    "    namelst.append('Full Name')\n",
    "    if num_names > 1:\n",
    "        for i in np.arange(2, num_names+1, 1):\n",
    "            fullname_str = 'Full Name ' + str(i)\n",
    "            state_cert[fullname_str] = state_cert['First name ' + str(i)] + \" \" + state_cert['Last name ' + str(i)] \n",
    "            namelst.append(fullname_str)\n",
    "    ind = []\n",
    "    for name in namelst:\n",
    "        ind.extend(state_cert[state_cert[name].apply(lambda x: x in name_options)].index.tolist())\n",
    "    #create subtable for the data we want, make it into a numeric value and sum it\n",
    "    subtbl = state_cert.loc[ind]\n",
    "    subtbl['Dollars'] = subtbl['Dollars'].apply(lambda x: float(x))\n",
    "    subtbl['90th'] = subtbl['90th'].apply(lambda x: float(x) if x != '22/8' else 22/8)\n",
    "    total_val = subtbl['Dollars'].sum() + subtbl['90th'].sum()/90\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD_assets['DSLD Total'] = np.nan\n",
    "dsldIndex = cumulative_CD_assets[cumulative_CD_assets['Different State Liquidated Debt'].apply(lambda x:\n",
    "                                                                                               type(x) == list)].index\n",
    "cumulative_CD_assets.loc[dsldIndex, 'DSLD Total'] = [dsldTotal(x) for x in dsldIndex]\n",
    "cumulative_CD_assets['DSLD Total'] = cumulative_CD_assets['DSLD Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Same State Pierce Certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#calculate sum for pierce certificates\n",
    "def pcTotal(ind):\n",
    "    name_options = cumulative_CD_assets.loc[ind, 'Pierce Certificates']\n",
    "    state = cumulative_CD_assets.loc[ind, 'state debt']\n",
    "    \n",
    "    pierce_state = pierce[pierce['State'].apply(lambda x: \n",
    "                                                pd.isnull(x) or x == state)]\n",
    "    ind1 = pierce_state[pierce_state['Full Name'].apply(lambda x: \n",
    "                                                        x in name_options)].index.tolist()\n",
    "    ind2 = pierce_state[pierce_state['Full Name 2'].apply(lambda x: \n",
    "                                                          x in name_options)].index.tolist()\n",
    "    ind1.extend(ind2)\n",
    "    total_val = pierce_state.loc[ind1]['Value'].sum()\n",
    "    return total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD_assets['PC Total'] = np.nan\n",
    "pcIndex = cumulative_CD_assets[cumulative_CD_assets['Pierce Certificates'].apply(lambda x: \n",
    "                                                                                 type(x) == list)].index\n",
    "cumulative_CD_assets.loc[pcIndex, 'PC Total'] = [pcTotal(x) for x in pcIndex]\n",
    "cumulative_CD_assets['PC Total'] = cumulative_CD_assets['PC Total'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD_assets['Debt Total'] = cumulative_CD_assets[['SSLO Total','DSLO Total',\n",
    "                                                           'SSLD Total', 'DSLD Total',\n",
    "                                                           'PC Total']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pre1790_certs = ['Same State Loan Office','Different State Loan Office', \n",
    "                 'Same State Liquidated Debt','Different State Liquidated Debt','Pierce Certificates']\n",
    "cumulative_CD_assets['tot_pre1790_certs'] = 5 - cumulative_CD_assets[pre1790_certs].isna().sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_CD_assets.to_csv(\"prepost_matched_debt_files.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matched_names = pd.concat([df_loanoffice_samestate, df_loanoffice_difstate, df_samestateliquid,\n",
    "                           df_difstateliquid, df_pierce])\n",
    "matched_names = matched_names[matched_names['Scores'] != 100][['CD name','Loan Office name', 'state']].drop_duplicates()\n",
    "matched_names.to_csv(\"../Data/total_matching_post1790.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}