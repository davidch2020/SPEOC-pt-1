{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from rapidfuzz import fuzz\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Final Table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "def deNaN(series):\n",
    "    return series.apply(lambda x: \"\" if pd.isnull(x) else x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "df = pd.read_csv('NY_results.csv', index_col = 0)\n",
    "\n",
    "# preprocess name columns\n",
    "df['Search Name'] = df['Search Name'].apply(lambda x: x.replace('[[', '').replace(']]',''))\n",
    "df['Search Name'] = df['Search Name'].apply(lambda x: x.split('a0')[0][2:-2])\n",
    "df['Original Name'] = df['Original Name'].apply(lambda x: x.replace('\\'','').replace('\\\"','').strip('][').split(', '))\n",
    "df['Original Name2'] = df['Original Name'].apply(lambda x: str(x))\n",
    "\n",
    "# preprocess slavecount oclumns\n",
    "df.loc[df[df['Slavecount'].apply(lambda x: '\\xa0' in x if not pd.isnull(x) else False)].index, 'Slavecount'] = np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "# dictionary to convert between string and list version of data\n",
    "str_convert = dict(zip(df['Original Name2'], df['Original Name']))\n",
    "# find unique value for all of the columns - helps with consolidation\n",
    "# use dict.fromkeys because it preserves order\n",
    "df_reformat = df.groupby(['Index', 'Original Name2'])['Search Name'].unique().reset_index()\n",
    "for col in ['Match Status', 'Match Reason', 'Location', 'Family Size', 'Slavecount', 'url']:\n",
    "    df_merge = df.groupby(['Index', 'Original Name2']).agg({col:list}).reset_index()\n",
    "    df_merge[col] = df_merge[col].apply(lambda x: list(dict.fromkeys(x)))\n",
    "    df_reformat = pd.merge(df_reformat, df_merge)\n",
    "# convert back to original format\n",
    "df_reformat['Original Name'] = df_reformat['Original Name2'].apply(lambda x: str_convert[x])\n",
    "# preprocess names to prepare for merging\n",
    "df_reformat['Original Name2'] = df_reformat['Original Name'].apply(lambda x: set([y.replace('\\\"', '') for y in x]))\n",
    "df_reformat['Original Name2'] = df_reformat['Original Name2'].apply(lambda x: str(sorted(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "# NY loan data\n",
    "NY_CD_raw = pd.read_excel(\"../../Data/Post1790/NY/NY_1790_CD.xlsx\",\n",
    "                      header = 11, usecols = 'H, I, M, N, X, Y, AC, AD, AM, AN, AR, AS')\n",
    "NY_CD_raw.columns = ['First Name', 'Last Name', '6p_Dollar', '6p_Cents',\n",
    "                 'First Name.1', 'Last Name.1', '6p_def_Dollar', '6p_def_Cents',\n",
    "                 'First Name.2', 'Last Name.2', '3p_Dollar', '3p_Cents']\n",
    "# create name column\n",
    "NY_CD_raw['Name 1'] =  deNaN(NY_CD_raw['First Name']) + \" \" + deNaN(NY_CD_raw['Last Name'])\n",
    "NY_CD_raw['Name 2'] =  deNaN(NY_CD_raw['First Name.1']) + \" \" + deNaN(NY_CD_raw['Last Name.1'])\n",
    "NY_CD_raw['Name 3'] =  deNaN(NY_CD_raw['First Name.2']) + \" \" + deNaN(NY_CD_raw['Last Name.2'])\n",
    "NY_CD_raw['Name'] = [set([x.replace(\"  \",\" \").strip() for x in [name1, name2, name3] if x.strip() != \"\"]) for name1, name2, name3 in zip(NY_CD_raw['Name 1'], NY_CD_raw['Name 2'], NY_CD_raw['Name 3'])]\n",
    "# create name column string equivalent and dictionary to convert\n",
    "NY_CD_raw['Name_str'] = NY_CD_raw['Name'].apply(lambda x: str(sorted(x)))\n",
    "NY_dict = dict(zip(NY_CD_raw['Name_str'], NY_CD_raw['Name']))\n",
    "\n",
    "# aggregate our reults - creat eaggregated dataframe\n",
    "NY_CD_raw['6p_Total'] = NY_CD_raw['6p_Dollar'].fillna(0) + NY_CD_raw['6p_Cents'].fillna(0)\n",
    "NY_CD_raw['6p_def_Total'] = NY_CD_raw['6p_def_Dollar'].fillna(0) + NY_CD_raw['6p_def_Cents'].fillna(0)\n",
    "NY_CD_raw['3p_Total'] = NY_CD_raw['3p_Dollar'].fillna(0) + NY_CD_raw['3p_Cents'].fillna(0)\n",
    "NY_grouped = NY_CD_raw.groupby('Name_str').agg({'6p_Total': ['sum', 'count'],\n",
    "                                                '6p_def_Total': 'sum',\n",
    "                                                '3p_Total': 'sum'}).reset_index()\n",
    "NY_grouped.columns = ['Name_str', '6p_Total', 'count', '6p_def_Total', '3p_Total']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "# merge NY asset data and scraped data\n",
    "NY_final = pd.merge(NY_grouped, df_reformat, left_on='Name_str', right_on = 'Original Name2')\n",
    "NY_final['Original Name'] = NY_final['Original Name2'].apply(lambda x: NY_dict[x])\n",
    "NY_final.drop(['Original Name2'], axis = 1, inplace = True)\n",
    "\n",
    "# re-string Search Name Column\n",
    "NY_final['Name_str'] = NY_final['Search Name'].apply(lambda x: str(sorted(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "# names that we will match\n",
    "sn_series = NY_final['Search Name'].explode().drop_duplicates()\n",
    "sn_names = [sn for sn in NY_final['Search Name'].tolist() if len(sn) < 2]\n",
    "sn_series = [x for x in sn_series[sn_series.apply(lambda x: [x] in sn_names)]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "# use fuzzy string matching to see if the same name appears multiple times spelled slightly differently\n",
    "elements = sn_series\n",
    "results = [[name, [], 0] for name in elements]\n",
    "\n",
    "for (i, element) in enumerate(elements):\n",
    "    for (j, choice) in enumerate(elements[i+1:]):\n",
    "        if fuzz.ratio(element, choice, score_cutoff=85):\n",
    "            results[i][2] += 1\n",
    "            results[i][1].append(choice)\n",
    "            results[j+i+1][2] += 1\n",
    "            results[j+i+1][1].append(element)\n",
    "# remove names with no matches\n",
    "match_df = pd.DataFrame(results, columns=['name', 'duplicates', 'duplicate_count'])\n",
    "match_df['dup_list'] = [[name] + dup for name, dup in zip(match_df['name'], match_df['duplicates'])]\n",
    "match_df['dup_list_str'] = match_df['dup_list'].apply(lambda x: str(sorted(x)))\n",
    "match_df = match_df[match_df['duplicate_count'] > 0]\n",
    "# create duplicate list\n",
    "# convert to string format, create match reason column\n",
    "mr_dict = dict(zip(NY_final[NY_final['Search Name'].apply(lambda x: len(x) == 1)]['Search Name'].apply(lambda x: x[0]),\n",
    "                   NY_final[NY_final['Search Name'].apply(lambda x: len(x) == 1)]['Match Reason']))\n",
    "match_df['match reason'] = match_df['name'].apply(lambda x: mr_dict[x][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [],
   "source": [
    "# see whether two matches are actually a match, using census data\n",
    "grouped_df = match_df.groupby(['dup_list_str'])['match reason'].unique().reset_index()\n",
    "grouped_df = grouped_df[grouped_df['match reason'].apply(lambda x: len(x) == 1 and 'Too Many Potential Matches' not in x[0])]\n",
    "# list to manually remove certain matches\n",
    "remlist = []\n",
    "final_merge = pd.merge(match_df.drop('match reason', axis = 1),grouped_df[grouped_df['match reason'].apply(lambda x: len(x) == 1)], on = 'dup_list_str')\n",
    "final_merge = final_merge[final_merge['dup_list'].apply(lambda x: (x not in remlist))]\n",
    "fuzzy_merge_dict = dict(zip(final_merge['name'].apply(lambda x: str([x])),\n",
    "                            final_merge['dup_list_str'].astype(str)))\n",
    "# add in merged data\n",
    "NY_final['Name_str_new'] = NY_final['Name_str'].apply(lambda x: fuzzy_merge_dict.get(x, x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [],
   "source": [
    "NY_grouped = NY_final.groupby('Name_str_new').agg({'count':'sum', '6p_Total':'sum', '6p_def_Total':'sum', '3p_Total':'sum',\n",
    "                                                   'Family Size': list,  'Location': list, 'Match Reason': list,\n",
    "                                                   'Match Status': list, 'Slavecount': list, 'url': list,\n",
    "                                                   'Name_str': list}).reset_index()\n",
    "# remove duplicates, flatten string\n",
    "for cols in ['Family Size', 'Location', 'Match Reason', 'Match Status', 'Slavecount', 'url']:\n",
    "    NY_grouped[cols] = NY_grouped[cols].apply(lambda x: list(dict.fromkeys(list(itertools.chain(*x)))))\n",
    "\n",
    "# change to list format\n",
    "namestr_dict = dict(zip(NY_final['Name_str'], NY_final['Search Name']))\n",
    "NY_grouped['Name_str'] = NY_grouped['Name_str'].apply(lambda x: list(dict.fromkeys(list(itertools.chain(*[namestr_dict[ele] for ele in x])))))\n",
    "NY_grouped.rename({'Name_str': 'Original Search Names'}, axis = 1, inplace = True)\n",
    "\n",
    "# aggregate data - group by search name\n",
    "NY_grouped['Name_str_new'] = NY_grouped['Original Search Names'].apply(lambda x: [max(x, key=len)] if x in final_merge['dup_list'].tolist() else x)\n",
    "NY_grouped.rename({'Name_str_new': 'Search Names'}, axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [],
   "source": [
    "# processing names where search names length is 3\n",
    "NY_table = NY_grouped.copy()\n",
    "# processing search names length of 3\n",
    "names  = NY_table.loc[NY_table[NY_table['Search Names'].apply(lambda x: len(x)>2)].index, 'Search Names'].apply(lambda x: max(x, key = len)).tolist()\n",
    "NY_table.loc[NY_table[NY_table['Search Names'].apply(lambda x: len(x)>2)].index, 'Search Name'] = names\n",
    "NY_table.loc[NY_table[NY_table['Search Names'].apply(lambda x: len(x)>2)].index, 'Search Names'] = NY_table.loc[NY_table[NY_table['Search Names'].apply(lambda x: len(x)>2)].index, 'Search Names'].apply(lambda x: [max(x, key = len)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [],
   "source": [
    "# processing search names length of 2\n",
    "snames = NY_table.loc[NY_table[NY_table['Search Names'].apply(lambda x: len(x)>1 and len(x) < 3)].index,\n",
    "                            'Search Names']\n",
    "scores = NY_table.loc[NY_table[NY_table['Search Names'].apply(lambda x: len(x)>1 and len(x) < 3)].index,\n",
    "                            'Search Names'].apply(lambda x: fuzz.ratio(x[0], x[1]))\n",
    "compare = pd.DataFrame([snames, scores]).T\n",
    "compare.columns = ['Search Names', 'Scores']\n",
    "\n",
    "names = [names for names in compare['Search Names']]\n",
    "namedict = dict(zip([str(n) for n in names], names))\n",
    "remlist = []\n",
    "for name_str, name in namedict.items():\n",
    "    ind = NY_table[NY_table['Search Names'].apply(lambda x: str(x) == name_str)].index\n",
    "    mr = NY_table.loc[ind, 'Match Reason'].tolist()[0]\n",
    "    for code in ['Full Match', 'Too Many Potential Matches Found', 'No Match Found']:\n",
    "        if len(mr) == 1 and code in mr[0]:\n",
    "            ind = NY_table[NY_table['Search Names'].apply(lambda x: all(x == name) if type(x == name) != bool else x == name)].index\n",
    "            NY_table.loc[ind, 'Search Name'] = max(name, key = len)\n",
    "            remlist.append(name_str)\n",
    "    for code in ['Full Match', 'Only Location Found', 'Too Many Potential Matches Found', 'No Match Found']:\n",
    "        if len(mr) == 2 and (code in mr[0] or mr[1]) and name_str not in remlist:\n",
    "            ind = NY_table[NY_table['Search Names'].apply(lambda x: all(x == name) if type(x == name) != bool else x == name)].index\n",
    "            mr1 = df[df['Search Name'] == name[0]]['Match Reason'].tolist()[0]\n",
    "            mr2 = df[df['Search Name'] == name[1]]['Match Reason'].tolist()[0]\n",
    "            name = name[0] if mr1 == 'Full Match' else name[1]\n",
    "            NY_table.loc[ind, 'Search Name'] = name\n",
    "            remlist.append(name_str)\n",
    "for n in remlist:\n",
    "    del namedict[n]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "# replace search names with just a list with one name\n",
    "candidate_index = NY_table[[len(sn) == 2 and len(mr) == 1 for sn, mr in zip(NY_table['Search Names'], NY_table['Match Reason'])]].index\n",
    "snames = compare[compare['Search Names'].apply(lambda x: x in NY_table.loc[candidate_index]['Search Names'].tolist())].query('Scores > 80')['Search Names'].tolist()\n",
    "repindex = NY_table.loc[candidate_index][NY_table.loc[candidate_index, 'Search Names'].apply(lambda x: x in snames)].index\n",
    "NY_table.loc[repindex, 'Search Names'] = NY_table.loc[repindex, 'Search Name']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [],
   "source": [
    "# set search names to the name for everyone else\n",
    "goodnames = NY_table[NY_table['Search Names'].apply(lambda x: len(x) == 1)].index\n",
    "NY_table.loc[goodnames, 'Search Name'] = \\\n",
    "    NY_table.loc[goodnames, 'Search Names'].apply(lambda x: x[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [],
   "source": [
    "datacols = ['Family Size', 'Location', 'Match Reason', 'Match Status', 'Slavecount', 'url']\n",
    "for ind in NY_table['Search Name'].index:\n",
    "    search_name = NY_table.loc[ind, 'Search Name']\n",
    "    search_namelist = NY_table.loc[ind, 'Search Names']\n",
    "    if len(search_namelist) > 1:\n",
    "        try:\n",
    "            NY_table.loc[ind, datacols] = df[df['Search Name'] == search_name][datacols].drop_duplicates().squeeze().tolist()\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        for col in datacols:\n",
    "            NY_table.loc[ind, col] = NY_table.loc[ind, col][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table 1: Indexed by Original Name List\n",
    "Original Name List created by mapping search names list to Original Names in df\n",
    "Other identifying columns are Search Names and Search Name columns\n",
    "Also delist the other columns with relevant information\n",
    "if Match Reason (before cleaning) is only \"too many potential matches found\" - flag as potentially multiple people\n",
    "\n",
    "Table 2: Contains data from df for information on other people in Search Names list from table 1 but aren't Search Name\n",
    "Indexed by Search Names and Name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [],
   "source": [
    "# add original names\n",
    "ogname_dict = dict(df[['Search Name', 'Original Name']].groupby('Search Name').agg({'Original Name':list}).reset_index().values)\n",
    "NY_table['Original Names'] = NY_table['Original Search Names'].apply(lambda x: [ogname_dict[n][0] for n in x])\n",
    "NY_table['Original Names'] = NY_table['Original Names'].apply(lambda x: list(dict.fromkeys(list(itertools.chain(*x)))))\n",
    "NY_table['Match Reason'] = NY_table['Match Reason'].apply(lambda x: x if 'Too Many' not in x else \"Too Many Potential Matches Found (\" + str(x.split(\"Found \")[1]) + \")\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [],
   "source": [
    "multiple_ind = NY_table[['Too Many' in mr and count > 1 and len(snames) == 1 for mr, count, snames in zip(NY_table['Match Reason'],\n",
    "                                                                                                          NY_table['count'],\n",
    "                                                                                                          NY_table['Search Names'])]].index\n",
    "NY_table.loc[multiple_ind, 'notes'] = 'Potentially Multiple People'\n",
    "\n",
    "multiple_ind = NY_table[NY_table['Search Names'].apply(lambda x: len(x) > 1)].index\n",
    "NY_table.loc[multiple_ind, 'notes'] = 'See Supplementary Table'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [],
   "source": [
    "# create table with supplementary data\n",
    "NY_table2 = NY_table.copy()\n",
    "NY_table2['Search Names2'] = NY_table2['Search Names']\n",
    "NY_table2 = NY_table2[['Search Names', 'Search Names2', 'Search Name', 'Original Names', 'count', '6p_Total', '6p_def_Total', '3p_Total']].explode('Search Names2')\n",
    "NY_table2 = NY_table2[NY_table2['Search Names2'] != NY_table2['Search Name']]\n",
    "NY_table2.drop('Search Name', axis = 1, inplace = True)\n",
    "NY_table2.rename({'Search Names2':'Search Name'}, axis = 1, inplace = True)\n",
    "NY_table2.reset_index(drop = True, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [],
   "source": [
    "# reformat match reason column\n",
    "# add data to NY_table2 - suppelementary table\n",
    "for ind in NY_table2.index:\n",
    "    search_name = NY_table2.loc[ind, 'Search Name']\n",
    "    search_namelist = NY_table2.loc[ind, 'Search Names']\n",
    "    NY_table2.loc[ind, datacols] = df[df['Search Name'] == search_name][datacols].drop_duplicates().squeeze().tolist()\n",
    "NY_table2['Match Reason'] = NY_table2['Match Reason'].apply(lambda x: x if 'Too Many' not in x else \"Too Many Potential Matches Found (\" + str(x.split(\"Found \")[1]) + \")\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [],
   "source": [
    "# adding how many people were actually searched for - # unique people\n",
    "NY_table2['temp'] = NY_table2['Search Names'].astype(str)\n",
    "namecntdf = NY_table2.groupby('temp')['Search Names'].count().reset_index()\n",
    "namecntdict = dict(zip(namecntdf['temp'], namecntdf['Search Names']))\n",
    "NY_table['temp'] = NY_table['Search Names'].astype(str)\n",
    "NY_table['# debtholders'] = NY_table['temp'].apply(lambda x: namecntdict.get(x, 0)+1)\n",
    "NY_table2['# debtholders'] = NY_table2['temp'].apply(lambda x: namecntdict.get(x, 0)+1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "outputs": [],
   "source": [
    "# reodder columns\n",
    "NY_table = NY_table[['Search Names', 'Search Name', '# debtholders', 'Original Names', 'count', '6p_Total', '6p_def_Total', '3p_Total',\n",
    "                     'Location', 'Family Size', 'Slavecount', 'Match Status', 'Match Reason', 'notes', 'url']]\n",
    "NY_table2 = NY_table2[['Search Names', 'Search Name', '# debtholders', 'Original Names', 'count', '6p_Total', '6p_def_Total', '3p_Total',\n",
    "                       'Location', 'Family Size', 'Slavecount', 'Match Status', 'Match Reason', 'url']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "outputs": [],
   "source": [
    "NY_table.sort_values('3p_Total', ascending = False).to_csv('../../Data/Post1790/Aggregated/NY/NY_table.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [],
   "source": [
    "NY_table2.sort_values('3p_Total', ascending = False).to_csv('../../Data/Post1790/Aggregated/NY/NY_supp_table.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}